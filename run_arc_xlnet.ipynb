{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.transformers import modeling_with_arc_xlnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from src.transformers import modeling_xlnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import logging\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kg_loader import KG\n",
    "from graph_utils import GraphEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.transformers.tokenization_xlnet import XLNetTokenizer\n",
    "from src.transformers.tokenization_bert import BertTokenizer\n",
    "from src.transformers.tokenization_roberta import RobertaTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.transformers.modeling_with_arc_xlnet import XLNetForMultipleChoice\n",
    "from src.transformers.modeling_roberta import RobertaForMultipleChoice\n",
    "from src.transformers.modeling_bert import BertForMultipleChoice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.transformers.optimization import AdamW, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.transformers.configuration_xlnet import XLNetConfig\n",
    "from src.transformers.configuration_bert import BertConfig\n",
    "from src.transformers.configuration_roberta import RobertaConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.transformers.file_utils import WEIGHTS_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_arc import convert_examples_to_features, processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.transformers.tokenization_utils import PreTrainedTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "except ImportError:\n",
    "    from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_MODELS = sum(\n",
    "    (\n",
    "        tuple(conf.pretrained_config_archive_map.keys())\n",
    "        for conf in (BertConfig, RobertaConfig, XLNetConfig)\n",
    "    ),\n",
    "    (),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CLASSES = {\n",
    "    \"bert\" : (BertConfig, BertForMultipleChoice, BertTokenizer),\n",
    "    \"XLNet\" : (XLNetConfig, XLNetForMultipleChoice, XLNetTokenizer),\n",
    "    \"Roberta\" : (RobertaConfig, RobertaForMultipleChoice, RobertaTokenizer),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_field(features, field):\n",
    "    return [\n",
    "        [\n",
    "            choice[field] \n",
    "            for choice in feature.choices_features\n",
    "        ]\n",
    "        for feature in features\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.array([1,4,2,3,0,3,2,1,2,3,3,2,4,1,2,1,3,2,2,2,1,1,3,3,2,2,1,3,3,2,2,3,1,3]).astype('int64')\n",
    "labels = np.array([3,2,4,1,1,3,1,2,2,4,1,2,4,1,4,1,4,1,2,3,4,1,4,1,4,1,2,3,2,3,1,2,3,1]).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_accuracy(preds, labels):\n",
    "    print(\"labels {} \\n\".format(labels))\n",
    "    print(\"label.shape {} \\n\".format(labels.shape))\n",
    "    print(\"label data type {} \\n\".format(labels.dtype))\n",
    "    print(\"preds shape {} \\n\".format(preds.shape))\n",
    "    print(\"preds data type {} \\n\".format(preds.dtype))\n",
    "    print(preds)\n",
    "    return (preds == labels).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels [3 2 4 1 1 3 1 2 2 4 1 2 4 1 4 1 4 1 2 3 4 1 4 1 4 1 2 3 2 3 1 2 3 1] \n",
      "\n",
      "label.shape (34,) \n",
      "\n",
      "label data type int64 \n",
      "\n",
      "preds shape (34,) \n",
      "\n",
      "preds data type int64 \n",
      "\n",
      "[1 4 2 3 0 3 2 1 2 3 3 2 4 1 2 1 3 2 2 2 1 1 3 3 2 2 1 3 3 2 2 3 1 3]\n"
     ]
    }
   ],
   "source": [
    "x = simple_accuracy(preds,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2647058823529412"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def simple_accuracy(out, labels):\n",
    "    #outputs = np.argmax(out, axis=0)\n",
    "    #return np.sum(outputs == labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if n_gpu > 0:\n",
    "        torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataset, model, tokenizer):\n",
    "    # Train the model\n",
    "    if local_rank in [-1,0]:\n",
    "        tb_writer = SummaryWriter()\n",
    "\n",
    "    train_batch_size = per_gpu_train_batch_size * max(1, n_gpu)\n",
    "    train_sampler = RandomSampler(train_dataset) if local_rank == -1 else DistributedSampler(train_dataset)\n",
    "    train_dataloader = DataLoader(train_dataset, sampler = train_sampler, batch_size = train_batch_size)\n",
    "    \n",
    "    num_train_epochs = 3.0\n",
    "    if max_steps > 0:\n",
    "        t_total = max_steps\n",
    "        num_train_epochs = max_steps // (len(train_dataloader) // gradient_accumulation_steps) + 1\n",
    "\n",
    "    else:\n",
    "        t_total = len(train_dataloader) // gradient_accumulation_steps * num_train_epochs\n",
    "\n",
    "    # Prepare optimizer and schedule ( Linear warmpu and decay)\n",
    "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_grouped_parameters = [\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "            \"weight_decay\": weight_decay,\n",
    "        },\n",
    "        {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
    "    ]\n",
    "\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr = learning_rate, eps = adam_epsilon)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, num_warmup_steps=warmup_steps, num_training_steps = t_total\n",
    "    )\n",
    "\n",
    "    if fp16:\n",
    "        try:\n",
    "            from apex import amp\n",
    "        except ImportError:\n",
    "            raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\")\n",
    "        model, optimizer = amp.initialize(model, optimizer, opt_level=fp16_opt_level)\n",
    "\n",
    "    # multi-gpu training (should be after apex fp16 initialization)\n",
    "    if n_gpu > 1:\n",
    "        model = torch.nn.DataParallel(model)\n",
    "\n",
    "    # Distributed training (should be after apex fp16 initialization)\n",
    "    if local_rank != -1:\n",
    "        model = torch.nn.parallel.DistributedDataParallel(\n",
    "            model, device_ids=[local_rank], output_device=local_rank, find_unused_parameters=True\n",
    "        )\n",
    "\n",
    "    # Train\n",
    "    logger.info(\"******* Running Training *********\")\n",
    "    logger.info(\" Num Examples = %d\", len(train_dataset))\n",
    "    logger.info(\" Num Epochs = %d\", num_train_epochs)\n",
    "    logger.info(\" Instantaneous batch size per GPU = %d\", per_gpu_train_batch_size)\n",
    "    logger.info(\n",
    "        \"  Total train batch size (w. parallel, distributed & accumulation) = %d\",\n",
    "        train_batch_size\n",
    "        * gradient_accumulation_steps\n",
    "        * (torch.distributed.get_world_size() if local_rank != -1 else 1),\n",
    "    )\n",
    "\n",
    "    logger.info(\" Gradient Accumulation steps = %d\", gradient_accumulation_steps)\n",
    "    logger.info(\" Total optimization steps =%d\",t_total)\n",
    "\n",
    "    global_step = 0\n",
    "    tr_loss, logging_loss = 0.0, 0.0\n",
    "    best_dev_acc = 0.0\n",
    "    best_steps = 0\n",
    "    model.zero_grad()\n",
    "    train_iterator = trange(int(num_train_epochs), desc =\"Epoch\", \n",
    "                            disable=local_rank not in [-1, 0])\n",
    "    set_seed(seed) # Added here for reproductibility\n",
    "    \n",
    "    ent = torch.from_numpy(np.stack([kg.kg_embeddings['ent_embeddings'] \n",
    "                                      for _ in range(1)],axis=0)).to(device)\n",
    "    rel = torch.from_numpy(np.stack([kg.kg_embeddings['rel_matrices'] \n",
    "                                      for _ in range(1)],axis=0)).to(device)\n",
    "    for _ in train_iterator:\n",
    "        epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\", \n",
    "                              disable=local_rank not in [-1, 0])\n",
    "        for step, batch in enumerate(epoch_iterator):\n",
    "            model.train()\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            inputs = {\n",
    "                \"input_ids\": batch[0],\n",
    "                \"attention_mask\": batch[1],\n",
    "                \"token_type_ids\": batch[2]\n",
    "                if model_type in [\"bert\", \"xlnet\"]\n",
    "                else None,  # XLM don't use segment_ids\n",
    "                \n",
    "                \"gpre\" : batch[3],\n",
    "                \"ghyp\" : batch[4],\n",
    "                \"ent\" : ent,\n",
    "                \"rel\" : rel,\n",
    "                \"labels\": batch[5],\n",
    "            }\n",
    "\n",
    "            outputs = model(**inputs)\n",
    "            loss = outputs[0] # model outputs are always tuple in transformers\n",
    "\n",
    "            if n_gpu > 1:\n",
    "                loss = loss.mean() # mean() to average on multi-gpu parallel training\n",
    "            if gradient_accumulation_steps > 1:\n",
    "                loss = loss / gradient_accumulation_steps\n",
    "\n",
    "            if fp16:\n",
    "                with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                    scaled_loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), max_grad_norm)\n",
    "            else:\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "\n",
    "            tr_loss += loss.item()\n",
    "            if(step +1) % gradient_accumulation_steps == 0:\n",
    "                optimizer.step()\n",
    "                scheduler.step() # update learning rate scheduler\n",
    "                model.zero_grad()\n",
    "                global_step += 1\n",
    "\n",
    "                if local_rank in [-1,0] and logging_steps > 0 and global_step % logging_steps == 0:\n",
    "                    # Log metrics\n",
    "                    # Log metrics\n",
    "                    if (\n",
    "                        local_rank == -1 and evaluate_during_training\n",
    "                    ):  # Only evaluate when single GPU otherwise metrics may not average well\n",
    "                        results = evaluate(model, tokenizer)\n",
    "                        for key, value in results.items():\n",
    "                            tb_writer.add_scalar(\"eval_{}\".format(key), value, global_step)\n",
    "                        if results[\"eval_acc\"] > best_dev_acc:\n",
    "                            best_dev_acc = results[\"eval_acc\"]\n",
    "                            best_steps = global_step\n",
    "                            if do_test:\n",
    "                                results_test = evaluate(model, tokenizer, test=True)\n",
    "                                for key, value in results_test.items():\n",
    "                                    tb_writer.add_scalar(\"test_{}\".format(key), value, global_step)\n",
    "                                logger.info(\n",
    "                                    \"test acc: %s, loss: %s, global steps: %s\",\n",
    "                                    str(results_test[\"eval_acc\"]),\n",
    "                                    str(results_test[\"eval_loss\"]),\n",
    "                                    str(global_step),\n",
    "                                )\n",
    "                    tb_writer.add_scalar(\"lr\", scheduler.get_lr()[0], global_step)\n",
    "                    tb_writer.add_scalar(\"loss\", (tr_loss - logging_loss) / logging_steps, global_step)\n",
    "                    logger.info(\n",
    "                        \"Average loss: %s at global step: %s\",\n",
    "                        str((tr_loss - logging_loss) / logging_steps),\n",
    "                        str(global_step),\n",
    "                    )\n",
    "                    logging_loss = tr_loss\n",
    "\n",
    "                if local_rank in [-1, 0] and save_steps > 0 and global_step % save_steps == 0:\n",
    "                    # Save model checkpoint\n",
    "                    print(output_dir)\n",
    "                    output_dir1 = os.path.join(output_dir, \"checkpoint-{}\".format(global_step))\n",
    "                    print(output_dir1)\n",
    "                    if not os.path.exists(output_dir1):\n",
    "                        os.makedirs(output_dir1)\n",
    "                    model_to_save = (\n",
    "                        model.module if hasattr(model, \"module\") else model\n",
    "                    )  # Take care of distributed/parallel training\n",
    "                    model_to_save.save_pretrained(output_dir1)\n",
    "                    tokenizer.save_vocabulary(output_dir1)\n",
    "                    torch.save(output_dir,os.path.join(output_dir, \"training_args.bin\"))\n",
    "                    logger.info(\"Saving model checkpoint to %s\", output_dir1)\n",
    "            if max_steps > 0 and global_step > max_steps:\n",
    "                epoch_iterator.close()\n",
    "                break\n",
    "    if local_rank in [-1,0]:\n",
    "        tb_writer.close()\n",
    "\n",
    "    return global_step, tr_loss / global_step, best_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, tokenizer, prefix=\"\", test = False):\n",
    "    eval_task_names = (task_name,)\n",
    "    eval_outputs_dirs = (output_dir,)\n",
    "\n",
    "    results = {}\n",
    "    for eval_task, eval_output_dir in zip(eval_task_names, eval_outputs_dirs):\n",
    "        eval_dataset = load_and_cache_examples(\n",
    "            eval_task, tokenizer, evaluate=True, test=False)\n",
    "\n",
    "        if not os.path.exists(eval_output_dir) and local_rank in [-1, 0]:\n",
    "            os.makedirs(eval_output_dir)\n",
    "\n",
    "        eval_batch_size = per_gpu_eval_batch_size * max(1, n_gpu)\n",
    "        print(\"eval_batch_size {} \\n\".format(eval_batch_size))\n",
    "        # Note that DistributedSampler samples randomly\n",
    "        eval_sampler = SequentialSampler(eval_dataset)\n",
    "        eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=eval_batch_size)\n",
    "\n",
    "        # multi-gpu evaluate\n",
    "        if n_gpu > 1:\n",
    "            model = torch.nn.DataParallel(model)\n",
    "\n",
    "        # Eval!\n",
    "        logger.info(\"***** Running evaluation {} *****\".format(prefix))\n",
    "        logger.info(\"  Num examples = %d\", len(eval_dataset))\n",
    "        logger.info(\"  Batch size = %d\", eval_batch_size)\n",
    "        eval_loss = 0.0\n",
    "        nb_eval_steps = 0\n",
    "        preds = None\n",
    "        out_label_ids = None\n",
    "        ent = torch.from_numpy(np.stack([kg.kg_embeddings['ent_embeddings'] \n",
    "                                          for _ in range(1)],axis=0)).to(device)\n",
    "        rel = torch.from_numpy(np.stack([kg.kg_embeddings['rel_matrices'] \n",
    "                                          for _ in range(1)],axis=0)).to(device)\n",
    "        for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
    "            model.eval()\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                inputs = {\n",
    "                    \"input_ids\": batch[0],\n",
    "                    \"attention_mask\": batch[1],\n",
    "                    \"token_type_ids\": batch[2]\n",
    "                    if model_type in [\"bert\", \"xlnet\"]\n",
    "                    else None,  # XLM don't use segment_ids\n",
    "                    \"gpre\" : batch[3],\n",
    "                    \"ghyp\" : batch[4],\n",
    "                    \"ent\" : ent,\n",
    "                    \"rel\" : rel,\n",
    "                    \"labels\": batch[5],\n",
    "                }\n",
    "                outputs = model(**inputs)\n",
    "                tmp_eval_loss, logits = outputs[:2]\n",
    "\n",
    "                eval_loss += tmp_eval_loss.mean().item()\n",
    "            nb_eval_steps += 1\n",
    "            if preds is None:\n",
    "                preds = logits.detach().cpu().numpy()\n",
    "                out_label_ids = inputs[\"labels\"].detach().cpu().numpy()\n",
    "            else:\n",
    "                preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
    "                out_label_ids = np.append(out_label_ids, inputs[\"labels\"].detach().cpu().numpy(), axis=0)\n",
    "\n",
    "        eval_loss = eval_loss / nb_eval_steps\n",
    "        preds = np.argmax(preds, axis=1)\n",
    "        acc = simple_accuracy(preds, out_label_ids)\n",
    "        result = {\"eval_acc\": acc, \"eval_loss\": eval_loss}\n",
    "        results.update(result)\n",
    "\n",
    "        output_eval_file = os.path.join(eval_output_dir, \"is_test_\" + str(test).lower() + \"_eval_results.txt\")\n",
    "\n",
    "        with open(output_eval_file, \"w\") as writer:\n",
    "            logger.info(\"***** Eval results {} *****\".format(str(prefix) + \" is test:\" + str(test)))\n",
    "            writer.write(\"model           =%s\\n\" % str(model_name_or_path))\n",
    "            writer.write(\n",
    "                \"total batch size=%d\\n\"\n",
    "                % (\n",
    "                    per_gpu_train_batch_size\n",
    "                    * gradient_accumulation_steps\n",
    "                    * (torch.distributed.get_world_size() if local_rank != -1 else 1)\n",
    "                )\n",
    "            )\n",
    "            writer.write(\"train num epochs=%d\\n\" % num_train_epochs)\n",
    "            writer.write(\"fp16            =%s\\n\" % fp16)\n",
    "            writer.write(\"max seq length  =%d\\n\" % max_seq_length)\n",
    "            for key in sorted(result.keys()):\n",
    "                logger.info(\"  %s = %s\", key, str(result[key]))\n",
    "                writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_cache_examples(task, tokenizer, evaluate=False, test=False):\n",
    "    if local_rank not in [-1, 0]:\n",
    "        torch.distributed.barrier()  # Make sure only the first process in distributed training process the dataset, and the others will use the cache\n",
    "\n",
    "    processor = processors[task]()\n",
    "    # Load data features from cache or dataset file\n",
    "    if evaluate:\n",
    "        cached_mode = \"dev\"\n",
    "    elif test:\n",
    "        cached_mode = \"test\"\n",
    "    else:\n",
    "        cached_mode = \"train\"\n",
    "    assert not (evaluate and test)\n",
    "    cached_features_file = os.path.join(\n",
    "        data_dir,\n",
    "        \"cached_{}_{}_{}_{}\".format(\n",
    "            cached_mode,\n",
    "            list(filter(None, model_name_or_path.split(\"/\"))).pop(),\n",
    "            str(max_seq_length),\n",
    "            str(task),\n",
    "        ),\n",
    "    )\n",
    "    if os.path.exists(cached_features_file) and not overwrite_cache:\n",
    "        logger.info(\"Loading features from cached file %s\", cached_features_file)\n",
    "        features = torch.load(cached_features_file)\n",
    "    else:\n",
    "        logger.info(\"Creating features from dataset file at %s\", data_dir)\n",
    "        label_list = processor.get_labels()\n",
    "        if evaluate:\n",
    "            examples = processor.get_dev_examples(data_dir)\n",
    "        elif test:\n",
    "            examples = processor.get_test_examples(data_dir)\n",
    "        else:\n",
    "            examples = processor.get_train_examples(data_dir)\n",
    "        logger.info(\"Training number: %s\", str(len(examples)))\n",
    "        features = convert_examples_to_features(\n",
    "                    examples,\n",
    "                    label_list,\n",
    "                    max_seq_length,\n",
    "                    tokenizer,\n",
    "                    graph_encoder,\n",
    "                    kg,\n",
    "                    pad_on_left=bool(model_type in [\"xlnet\"]),\n",
    "                    pad_token_segment_id=4 if model_type in [\"xlnet\"] else 0,\n",
    "                    \n",
    "                )\n",
    "        #print(features[0].choices_features)\n",
    "        if local_rank in [-1, 0]:\n",
    "            logger.info(\"Saving features into cached file %s\", cached_features_file)\n",
    "            torch.save(features, cached_features_file)\n",
    "\n",
    "    if local_rank == 0:\n",
    "        torch.distributed.barrier()  # Make sure only the first process in distributed training process the dataset, and the others will use the cache\n",
    "\n",
    "    # Convert to Tensors and build dataset\n",
    "    all_input_ids = torch.tensor(select_field(features, \"input_ids\"), dtype=torch.long)\n",
    "    print(\"all_input_ids.shape {} \\n\".format(all_input_ids.shape))\n",
    "    all_input_mask = torch.tensor(select_field(features, \"attention_mask\"), dtype=torch.long)\n",
    "    print(\"all_input_mask.shape {} \\n\".format(all_input_mask.shape))\n",
    "    all_segment_ids = torch.tensor(select_field(features, \"token_type_ids\"), dtype =torch.long)\n",
    "    print(\"all_segment_ids.shape {} \\n\".format(all_segment_ids.shape))\n",
    "    all_prem_ids = torch.tensor(select_field(features,\"gpre\"), dtype = torch.long)\n",
    "    print(\"all_prem_ids.shape {} \\n\".format(all_prem_ids.shape))\n",
    "    all_hyp_ids = torch.tensor(select_field(features,\"ghyp\"),dtype = torch.long)\n",
    "    print(\"all_hyp_ids.shape {} \\n\".format(all_hyp_ids.shape))\n",
    "    all_label_ids = torch.tensor([f.label for f in features], dtype=torch.long)\n",
    "    print(\"all_label_ids.shape {} \\n\".format(all_label_ids.shape))\n",
    "    # to do changes here:\n",
    "    dataset = TensorDataset(all_input_ids,all_input_mask, all_segment_ids, all_prem_ids, all_hyp_ids, all_label_ids,)\n",
    "        \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = 'arc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data/arc/processed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"XLNet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['bert', 'XLNet', 'Roberta'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_CLASSES.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = 'xlnet-base-cased'\n",
    "do_lower_case = False # set true when using uncased model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ALL_MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['arc', 'race', 'swag'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processors.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = 'arc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"save/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_name = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_train = True\n",
    "do_eval = True\n",
    "do_test = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_during_training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_gpu_train_batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_gpu_eval_batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_accumulation_steps = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_decay = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_epsilon = 1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_grad_norm = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_epochs = 3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If > 0: set total number of training steps to perform. Override num_train_epochs.\n",
    "max_steps = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup_steps = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging_steps = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_steps = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_all_checkpoints = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_cuda = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite_output_dir = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite_cache = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp16 = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp16_opt_level = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_kg = \"data/conceptnet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ent_pre = 262"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ent_hyp = 83"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_rank = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_ip = \"\"\n",
    "server_port = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (\n",
    "        os.path.exists(output_dir)\n",
    "        and os.listdir(output_dir)\n",
    "        and do_train\n",
    "        and not overwrite_output_dir\n",
    "    ):\n",
    "        raise ValueError(\n",
    "            \"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\".format(\n",
    "                output_dir\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "if server_ip and server_port:\n",
    "        # Distant debugging - see https://code.visualstudio.com/docs/python/debugging#_attach-to-a-local-script\n",
    "        import ptvsd\n",
    "\n",
    "        print(\"Waiting for debugger attach\")\n",
    "        ptvsd.enable_attach(address=(server_ip, server_port), redirect_output=True)\n",
    "        ptvsd.wait_for_attach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "if local_rank == -1 or no_cuda:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() and not no_cuda else \"cpu\")\n",
    "        n_gpu = torch.cuda.device_count()\n",
    "    # Initializes the distributed backend which will take care of sychronizing nodes/GPUs\n",
    "else:\n",
    "    torch.cuda.set_device(local_rank)\n",
    "    device = torch.device(\"cuda\", local_rank)\n",
    "    torch.distributed.init_process_group(backend=\"nccl\")\n",
    "    n_gpu = 1\n",
    "device = device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/07/2020 14:18:03 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 4, distributed training: False, 16-bits training: False\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(\n",
    "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "        level=logging.INFO if local_rank in [-1, 0] else logging.WARN,\n",
    "    )\n",
    "logger.warning(\n",
    "    \"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\",\n",
    "    local_rank,\n",
    "    device,\n",
    "    n_gpu,\n",
    "    bool(local_rank != -1),\n",
    "    fp16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = task_name.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "if task_name not in processors:\n",
    "        raise ValueError(\"Task not found: %s\" % (task_name))\n",
    "processor = processors[task_name]()\n",
    "label_list = processor.get_labels()\n",
    "num_labels = len(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '1', '2', '3']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "if local_rank not in [-1, 0]:\n",
    "    torch.distributed.barrier() # Make sure only the first process in distributed training will download model and vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = model_type.lower()\n",
    "config_class, model_class, tokenizer_class = MODEL_CLASSES['XLNet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/07/2020 14:18:04 - INFO - filelock -   Lock 139974592477968 acquired on /home/abhishek/.cache/torch/transformers/c9cc6e53904f7f3679a31ec4af244f4419e25ebc8e71ebf8c558a31cbcf07fc8.ef1824921bc0786e97dc88d55eb17aabf18aac90f24bd34c0650529e7ba27d6f.lock\n",
      "01/07/2020 14:18:04 - INFO - filelock -   Lock 139974592477968 released on /home/abhishek/.cache/torch/transformers/c9cc6e53904f7f3679a31ec4af244f4419e25ebc8e71ebf8c558a31cbcf07fc8.ef1824921bc0786e97dc88d55eb17aabf18aac90f24bd34c0650529e7ba27d6f.lock\n",
      "01/07/2020 14:18:04 - INFO - src.transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-config.json from cache at /home/abhishek/.cache/torch/transformers/c9cc6e53904f7f3679a31ec4af244f4419e25ebc8e71ebf8c558a31cbcf07fc8.ef1824921bc0786e97dc88d55eb17aabf18aac90f24bd34c0650529e7ba27d6f\n",
      "01/07/2020 14:18:04 - INFO - src.transformers.configuration_utils -   Model config {\n",
      "  \"attn_type\": \"bi\",\n",
      "  \"bi_data\": false,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"clamp_len\": -1,\n",
      "  \"d_head\": 64,\n",
      "  \"d_inner\": 3072,\n",
      "  \"d_model\": 768,\n",
      "  \"do_sample\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"end_n_top\": 5,\n",
      "  \"eos_token_ids\": 0,\n",
      "  \"ff_activation\": \"gelu\",\n",
      "  \"finetuning_task\": \"arc\",\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"mem_len\": null,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_labels\": 4,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"reuse_len\": null,\n",
      "  \"same_length\": false,\n",
      "  \"start_n_top\": 5,\n",
      "  \"summary_activation\": \"tanh\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"last\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"untie_r\": true,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = config_class.from_pretrained(\n",
    "    config_name if config_name else model_name_or_path,\n",
    "    num_labels=num_labels,\n",
    "    finetuning_task=task_name,\n",
    "    cache_dir=cache_dir if cache_dir else None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_name=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ent_pre = 262\n",
    "max_ent_hyp = 83"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/07/2020 14:18:05 - INFO - filelock -   Lock 139974592503056 acquired on /home/abhishek/.cache/torch/transformers/dad589d582573df0293448af5109cb6981ca77239ed314e15ca63b7b8a318ddd.8b10bd978b5d01c21303cc761fc9ecd464419b3bf921864a355ba807cfbfafa8.lock\n",
      "01/07/2020 14:18:05 - INFO - filelock -   Lock 139974592503056 released on /home/abhishek/.cache/torch/transformers/dad589d582573df0293448af5109cb6981ca77239ed314e15ca63b7b8a318ddd.8b10bd978b5d01c21303cc761fc9ecd464419b3bf921864a355ba807cfbfafa8.lock\n",
      "01/07/2020 14:18:05 - INFO - src.transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-spiece.model from cache at /home/abhishek/.cache/torch/transformers/dad589d582573df0293448af5109cb6981ca77239ed314e15ca63b7b8a318ddd.8b10bd978b5d01c21303cc761fc9ecd464419b3bf921864a355ba807cfbfafa8\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tokenizer_class.from_pretrained(\n",
    "    tokenizer_name if tokenizer_name else model_name_or_path,\n",
    "    do_lower_case=do_lower_case,\n",
    "    cache_dir=cache_dir if cache_dir else None,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg = KG(path_to_kg)\n",
    "graph_encoder = GraphEncoder(kg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/07/2020 14:18:08 - INFO - filelock -   Lock 139973964894352 acquired on /home/abhishek/.cache/torch/transformers/24197ba0ce5dbfe23924431610704c88e2c0371afa49149360e4c823219ab474.7eac4fe898a021204e63c88c00ea68c60443c57f94b4bc3c02adbde6465745ac.lock\n",
      "01/07/2020 14:18:08 - INFO - filelock -   Lock 139973964894352 released on /home/abhishek/.cache/torch/transformers/24197ba0ce5dbfe23924431610704c88e2c0371afa49149360e4c823219ab474.7eac4fe898a021204e63c88c00ea68c60443c57f94b4bc3c02adbde6465745ac.lock\n",
      "01/07/2020 14:18:08 - INFO - src.transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-pytorch_model.bin from cache at /home/abhishek/.cache/torch/transformers/24197ba0ce5dbfe23924431610704c88e2c0371afa49149360e4c823219ab474.7eac4fe898a021204e63c88c00ea68c60443c57f94b4bc3c02adbde6465745ac\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_entities 1100498\n",
      "num_relations 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/07/2020 14:18:17 - INFO - src.transformers.modeling_utils -   Weights of XLNetForMultipleChoice not initialized from pretrained model: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias', 'logits_proj.weight', 'logits_proj.bias', 'gmatch.ent_emb.weight', 'gmatch.linear1.weight', 'gmatch.linear1.bias', 'EntAttn.linear.weight', 'EntAttn.linear.bias', 'RelAttn.linear.weight', 'RelAttn.linear.bias', 'RelAttn.linear2.weight', 'RelAttn.linear2.bias']\n",
      "01/07/2020 14:18:17 - INFO - src.transformers.modeling_utils -   Weights from pretrained model not used in XLNetForMultipleChoice: ['lm_loss.weight', 'lm_loss.bias']\n"
     ]
    }
   ],
   "source": [
    "model = model_class.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    kg = kg,\n",
    "    from_tf=bool(\".ckpt\" in model_name_or_path),\n",
    "    config = config,\n",
    "    cache_dir=cache_dir if cache_dir else None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "src.transformers.modeling_with_arc_xlnet.XLNetForMultipleChoice"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XLNetForMultipleChoice(\n",
       "  (transformer): XLNetModel(\n",
       "    (word_embedding): Embedding(32000, 768)\n",
       "    (layer): ModuleList(\n",
       "      (0): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (2): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (3): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (4): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (5): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (6): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (7): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (8): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (9): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (10): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (11): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (sequence_summary): SequenceSummary(\n",
       "    (summary): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "    (first_dropout): Identity()\n",
       "    (last_dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (logits_proj): Linear(in_features=768, out_features=1, bias=True)\n",
       "  (gmatch): Gmatch(\n",
       "    (ent_emb): Embedding(1100498, 100)\n",
       "    (linear1): Linear(in_features=400, out_features=100, bias=True)\n",
       "    (max_pool_pre): MaxPool2d(kernel_size=(262, 1), stride=(262, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (max_pool_hyp): MaxPool2d(kernel_size=(83, 1), stride=(83, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (avg_pool_pre): AvgPool2d(kernel_size=(262, 1), stride=(262, 1), padding=0)\n",
       "    (avg_pool_hyp): AvgPool2d(kernel_size=(83, 1), stride=(83, 1), padding=0)\n",
       "  )\n",
       "  (EntAttn): Entity_Attn(\n",
       "    (linear): Linear(in_features=768, out_features=100, bias=True)\n",
       "  )\n",
       "  (RelAttn): Relation_Attn(\n",
       "    (linear): Linear(in_features=768, out_features=10000, bias=True)\n",
       "    (linear2): Linear(in_features=10000, out_features=100, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/07/2020 14:18:20 - INFO - __main__ -   Training/evaluation parameters %s\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Training/evaluation parameters %s\")\n",
    "best_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/07/2020 14:18:20 - INFO - __main__ -   Creating features from dataset file at data/arc/processed\n",
      "01/07/2020 14:18:20 - INFO - utils_arc -   LOOKING AT data/arc/processed train\n",
      "01/07/2020 14:18:20 - INFO - __main__ -   Training number: 3353\n",
      "01/07/2020 14:18:56 - INFO - __main__ -   Saving features into cached file data/arc/processed/cached_train_xlnet-base-cased_512_arc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_input_ids.shape torch.Size([3353, 4, 512]) \n",
      "\n",
      "all_input_mask.shape torch.Size([3353, 4, 512]) \n",
      "\n",
      "all_segment_ids.shape torch.Size([3353, 4, 512]) \n",
      "\n",
      "all_prem_ids.shape torch.Size([3353, 4, 262]) \n",
      "\n",
      "all_hyp_ids.shape torch.Size([3353, 4, 83]) \n",
      "\n",
      "all_label_ids.shape torch.Size([3353]) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/07/2020 14:19:06 - INFO - __main__ -   ******* Running Training *********\n",
      "01/07/2020 14:19:06 - INFO - __main__ -    Num Examples = 3353\n",
      "01/07/2020 14:19:06 - INFO - __main__ -    Num Epochs = 3\n",
      "01/07/2020 14:19:06 - INFO - __main__ -    Instantaneous batch size per GPU = 1\n",
      "01/07/2020 14:19:06 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "01/07/2020 14:19:06 - INFO - __main__ -    Gradient Accumulation steps = 1\n",
      "01/07/2020 14:19:06 - INFO - __main__ -    Total optimization steps =2517\n",
      "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Iteration:   0%|          | 0/839 [00:00<?, ?it/s]\u001b[A/home/abhishek/anaconda3/envs/QA/lib/python3.7/site-packages/torch/nn/functional.py:1280: UserWarning: `eps` parameter is deprecated and has no effect.\n",
      "  warnings.warn(\"`eps` parameter is deprecated and has no effect.\")\n",
      "/home/abhishek/anaconda3/envs/QA/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "\n",
      "Iteration:   0%|          | 1/839 [00:06<1:35:25,  6.83s/it]\u001b[A\n",
      "Iteration:   0%|          | 2/839 [00:07<1:09:40,  4.99s/it]\u001b[A\n",
      "Iteration:   0%|          | 3/839 [00:08<51:38,  3.71s/it]  \u001b[A\n",
      "Iteration:   0%|          | 4/839 [00:08<39:01,  2.80s/it]\u001b[A\n",
      "Iteration:   1%|          | 5/839 [00:09<30:22,  2.18s/it]\u001b[A\n",
      "Iteration:   1%|          | 6/839 [00:10<24:16,  1.75s/it]\u001b[A\n",
      "Iteration:   1%|          | 7/839 [00:11<19:56,  1.44s/it]\u001b[A\n",
      "Iteration:   1%|          | 8/839 [00:11<16:54,  1.22s/it]\u001b[A\n",
      "Iteration:   1%|          | 9/839 [00:12<14:48,  1.07s/it]\u001b[A\n",
      "Iteration:   1%|          | 10/839 [00:13<13:21,  1.03it/s]\u001b[A\n",
      "Iteration:   1%|▏         | 11/839 [00:14<12:21,  1.12it/s]\u001b[A\n",
      "Iteration:   1%|▏         | 12/839 [00:14<11:38,  1.18it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 13/839 [00:15<11:03,  1.25it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 14/839 [00:16<10:47,  1.27it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 15/839 [00:16<10:29,  1.31it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 16/839 [00:17<10:13,  1.34it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 17/839 [00:18<10:04,  1.36it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 18/839 [00:19<09:54,  1.38it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 19/839 [00:19<09:49,  1.39it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 20/839 [00:20<09:48,  1.39it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 21/839 [00:21<09:50,  1.39it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 22/839 [00:21<09:48,  1.39it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 23/839 [00:22<09:45,  1.39it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 24/839 [00:23<09:42,  1.40it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 25/839 [00:24<09:44,  1.39it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 26/839 [00:24<09:43,  1.39it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 27/839 [00:25<09:48,  1.38it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 28/839 [00:26<09:43,  1.39it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 29/839 [00:26<09:38,  1.40it/s]\u001b[A\n",
      "Iteration:   4%|▎         | 30/839 [00:27<09:34,  1.41it/s]\u001b[A\n",
      "Iteration:   4%|▎         | 31/839 [00:28<09:33,  1.41it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 32/839 [00:29<09:31,  1.41it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 33/839 [00:29<09:31,  1.41it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 34/839 [00:30<09:30,  1.41it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 35/839 [00:31<09:35,  1.40it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 36/839 [00:31<09:34,  1.40it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 37/839 [00:32<09:27,  1.41it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 38/839 [00:33<09:25,  1.42it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 39/839 [00:33<09:24,  1.42it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 40/839 [00:34<09:29,  1.40it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 41/839 [00:35<09:27,  1.41it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 42/839 [00:36<09:28,  1.40it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 43/839 [00:36<09:27,  1.40it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 44/839 [00:37<09:26,  1.40it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 45/839 [00:38<09:26,  1.40it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 46/839 [00:38<09:25,  1.40it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 47/839 [00:39<09:25,  1.40it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 48/839 [00:40<09:24,  1.40it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 49/839 [00:41<09:24,  1.40it/s]\u001b[A01/07/2020 14:19:48 - INFO - __main__ -   Average loss: 1.4890675687789916 at global step: 50\n",
      "\n",
      "Iteration:   6%|▌         | 50/839 [00:41<09:24,  1.40it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 51/839 [00:42<09:21,  1.40it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 52/839 [00:43<09:20,  1.40it/s]\u001b[A\n",
      "Iteration:   6%|▋         | 53/839 [00:43<09:21,  1.40it/s]\u001b[A\n",
      "Iteration:   6%|▋         | 54/839 [00:44<09:21,  1.40it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 55/839 [00:45<09:18,  1.40it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 56/839 [00:46<09:23,  1.39it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 57/839 [00:46<09:18,  1.40it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 58/839 [00:47<09:18,  1.40it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 59/839 [00:48<09:16,  1.40it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 60/839 [00:48<09:18,  1.39it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 61/839 [00:49<09:16,  1.40it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 62/839 [00:50<09:14,  1.40it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 63/839 [00:51<09:14,  1.40it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 64/839 [00:51<09:13,  1.40it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 65/839 [00:52<09:09,  1.41it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 66/839 [00:53<09:07,  1.41it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 67/839 [00:53<09:11,  1.40it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 68/839 [00:54<09:10,  1.40it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 69/839 [00:55<09:07,  1.41it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 70/839 [00:56<09:07,  1.41it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 71/839 [00:56<09:06,  1.40it/s]\u001b[A\n",
      "Iteration:   9%|▊         | 72/839 [00:57<09:02,  1.41it/s]\u001b[A\n",
      "Iteration:   9%|▊         | 73/839 [00:58<08:59,  1.42it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 74/839 [00:58<08:59,  1.42it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 75/839 [00:59<09:03,  1.41it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 76/839 [01:00<09:02,  1.41it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 77/839 [01:01<09:01,  1.41it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 78/839 [01:01<09:00,  1.41it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 79/839 [01:02<09:00,  1.41it/s]\u001b[A\n",
      "Iteration:  10%|▉         | 80/839 [01:03<08:59,  1.41it/s]\u001b[A\n",
      "Iteration:  10%|▉         | 81/839 [01:03<08:57,  1.41it/s]\u001b[A\n",
      "Iteration:  10%|▉         | 82/839 [01:04<09:06,  1.39it/s]\u001b[A\n",
      "Iteration:  10%|▉         | 83/839 [01:05<09:11,  1.37it/s]\u001b[A\n",
      "Iteration:  10%|█         | 84/839 [01:06<09:12,  1.37it/s]\u001b[A\n",
      "Iteration:  10%|█         | 85/839 [01:06<09:11,  1.37it/s]\u001b[A\n",
      "Iteration:  10%|█         | 86/839 [01:07<09:13,  1.36it/s]\u001b[A\n",
      "Iteration:  10%|█         | 87/839 [01:08<09:11,  1.36it/s]\u001b[A\n",
      "Iteration:  10%|█         | 88/839 [01:09<09:06,  1.37it/s]\u001b[A\n",
      "Iteration:  11%|█         | 89/839 [01:09<09:00,  1.39it/s]\u001b[A\n",
      "Iteration:  11%|█         | 90/839 [01:10<08:57,  1.39it/s]\u001b[A\n",
      "Iteration:  11%|█         | 91/839 [01:11<08:54,  1.40it/s]\u001b[A\n",
      "Iteration:  11%|█         | 92/839 [01:11<08:51,  1.40it/s]\u001b[A\n",
      "Iteration:  11%|█         | 93/839 [01:12<08:48,  1.41it/s]\u001b[A\n",
      "Iteration:  11%|█         | 94/839 [01:13<08:46,  1.41it/s]\u001b[A\n",
      "Iteration:  11%|█▏        | 95/839 [01:14<08:46,  1.41it/s]\u001b[A\n",
      "Iteration:  11%|█▏        | 96/839 [01:14<08:46,  1.41it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 97/839 [01:15<08:46,  1.41it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 98/839 [01:16<08:53,  1.39it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 99/839 [01:16<08:54,  1.38it/s]\u001b[A01/07/2020 14:20:24 - INFO - __main__ -   Average loss: 1.4178458309173585 at global step: 100\n",
      "\n",
      "Iteration:  12%|█▏        | 100/839 [01:17<08:52,  1.39it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 101/839 [01:18<08:51,  1.39it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 102/839 [01:19<08:47,  1.40it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 103/839 [01:19<08:46,  1.40it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 104/839 [01:20<08:48,  1.39it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 105/839 [01:21<08:46,  1.39it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 106/839 [01:21<08:44,  1.40it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 107/839 [01:22<08:42,  1.40it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 108/839 [01:23<08:41,  1.40it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  13%|█▎        | 109/839 [01:24<08:38,  1.41it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 110/839 [01:24<08:37,  1.41it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 111/839 [01:25<08:37,  1.41it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 112/839 [01:26<08:39,  1.40it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 113/839 [01:26<08:36,  1.40it/s]\u001b[A\n",
      "Iteration:  14%|█▎        | 114/839 [01:27<08:35,  1.41it/s]\u001b[A\n",
      "Iteration:  14%|█▎        | 115/839 [01:28<08:35,  1.40it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 116/839 [01:29<08:37,  1.40it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 117/839 [01:29<08:37,  1.39it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 118/839 [01:30<08:37,  1.39it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 119/839 [01:31<08:36,  1.39it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 120/839 [01:31<08:36,  1.39it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 121/839 [01:32<08:33,  1.40it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 122/839 [01:33<08:33,  1.40it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 123/839 [01:34<08:32,  1.40it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 124/839 [01:34<08:32,  1.39it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 125/839 [01:35<08:32,  1.39it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 126/839 [01:36<08:30,  1.40it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 127/839 [01:36<08:27,  1.40it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 128/839 [01:37<08:28,  1.40it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 129/839 [01:38<08:29,  1.39it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 130/839 [01:39<08:32,  1.38it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 131/839 [01:39<08:28,  1.39it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 132/839 [01:40<08:24,  1.40it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 133/839 [01:41<08:23,  1.40it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 134/839 [01:41<08:21,  1.40it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 135/839 [01:42<08:22,  1.40it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 136/839 [01:43<08:23,  1.40it/s]\u001b[A\n",
      "Iteration:  16%|█▋        | 137/839 [01:44<08:21,  1.40it/s]\u001b[A\n",
      "Iteration:  16%|█▋        | 138/839 [01:44<08:23,  1.39it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 139/839 [01:45<08:24,  1.39it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 140/839 [01:46<08:22,  1.39it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 141/839 [01:46<08:20,  1.39it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 142/839 [01:47<08:24,  1.38it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 143/839 [01:48<08:23,  1.38it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 144/839 [01:49<08:23,  1.38it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 145/839 [01:49<08:25,  1.37it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 146/839 [01:50<08:23,  1.38it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 147/839 [01:51<08:22,  1.38it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 148/839 [01:52<08:17,  1.39it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 149/839 [01:52<08:14,  1.39it/s]\u001b[A01/07/2020 14:21:00 - INFO - __main__ -   Average loss: 1.452704312801361 at global step: 150\n",
      "\n",
      "Iteration:  18%|█▊        | 150/839 [01:53<08:13,  1.39it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 151/839 [01:54<08:22,  1.37it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 152/839 [01:54<08:21,  1.37it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 153/839 [01:55<08:23,  1.36it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 154/839 [01:56<08:23,  1.36it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 155/839 [01:57<08:21,  1.36it/s]\u001b[A\n",
      "Iteration:  19%|█▊        | 156/839 [01:57<08:18,  1.37it/s]\u001b[A\n",
      "Iteration:  19%|█▊        | 157/839 [01:58<08:13,  1.38it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 158/839 [01:59<08:10,  1.39it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 159/839 [01:59<08:06,  1.40it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 160/839 [02:00<08:05,  1.40it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 161/839 [02:01<08:04,  1.40it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 162/839 [02:02<08:17,  1.36it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 163/839 [02:02<08:17,  1.36it/s]\u001b[A\n",
      "Iteration:  20%|█▉        | 164/839 [02:03<08:22,  1.34it/s]\u001b[A\n",
      "Iteration:  20%|█▉        | 165/839 [02:04<08:22,  1.34it/s]\u001b[A\n",
      "Iteration:  20%|█▉        | 166/839 [02:05<08:22,  1.34it/s]\u001b[A\n",
      "Iteration:  20%|█▉        | 167/839 [02:05<08:15,  1.36it/s]\u001b[A\n",
      "Iteration:  20%|██        | 168/839 [02:06<08:19,  1.34it/s]\u001b[A\n",
      "Iteration:  20%|██        | 169/839 [02:07<08:12,  1.36it/s]\u001b[A\n",
      "Iteration:  20%|██        | 170/839 [02:08<08:06,  1.37it/s]\u001b[A\n",
      "Iteration:  20%|██        | 171/839 [02:08<08:03,  1.38it/s]\u001b[A\n",
      "Iteration:  21%|██        | 172/839 [02:09<08:00,  1.39it/s]\u001b[A\n",
      "Iteration:  21%|██        | 173/839 [02:10<07:59,  1.39it/s]\u001b[A\n",
      "Iteration:  21%|██        | 174/839 [02:10<07:57,  1.39it/s]\u001b[A\n",
      "Iteration:  21%|██        | 175/839 [02:11<07:55,  1.40it/s]\u001b[A\n",
      "Iteration:  21%|██        | 176/839 [02:12<07:56,  1.39it/s]\u001b[A\n",
      "Iteration:  21%|██        | 177/839 [02:13<07:55,  1.39it/s]\u001b[A\n",
      "Iteration:  21%|██        | 178/839 [02:13<07:54,  1.39it/s]\u001b[A\n",
      "Iteration:  21%|██▏       | 179/839 [02:14<07:53,  1.39it/s]\u001b[A\n",
      "Iteration:  21%|██▏       | 180/839 [02:15<07:55,  1.39it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 181/839 [02:16<07:58,  1.37it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 182/839 [02:16<07:56,  1.38it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 183/839 [02:17<07:51,  1.39it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 184/839 [02:18<07:59,  1.37it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 185/839 [02:18<08:00,  1.36it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 186/839 [02:19<07:57,  1.37it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 187/839 [02:20<07:53,  1.38it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 188/839 [02:21<07:51,  1.38it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 189/839 [02:21<07:47,  1.39it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 190/839 [02:22<07:45,  1.39it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 191/839 [02:23<07:43,  1.40it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 192/839 [02:23<07:42,  1.40it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 193/839 [02:24<07:42,  1.40it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 194/839 [02:25<07:40,  1.40it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 195/839 [02:26<07:37,  1.41it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 196/839 [02:26<07:38,  1.40it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 197/839 [02:27<07:36,  1.41it/s]\u001b[A\n",
      "Iteration:  24%|██▎       | 198/839 [02:28<07:39,  1.40it/s]\u001b[A\n",
      "Iteration:  24%|██▎       | 199/839 [02:28<07:39,  1.39it/s]\u001b[A01/07/2020 14:21:36 - INFO - __main__ -   Average loss: 1.5057471764087678 at global step: 200\n",
      "\n",
      "Iteration:  24%|██▍       | 200/839 [02:29<07:47,  1.37it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 201/839 [02:30<07:43,  1.38it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 202/839 [02:31<07:48,  1.36it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 203/839 [02:31<07:46,  1.36it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 204/839 [02:32<07:45,  1.36it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 205/839 [02:33<07:42,  1.37it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 206/839 [02:34<07:41,  1.37it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 207/839 [02:34<07:36,  1.38it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 208/839 [02:35<07:34,  1.39it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 209/839 [02:36<07:32,  1.39it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 210/839 [02:36<07:31,  1.39it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 211/839 [02:37<07:29,  1.40it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 212/839 [02:38<07:27,  1.40it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 213/839 [02:39<07:26,  1.40it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 214/839 [02:39<07:25,  1.40it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 215/839 [02:40<07:26,  1.40it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 216/839 [02:41<07:26,  1.40it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 217/839 [02:41<07:25,  1.40it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 218/839 [02:42<07:23,  1.40it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 219/839 [02:43<07:22,  1.40it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 220/839 [02:44<07:22,  1.40it/s]\u001b[A\n",
      "Iteration:  26%|██▋       | 221/839 [02:44<07:22,  1.40it/s]\u001b[A\n",
      "Iteration:  26%|██▋       | 222/839 [02:45<07:22,  1.39it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 223/839 [02:46<07:20,  1.40it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 224/839 [02:46<07:19,  1.40it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 225/839 [02:47<07:18,  1.40it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 226/839 [02:48<07:17,  1.40it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 227/839 [02:49<07:17,  1.40it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 228/839 [02:49<07:16,  1.40it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 229/839 [02:50<07:15,  1.40it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 230/839 [02:51<07:13,  1.40it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 231/839 [02:51<07:12,  1.40it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 232/839 [02:52<07:19,  1.38it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 233/839 [02:53<07:19,  1.38it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  28%|██▊       | 234/839 [02:54<07:21,  1.37it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 235/839 [02:54<07:19,  1.37it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 236/839 [02:55<07:16,  1.38it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 237/839 [02:56<07:14,  1.38it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 238/839 [02:57<07:11,  1.39it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 239/839 [02:57<07:09,  1.40it/s]\u001b[A\n",
      "Iteration:  29%|██▊       | 240/839 [02:58<07:08,  1.40it/s]\u001b[A\n",
      "Iteration:  29%|██▊       | 241/839 [02:59<07:08,  1.40it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 242/839 [02:59<07:07,  1.40it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 243/839 [03:00<07:06,  1.40it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 244/839 [03:01<07:07,  1.39it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 245/839 [03:02<07:05,  1.39it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 246/839 [03:02<07:05,  1.40it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 247/839 [03:03<07:07,  1.38it/s]\u001b[A\n",
      "Iteration:  30%|██▉       | 248/839 [03:04<07:05,  1.39it/s]\u001b[A\n",
      "Iteration:  30%|██▉       | 249/839 [03:04<07:04,  1.39it/s]\u001b[A01/07/2020 14:22:12 - INFO - __main__ -   Average loss: 1.404422128200531 at global step: 250\n",
      "\n",
      "Iteration:  30%|██▉       | 250/839 [03:05<07:11,  1.37it/s]\u001b[A\n",
      "Iteration:  30%|██▉       | 251/839 [03:06<07:11,  1.36it/s]\u001b[A\n",
      "Iteration:  30%|███       | 252/839 [03:07<07:17,  1.34it/s]\u001b[A\n",
      "Iteration:  30%|███       | 253/839 [03:07<07:16,  1.34it/s]\u001b[A\n",
      "Iteration:  30%|███       | 254/839 [03:08<07:17,  1.34it/s]\u001b[A\n",
      "Iteration:  30%|███       | 255/839 [03:09<07:12,  1.35it/s]\u001b[A\n",
      "Iteration:  31%|███       | 256/839 [03:10<07:12,  1.35it/s]\u001b[A\n",
      "Iteration:  31%|███       | 257/839 [03:10<07:09,  1.35it/s]\u001b[A\n",
      "Iteration:  31%|███       | 258/839 [03:11<07:07,  1.36it/s]\u001b[A\n",
      "Iteration:  31%|███       | 259/839 [03:12<07:05,  1.36it/s]\u001b[A\n",
      "Iteration:  31%|███       | 260/839 [03:13<07:01,  1.37it/s]\u001b[A\n",
      "Iteration:  31%|███       | 261/839 [03:13<06:58,  1.38it/s]\u001b[A\n",
      "Iteration:  31%|███       | 262/839 [03:14<06:59,  1.38it/s]\u001b[A\n",
      "Iteration:  31%|███▏      | 263/839 [03:15<06:55,  1.39it/s]\u001b[A\n",
      "Iteration:  31%|███▏      | 264/839 [03:15<06:53,  1.39it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 265/839 [03:16<07:01,  1.36it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 266/839 [03:17<07:02,  1.35it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 267/839 [03:18<06:59,  1.36it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 268/839 [03:18<06:55,  1.38it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 269/839 [03:19<06:53,  1.38it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 270/839 [03:20<06:52,  1.38it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 271/839 [03:21<06:48,  1.39it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 272/839 [03:21<06:46,  1.39it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 273/839 [03:22<06:46,  1.39it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 274/839 [03:23<06:44,  1.40it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 275/839 [03:23<06:43,  1.40it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 276/839 [03:24<06:43,  1.40it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 277/839 [03:25<06:41,  1.40it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 278/839 [03:26<06:39,  1.40it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 279/839 [03:26<06:39,  1.40it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 280/839 [03:27<06:38,  1.40it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 281/839 [03:28<06:38,  1.40it/s]\u001b[A\n",
      "Iteration:  34%|███▎      | 282/839 [03:28<06:41,  1.39it/s]\u001b[A\n",
      "Iteration:  34%|███▎      | 283/839 [03:29<06:45,  1.37it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 284/839 [03:30<06:42,  1.38it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 285/839 [03:31<06:39,  1.39it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 286/839 [03:31<06:38,  1.39it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 287/839 [03:32<06:34,  1.40it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 288/839 [03:33<06:36,  1.39it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 289/839 [03:33<06:35,  1.39it/s]\u001b[A\n",
      "Iteration:  35%|███▍      | 290/839 [03:34<06:36,  1.38it/s]\u001b[A\n",
      "Iteration:  35%|███▍      | 291/839 [03:35<06:36,  1.38it/s]\u001b[A\n",
      "Iteration:  35%|███▍      | 292/839 [03:36<06:40,  1.36it/s]\u001b[A\n",
      "Iteration:  35%|███▍      | 293/839 [03:36<06:39,  1.37it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 294/839 [03:37<06:38,  1.37it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 295/839 [03:38<06:38,  1.37it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 296/839 [03:39<06:35,  1.37it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 297/839 [03:39<06:33,  1.38it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 298/839 [03:40<06:33,  1.37it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 299/839 [03:41<06:30,  1.38it/s]\u001b[A01/07/2020 14:22:48 - INFO - __main__ -   Average loss: 1.45770738363266 at global step: 300\n",
      "\n",
      "Iteration:  36%|███▌      | 300/839 [03:41<06:30,  1.38it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 301/839 [03:42<06:28,  1.38it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 302/839 [03:43<06:27,  1.38it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 303/839 [03:44<06:25,  1.39it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 304/839 [03:44<06:25,  1.39it/s]\u001b[A\n",
      "Iteration:  36%|███▋      | 305/839 [03:45<06:23,  1.39it/s]\u001b[A\n",
      "Iteration:  36%|███▋      | 306/839 [03:46<06:52,  1.29it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 307/839 [03:47<06:42,  1.32it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 308/839 [03:47<06:34,  1.35it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 309/839 [03:48<06:27,  1.37it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 310/839 [03:49<06:24,  1.38it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 311/839 [03:50<06:21,  1.38it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 312/839 [03:50<06:24,  1.37it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 313/839 [03:51<06:21,  1.38it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 314/839 [03:52<06:18,  1.39it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 315/839 [03:52<06:17,  1.39it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 316/839 [03:53<06:20,  1.38it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 317/839 [03:54<06:18,  1.38it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 318/839 [03:55<06:16,  1.38it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 319/839 [03:55<06:16,  1.38it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 320/839 [03:56<06:14,  1.39it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 321/839 [03:57<06:15,  1.38it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 322/839 [03:58<06:13,  1.38it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 323/839 [03:58<06:12,  1.38it/s]\u001b[A\n",
      "Iteration:  39%|███▊      | 324/839 [03:59<06:11,  1.39it/s]\u001b[A\n",
      "Iteration:  39%|███▊      | 325/839 [04:00<06:15,  1.37it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 326/839 [04:00<06:16,  1.36it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 327/839 [04:01<06:19,  1.35it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 328/839 [04:02<06:15,  1.36it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 329/839 [04:03<06:12,  1.37it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 330/839 [04:03<06:11,  1.37it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 331/839 [04:04<06:07,  1.38it/s]\u001b[A\n",
      "Iteration:  40%|███▉      | 332/839 [04:05<06:02,  1.40it/s]\u001b[A\n",
      "Iteration:  40%|███▉      | 333/839 [04:05<06:00,  1.40it/s]\u001b[A\n",
      "Iteration:  40%|███▉      | 334/839 [04:06<05:59,  1.40it/s]\u001b[A\n",
      "Iteration:  40%|███▉      | 335/839 [04:07<05:58,  1.41it/s]\u001b[A\n",
      "Iteration:  40%|████      | 336/839 [04:08<05:58,  1.40it/s]\u001b[A\n",
      "Iteration:  40%|████      | 337/839 [04:08<05:58,  1.40it/s]\u001b[A\n",
      "Iteration:  40%|████      | 338/839 [04:09<05:56,  1.40it/s]\u001b[A\n",
      "Iteration:  40%|████      | 339/839 [04:10<05:56,  1.40it/s]\u001b[A\n",
      "Iteration:  41%|████      | 340/839 [04:10<05:57,  1.40it/s]\u001b[A\n",
      "Iteration:  41%|████      | 341/839 [04:11<05:56,  1.40it/s]\u001b[A\n",
      "Iteration:  41%|████      | 342/839 [04:12<05:55,  1.40it/s]\u001b[A\n",
      "Iteration:  41%|████      | 343/839 [04:13<05:55,  1.39it/s]\u001b[A\n",
      "Iteration:  41%|████      | 344/839 [04:13<05:56,  1.39it/s]\u001b[A\n",
      "Iteration:  41%|████      | 345/839 [04:14<05:54,  1.39it/s]\u001b[A\n",
      "Iteration:  41%|████      | 346/839 [04:15<05:53,  1.40it/s]\u001b[A\n",
      "Iteration:  41%|████▏     | 347/839 [04:16<05:55,  1.38it/s]\u001b[A\n",
      "Iteration:  41%|████▏     | 348/839 [04:16<05:54,  1.38it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 349/839 [04:17<05:53,  1.39it/s]\u001b[A01/07/2020 14:23:25 - INFO - __main__ -   Average loss: 1.4880651128292084 at global step: 350\n",
      "\n",
      "Iteration:  42%|████▏     | 350/839 [04:18<05:58,  1.37it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 351/839 [04:18<05:54,  1.37it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 352/839 [04:19<05:53,  1.38it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 353/839 [04:20<05:51,  1.38it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 354/839 [04:21<05:49,  1.39it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 355/839 [04:21<05:47,  1.39it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 356/839 [04:22<05:46,  1.39it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  43%|████▎     | 357/839 [04:23<05:47,  1.39it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 358/839 [04:23<05:47,  1.38it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 359/839 [04:24<05:46,  1.39it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 360/839 [04:25<05:46,  1.38it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 361/839 [04:26<05:47,  1.38it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 362/839 [04:26<05:45,  1.38it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 363/839 [04:27<05:41,  1.39it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 364/839 [04:28<05:40,  1.40it/s]\u001b[A\n",
      "Iteration:  44%|████▎     | 365/839 [04:28<05:38,  1.40it/s]\u001b[A\n",
      "Iteration:  44%|████▎     | 366/839 [04:29<05:38,  1.40it/s]\u001b[A\n",
      "Iteration:  44%|████▎     | 367/839 [04:30<05:40,  1.39it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 368/839 [04:31<05:44,  1.37it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 369/839 [04:31<05:44,  1.37it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 370/839 [04:32<05:45,  1.36it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 371/839 [04:33<05:43,  1.36it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 372/839 [04:34<05:41,  1.37it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 373/839 [04:34<05:37,  1.38it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 374/839 [04:35<05:35,  1.39it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 375/839 [04:36<05:33,  1.39it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 376/839 [04:36<05:32,  1.39it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 377/839 [04:37<05:31,  1.39it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 378/839 [04:38<05:30,  1.40it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 379/839 [04:39<05:31,  1.39it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 380/839 [04:39<05:29,  1.39it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 381/839 [04:40<05:28,  1.40it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 382/839 [04:41<05:27,  1.39it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 383/839 [04:42<05:27,  1.39it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 384/839 [04:42<05:25,  1.40it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 385/839 [04:43<05:24,  1.40it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 386/839 [04:44<05:28,  1.38it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 387/839 [04:44<05:27,  1.38it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 388/839 [04:45<05:25,  1.38it/s]\u001b[A\n",
      "Iteration:  46%|████▋     | 389/839 [04:46<05:23,  1.39it/s]\u001b[A\n",
      "Iteration:  46%|████▋     | 390/839 [04:47<05:23,  1.39it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 391/839 [04:47<05:25,  1.38it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 392/839 [04:48<05:24,  1.38it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 393/839 [04:49<05:22,  1.38it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 394/839 [04:49<05:20,  1.39it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 395/839 [04:50<05:22,  1.38it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 396/839 [04:51<05:19,  1.39it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 397/839 [04:52<05:17,  1.39it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 398/839 [04:52<05:16,  1.39it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 399/839 [04:53<05:14,  1.40it/s]\u001b[A01/07/2020 14:24:01 - INFO - __main__ -   Average loss: 1.4273552942276 at global step: 400\n",
      "\n",
      "Iteration:  48%|████▊     | 400/839 [04:54<05:14,  1.39it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 401/839 [04:54<05:14,  1.39it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 402/839 [04:55<05:13,  1.39it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 403/839 [04:56<05:12,  1.40it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 404/839 [04:57<05:14,  1.38it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 405/839 [04:57<05:14,  1.38it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 406/839 [04:58<05:12,  1.39it/s]\u001b[A\n",
      "Iteration:  49%|████▊     | 407/839 [04:59<05:10,  1.39it/s]\u001b[A\n",
      "Iteration:  49%|████▊     | 408/839 [05:00<05:07,  1.40it/s]\u001b[A\n",
      "Iteration:  49%|████▊     | 409/839 [05:00<05:06,  1.40it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 410/839 [05:01<05:04,  1.41it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 411/839 [05:02<05:02,  1.42it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 412/839 [05:02<05:00,  1.42it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 413/839 [05:03<05:00,  1.42it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 414/839 [05:04<05:01,  1.41it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 415/839 [05:04<05:01,  1.41it/s]\u001b[A\n",
      "Iteration:  50%|████▉     | 416/839 [05:05<05:07,  1.38it/s]\u001b[A\n",
      "Iteration:  50%|████▉     | 417/839 [05:06<05:07,  1.37it/s]\u001b[A\n",
      "Iteration:  50%|████▉     | 418/839 [05:07<05:12,  1.35it/s]\u001b[A\n",
      "Iteration:  50%|████▉     | 419/839 [05:07<05:12,  1.34it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 420/839 [05:08<05:08,  1.36it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 421/839 [05:09<05:06,  1.36it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 422/839 [05:10<05:07,  1.35it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 423/839 [05:10<05:05,  1.36it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 424/839 [05:11<05:05,  1.36it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 425/839 [05:12<05:03,  1.36it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 426/839 [05:13<04:59,  1.38it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 427/839 [05:13<04:58,  1.38it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 428/839 [05:14<04:57,  1.38it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 429/839 [05:15<04:57,  1.38it/s]\u001b[A\n",
      "Iteration:  51%|█████▏    | 430/839 [05:15<04:59,  1.36it/s]\u001b[A\n",
      "Iteration:  51%|█████▏    | 431/839 [05:16<04:57,  1.37it/s]\u001b[A\n",
      "Iteration:  51%|█████▏    | 432/839 [05:17<04:55,  1.38it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 433/839 [05:18<04:56,  1.37it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 434/839 [05:18<04:54,  1.38it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 435/839 [05:19<04:51,  1.39it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 436/839 [05:20<04:51,  1.38it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 437/839 [05:21<04:49,  1.39it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 438/839 [05:21<04:49,  1.38it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 439/839 [05:22<04:50,  1.37it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 440/839 [05:23<04:48,  1.38it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 441/839 [05:23<04:46,  1.39it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 442/839 [05:24<04:48,  1.37it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 443/839 [05:25<04:47,  1.38it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 444/839 [05:26<04:45,  1.39it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 445/839 [05:26<04:44,  1.39it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 446/839 [05:27<04:42,  1.39it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 447/839 [05:28<04:41,  1.39it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 448/839 [05:28<04:42,  1.39it/s]\u001b[A\n",
      "Iteration:  54%|█████▎    | 449/839 [05:29<04:43,  1.38it/s]\u001b[A01/07/2020 14:24:37 - INFO - __main__ -   Average loss: 1.4909530305862426 at global step: 450\n",
      "\n",
      "Iteration:  54%|█████▎    | 450/839 [05:30<04:41,  1.38it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 451/839 [05:31<04:43,  1.37it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 452/839 [05:31<04:42,  1.37it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 453/839 [05:32<04:40,  1.37it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 454/839 [05:33<04:38,  1.38it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 455/839 [05:34<04:37,  1.38it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 456/839 [05:34<04:36,  1.39it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 457/839 [05:35<04:34,  1.39it/s]\u001b[A\n",
      "Iteration:  55%|█████▍    | 458/839 [05:36<04:34,  1.39it/s]\u001b[A\n",
      "Iteration:  55%|█████▍    | 459/839 [05:36<04:37,  1.37it/s]\u001b[A\n",
      "Iteration:  55%|█████▍    | 460/839 [05:37<04:36,  1.37it/s]\u001b[A\n",
      "Iteration:  55%|█████▍    | 461/839 [05:38<04:34,  1.38it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 462/839 [05:39<04:43,  1.33it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 463/839 [05:39<04:39,  1.35it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 464/839 [05:40<04:39,  1.34it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 465/839 [05:41<04:37,  1.35it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 466/839 [05:42<04:38,  1.34it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 467/839 [05:42<04:35,  1.35it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 468/839 [05:43<04:36,  1.34it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 469/839 [05:44<04:33,  1.35it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 470/839 [05:45<04:31,  1.36it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 471/839 [05:45<04:27,  1.37it/s]\u001b[A\n",
      "Iteration:  56%|█████▋    | 472/839 [05:46<04:26,  1.38it/s]\u001b[A\n",
      "Iteration:  56%|█████▋    | 473/839 [05:47<04:24,  1.38it/s]\u001b[A\n",
      "Iteration:  56%|█████▋    | 474/839 [05:48<04:23,  1.39it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 475/839 [05:48<04:22,  1.39it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 476/839 [05:49<04:20,  1.39it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 477/839 [05:50<04:24,  1.37it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 478/839 [05:50<04:22,  1.38it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 479/839 [05:51<04:21,  1.38it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 480/839 [05:52<04:21,  1.37it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 481/839 [05:53<04:19,  1.38it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  57%|█████▋    | 482/839 [05:53<04:18,  1.38it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 483/839 [05:54<04:15,  1.39it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 484/839 [05:55<04:13,  1.40it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 485/839 [05:55<04:15,  1.38it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 486/839 [05:56<04:14,  1.38it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 487/839 [05:57<04:13,  1.39it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 488/839 [05:58<04:12,  1.39it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 489/839 [05:58<04:12,  1.39it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 490/839 [05:59<04:10,  1.39it/s]\u001b[A\n",
      "Iteration:  59%|█████▊    | 491/839 [06:00<04:09,  1.40it/s]\u001b[A\n",
      "Iteration:  59%|█████▊    | 492/839 [06:00<04:08,  1.40it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 493/839 [06:01<04:07,  1.40it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 494/839 [06:02<04:06,  1.40it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 495/839 [06:03<04:06,  1.39it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 496/839 [06:03<04:07,  1.38it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 497/839 [06:04<04:05,  1.39it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 498/839 [06:05<04:04,  1.39it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 499/839 [06:06<04:03,  1.40it/s]\u001b[A01/07/2020 14:25:13 - INFO - __main__ -   Average loss: 1.412958587408066 at global step: 500\n",
      "\n",
      "Iteration:  60%|█████▉    | 500/839 [06:06<04:02,  1.40it/s]\u001b[A\n",
      "Iteration:  60%|█████▉    | 501/839 [06:07<04:02,  1.39it/s]\u001b[A\n",
      "Iteration:  60%|█████▉    | 502/839 [06:08<04:05,  1.37it/s]\u001b[A\n",
      "Iteration:  60%|█████▉    | 503/839 [06:08<04:04,  1.37it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 504/839 [06:09<04:04,  1.37it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 505/839 [06:10<04:02,  1.38it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 506/839 [06:11<04:02,  1.37it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 507/839 [06:11<04:00,  1.38it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 508/839 [06:12<03:59,  1.38it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 509/839 [06:13<03:58,  1.38it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 510/839 [06:13<03:56,  1.39it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 511/839 [06:14<03:56,  1.39it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 512/839 [06:15<03:55,  1.39it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 513/839 [06:16<03:53,  1.40it/s]\u001b[A\n",
      "Iteration:  61%|██████▏   | 514/839 [06:16<03:53,  1.39it/s]\u001b[A\n",
      "Iteration:  61%|██████▏   | 515/839 [06:17<03:51,  1.40it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 516/839 [06:18<03:50,  1.40it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 517/839 [06:18<03:50,  1.40it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 518/839 [06:19<03:49,  1.40it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 519/839 [06:20<03:48,  1.40it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 520/839 [06:21<03:47,  1.40it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 521/839 [06:21<03:47,  1.40it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 522/839 [06:22<03:46,  1.40it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 523/839 [06:23<03:45,  1.40it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 524/839 [06:23<03:44,  1.40it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 525/839 [06:24<03:44,  1.40it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 526/839 [06:25<03:43,  1.40it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 527/839 [06:26<03:41,  1.41it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 528/839 [06:26<03:40,  1.41it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 529/839 [06:27<03:40,  1.41it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 530/839 [06:28<03:39,  1.40it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 531/839 [06:28<03:39,  1.40it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 532/839 [06:29<03:44,  1.37it/s]\u001b[A\n",
      "Iteration:  64%|██████▎   | 533/839 [06:30<03:45,  1.36it/s]\u001b[A\n",
      "Iteration:  64%|██████▎   | 534/839 [06:31<03:44,  1.36it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 535/839 [06:31<03:42,  1.37it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 536/839 [06:32<03:45,  1.35it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 537/839 [06:33<03:45,  1.34it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 538/839 [06:34<03:44,  1.34it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 539/839 [06:34<03:43,  1.34it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 540/839 [06:35<03:44,  1.33it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 541/839 [06:36<03:41,  1.34it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 542/839 [06:37<03:40,  1.34it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 543/839 [06:37<03:38,  1.35it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 544/839 [06:38<03:38,  1.35it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 545/839 [06:39<03:36,  1.36it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 546/839 [06:40<03:34,  1.37it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 547/839 [06:40<03:31,  1.38it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 548/839 [06:41<03:29,  1.39it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 549/839 [06:42<03:29,  1.39it/s]\u001b[A01/07/2020 14:25:49 - INFO - __main__ -   Average loss: 1.4203422784805297 at global step: 550\n",
      "\n",
      "Iteration:  66%|██████▌   | 550/839 [06:42<03:28,  1.39it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 551/839 [06:43<03:27,  1.39it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 552/839 [06:44<03:26,  1.39it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 553/839 [06:45<03:27,  1.38it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 554/839 [06:45<03:26,  1.38it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 555/839 [06:46<03:23,  1.39it/s]\u001b[A\n",
      "Iteration:  66%|██████▋   | 556/839 [06:47<03:22,  1.40it/s]\u001b[A\n",
      "Iteration:  66%|██████▋   | 557/839 [06:48<03:22,  1.39it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 558/839 [06:48<03:22,  1.39it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 559/839 [06:49<03:20,  1.40it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 560/839 [06:50<03:21,  1.39it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 561/839 [06:50<03:21,  1.38it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 562/839 [06:51<03:20,  1.38it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 563/839 [06:52<03:19,  1.38it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 564/839 [06:53<03:18,  1.38it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 565/839 [06:53<03:17,  1.38it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 566/839 [06:54<03:18,  1.37it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 567/839 [06:55<03:17,  1.38it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 568/839 [06:55<03:16,  1.38it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 569/839 [06:56<03:15,  1.38it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 570/839 [06:57<03:13,  1.39it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 571/839 [06:58<03:13,  1.39it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 572/839 [06:58<03:12,  1.39it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 573/839 [06:59<03:12,  1.38it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 574/839 [07:00<03:11,  1.38it/s]\u001b[A\n",
      "Iteration:  69%|██████▊   | 575/839 [07:01<03:10,  1.39it/s]\u001b[A\n",
      "Iteration:  69%|██████▊   | 576/839 [07:01<03:09,  1.39it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 577/839 [07:02<03:08,  1.39it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 578/839 [07:03<03:07,  1.39it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 579/839 [07:03<03:06,  1.39it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 580/839 [07:04<03:05,  1.39it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 581/839 [07:05<03:04,  1.40it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 582/839 [07:06<03:03,  1.40it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 583/839 [07:06<03:02,  1.40it/s]\u001b[A\n",
      "Iteration:  70%|██████▉   | 584/839 [07:07<03:01,  1.40it/s]\u001b[A\n",
      "Iteration:  70%|██████▉   | 585/839 [07:08<03:02,  1.39it/s]\u001b[A\n",
      "Iteration:  70%|██████▉   | 586/839 [07:08<03:01,  1.39it/s]\u001b[A\n",
      "Iteration:  70%|██████▉   | 587/839 [07:09<03:00,  1.39it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 588/839 [07:10<02:59,  1.40it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 589/839 [07:11<02:59,  1.39it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 590/839 [07:11<02:59,  1.39it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 591/839 [07:12<02:59,  1.38it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 592/839 [07:13<02:58,  1.38it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 593/839 [07:13<02:56,  1.39it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 594/839 [07:14<02:57,  1.38it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 595/839 [07:15<02:57,  1.37it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 596/839 [07:16<02:56,  1.38it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 597/839 [07:16<02:56,  1.37it/s]\u001b[A\n",
      "Iteration:  71%|███████▏  | 598/839 [07:17<02:54,  1.38it/s]\u001b[A\n",
      "Iteration:  71%|███████▏  | 599/839 [07:18<02:54,  1.38it/s]\u001b[A01/07/2020 14:26:25 - INFO - __main__ -   Average loss: 1.4361082339286804 at global step: 600\n",
      "\n",
      "Iteration:  72%|███████▏  | 600/839 [07:19<02:52,  1.38it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 601/839 [07:19<02:51,  1.39it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 602/839 [07:20<02:50,  1.39it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 603/839 [07:21<02:52,  1.36it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 604/839 [07:21<02:53,  1.36it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  72%|███████▏  | 605/839 [07:22<02:53,  1.35it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 606/839 [07:23<02:51,  1.36it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 607/839 [07:24<02:52,  1.34it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 608/839 [07:24<02:49,  1.36it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 609/839 [07:25<02:51,  1.34it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 610/839 [07:26<02:48,  1.36it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 611/839 [07:27<02:48,  1.35it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 612/839 [07:27<02:46,  1.36it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 613/839 [07:28<02:44,  1.38it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 614/839 [07:29<02:42,  1.38it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 615/839 [07:30<02:40,  1.39it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 616/839 [07:30<02:40,  1.39it/s]\u001b[A\n",
      "Iteration:  74%|███████▎  | 617/839 [07:31<02:39,  1.39it/s]\u001b[A\n",
      "Iteration:  74%|███████▎  | 618/839 [07:32<02:42,  1.36it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 619/839 [07:32<02:41,  1.37it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 620/839 [07:33<02:41,  1.36it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 621/839 [07:34<02:39,  1.36it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 622/839 [07:35<02:38,  1.37it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 623/839 [07:35<02:36,  1.38it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 624/839 [07:36<02:35,  1.38it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 625/839 [07:37<02:36,  1.37it/s]\u001b[A\n",
      "Iteration:  75%|███████▍  | 626/839 [07:38<02:35,  1.37it/s]\u001b[A\n",
      "Iteration:  75%|███████▍  | 627/839 [07:38<02:34,  1.38it/s]\u001b[A\n",
      "Iteration:  75%|███████▍  | 628/839 [07:39<02:32,  1.38it/s]\u001b[A\n",
      "Iteration:  75%|███████▍  | 629/839 [07:40<02:31,  1.39it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 630/839 [07:40<02:30,  1.39it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 631/839 [07:41<02:29,  1.39it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 632/839 [07:42<02:28,  1.39it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 633/839 [07:43<02:27,  1.40it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 634/839 [07:43<02:26,  1.40it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 635/839 [07:44<02:26,  1.40it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 636/839 [07:45<02:25,  1.39it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 637/839 [07:45<02:24,  1.40it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 638/839 [07:46<02:24,  1.39it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 639/839 [07:47<02:24,  1.39it/s]\u001b[A\n",
      "Iteration:  76%|███████▋  | 640/839 [07:48<02:23,  1.39it/s]\u001b[A\n",
      "Iteration:  76%|███████▋  | 641/839 [07:48<02:21,  1.39it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 642/839 [07:49<02:21,  1.39it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 643/839 [07:50<02:20,  1.39it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 644/839 [07:50<02:19,  1.40it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 645/839 [07:51<02:19,  1.39it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 646/839 [07:52<02:19,  1.39it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 647/839 [07:53<02:18,  1.39it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 648/839 [07:53<02:17,  1.39it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 649/839 [07:54<02:16,  1.39it/s]\u001b[A01/07/2020 14:27:02 - INFO - __main__ -   Average loss: 1.526275919675827 at global step: 650\n",
      "\n",
      "Iteration:  77%|███████▋  | 650/839 [07:55<02:16,  1.39it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 651/839 [07:56<02:15,  1.39it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 652/839 [07:56<02:14,  1.39it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 653/839 [07:57<02:13,  1.40it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 654/839 [07:58<02:14,  1.37it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 655/839 [07:58<02:13,  1.38it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 656/839 [07:59<02:13,  1.38it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 657/839 [08:00<02:12,  1.37it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 658/839 [08:01<02:11,  1.38it/s]\u001b[A\n",
      "Iteration:  79%|███████▊  | 659/839 [08:01<02:09,  1.38it/s]\u001b[A\n",
      "Iteration:  79%|███████▊  | 660/839 [08:02<02:09,  1.38it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 661/839 [08:03<02:08,  1.39it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 662/839 [08:03<02:07,  1.38it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 663/839 [08:04<02:08,  1.37it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 664/839 [08:05<02:06,  1.38it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 665/839 [08:06<02:06,  1.38it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 666/839 [08:06<02:05,  1.38it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 667/839 [08:07<02:05,  1.37it/s]\u001b[A\n",
      "Iteration:  80%|███████▉  | 668/839 [08:08<02:03,  1.38it/s]\u001b[A\n",
      "Iteration:  80%|███████▉  | 669/839 [08:09<02:02,  1.39it/s]\u001b[A\n",
      "Iteration:  80%|███████▉  | 670/839 [08:09<02:01,  1.39it/s]\u001b[A\n",
      "Iteration:  80%|███████▉  | 671/839 [08:10<02:00,  1.39it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 672/839 [08:11<02:01,  1.38it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 673/839 [08:11<02:00,  1.38it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 674/839 [08:12<01:59,  1.38it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 675/839 [08:13<01:58,  1.38it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 676/839 [08:14<01:57,  1.39it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 677/839 [08:14<01:56,  1.38it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 678/839 [08:15<01:56,  1.39it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 679/839 [08:16<01:55,  1.39it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 680/839 [08:16<01:54,  1.39it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 681/839 [08:17<01:53,  1.39it/s]\u001b[A\n",
      "Iteration:  81%|████████▏ | 682/839 [08:18<01:52,  1.39it/s]\u001b[A\n",
      "Iteration:  81%|████████▏ | 683/839 [08:19<01:52,  1.39it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 684/839 [08:19<01:51,  1.39it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 685/839 [08:20<01:50,  1.39it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 686/839 [08:21<01:49,  1.39it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 687/839 [08:22<01:49,  1.39it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 688/839 [08:22<01:48,  1.40it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 689/839 [08:23<01:47,  1.40it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 690/839 [08:24<01:46,  1.40it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 691/839 [08:24<01:46,  1.39it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 692/839 [08:25<01:45,  1.39it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 693/839 [08:26<01:44,  1.39it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 694/839 [08:27<01:43,  1.40it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 695/839 [08:27<01:43,  1.40it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 696/839 [08:28<01:42,  1.39it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 697/839 [08:29<01:44,  1.36it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 698/839 [08:29<01:43,  1.37it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 699/839 [08:30<01:43,  1.35it/s]\u001b[A01/07/2020 14:27:38 - INFO - __main__ -   Average loss: 1.3693797433376311 at global step: 700\n",
      "\n",
      "Iteration:  83%|████████▎ | 700/839 [08:31<01:42,  1.36it/s]\u001b[A\n",
      "Iteration:  84%|████████▎ | 701/839 [08:32<01:41,  1.36it/s]\u001b[A\n",
      "Iteration:  84%|████████▎ | 702/839 [08:32<01:40,  1.37it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 703/839 [08:33<01:38,  1.37it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 704/839 [08:34<01:37,  1.38it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 705/839 [08:35<01:36,  1.39it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 706/839 [08:35<01:35,  1.39it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 707/839 [08:36<01:34,  1.39it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 708/839 [08:37<01:34,  1.39it/s]\u001b[A\n",
      "Iteration:  85%|████████▍ | 709/839 [08:37<01:34,  1.38it/s]\u001b[A\n",
      "Iteration:  85%|████████▍ | 710/839 [08:38<01:34,  1.37it/s]\u001b[A\n",
      "Iteration:  85%|████████▍ | 711/839 [08:39<01:33,  1.37it/s]\u001b[A\n",
      "Iteration:  85%|████████▍ | 712/839 [08:40<01:32,  1.37it/s]\u001b[A\n",
      "Iteration:  85%|████████▍ | 713/839 [08:40<01:31,  1.38it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 714/839 [08:41<01:30,  1.38it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 715/839 [08:42<01:29,  1.38it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 716/839 [08:43<01:29,  1.38it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 717/839 [08:43<01:28,  1.38it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 718/839 [08:44<01:27,  1.38it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 719/839 [08:45<01:26,  1.39it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 720/839 [08:45<01:25,  1.39it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 721/839 [08:46<01:24,  1.39it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 722/839 [08:47<01:24,  1.38it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 723/839 [08:48<01:24,  1.38it/s]\u001b[A\n",
      "Iteration:  86%|████████▋ | 724/839 [08:48<01:23,  1.37it/s]\u001b[A\n",
      "Iteration:  86%|████████▋ | 725/839 [08:49<01:22,  1.38it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 726/839 [08:50<01:21,  1.38it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 727/839 [08:50<01:20,  1.39it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 728/839 [08:51<01:19,  1.39it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 729/839 [08:52<01:19,  1.39it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  87%|████████▋ | 730/839 [08:53<01:18,  1.39it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 731/839 [08:53<01:17,  1.39it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 732/839 [08:54<01:16,  1.39it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 733/839 [08:55<01:16,  1.39it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 734/839 [08:56<01:15,  1.39it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 735/839 [08:56<01:14,  1.39it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 736/839 [08:57<01:14,  1.39it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 737/839 [08:58<01:14,  1.38it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 738/839 [08:58<01:13,  1.38it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 739/839 [08:59<01:12,  1.37it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 740/839 [09:00<01:11,  1.38it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 741/839 [09:01<01:11,  1.37it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 742/839 [09:01<01:10,  1.38it/s]\u001b[A\n",
      "Iteration:  89%|████████▊ | 743/839 [09:02<01:09,  1.38it/s]\u001b[A\n",
      "Iteration:  89%|████████▊ | 744/839 [09:03<01:08,  1.39it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 745/839 [09:03<01:07,  1.39it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 746/839 [09:04<01:07,  1.37it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 747/839 [09:05<01:06,  1.37it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 748/839 [09:06<01:06,  1.37it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 749/839 [09:06<01:05,  1.37it/s]\u001b[A01/07/2020 14:28:14 - INFO - __main__ -   Average loss: 1.5253189325332641 at global step: 750\n",
      "\n",
      "Iteration:  89%|████████▉ | 750/839 [09:07<01:04,  1.37it/s]\u001b[A\n",
      "Iteration:  90%|████████▉ | 751/839 [09:08<01:03,  1.38it/s]\u001b[A\n",
      "Iteration:  90%|████████▉ | 752/839 [09:09<01:02,  1.40it/s]\u001b[A\n",
      "Iteration:  90%|████████▉ | 753/839 [09:09<01:01,  1.40it/s]\u001b[A\n",
      "Iteration:  90%|████████▉ | 754/839 [09:10<01:01,  1.39it/s]\u001b[A\n",
      "Iteration:  90%|████████▉ | 755/839 [09:11<01:00,  1.39it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 756/839 [09:11<00:59,  1.39it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 757/839 [09:12<00:58,  1.39it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 758/839 [09:13<00:58,  1.40it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 759/839 [09:14<00:57,  1.40it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 760/839 [09:14<00:56,  1.39it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 761/839 [09:15<00:56,  1.39it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 762/839 [09:16<00:55,  1.39it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 763/839 [09:16<00:54,  1.40it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 764/839 [09:17<00:53,  1.40it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 765/839 [09:18<00:52,  1.40it/s]\u001b[A\n",
      "Iteration:  91%|█████████▏| 766/839 [09:19<00:52,  1.39it/s]\u001b[A\n",
      "Iteration:  91%|█████████▏| 767/839 [09:19<00:52,  1.38it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 768/839 [09:20<00:51,  1.37it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 769/839 [09:21<00:51,  1.37it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 770/839 [09:22<00:50,  1.38it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 771/839 [09:22<00:49,  1.38it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 772/839 [09:23<00:48,  1.38it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 773/839 [09:24<00:48,  1.37it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 774/839 [09:24<00:47,  1.38it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 775/839 [09:25<00:45,  1.39it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 776/839 [09:26<00:45,  1.40it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 777/839 [09:27<00:43,  1.41it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 778/839 [09:27<00:43,  1.41it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 779/839 [09:28<00:42,  1.41it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 780/839 [09:29<00:42,  1.38it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 781/839 [09:29<00:42,  1.38it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 782/839 [09:30<00:41,  1.39it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 783/839 [09:31<00:40,  1.38it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 784/839 [09:32<00:39,  1.39it/s]\u001b[A\n",
      "Iteration:  94%|█████████▎| 785/839 [09:32<00:39,  1.38it/s]\u001b[A\n",
      "Iteration:  94%|█████████▎| 786/839 [09:33<00:38,  1.38it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 787/839 [09:34<00:37,  1.38it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 788/839 [09:35<00:37,  1.37it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 789/839 [09:35<00:36,  1.37it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 790/839 [09:36<00:35,  1.38it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 791/839 [09:37<00:35,  1.37it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 792/839 [09:37<00:34,  1.38it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 793/839 [09:38<00:33,  1.38it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 794/839 [09:39<00:32,  1.39it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 795/839 [09:40<00:31,  1.39it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 796/839 [09:40<00:31,  1.39it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 797/839 [09:41<00:30,  1.38it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 798/839 [09:42<00:29,  1.38it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 799/839 [09:42<00:29,  1.38it/s]\u001b[A01/07/2020 14:28:50 - INFO - __main__ -   Average loss: 1.4794691157341004 at global step: 800\n",
      "\n",
      "Iteration:  95%|█████████▌| 800/839 [09:43<00:28,  1.38it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 801/839 [09:44<00:27,  1.39it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 802/839 [09:45<00:26,  1.39it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 803/839 [09:45<00:25,  1.39it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 804/839 [09:46<00:25,  1.40it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 805/839 [09:47<00:24,  1.40it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 806/839 [09:47<00:23,  1.40it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 807/839 [09:48<00:22,  1.39it/s]\u001b[A\n",
      "Iteration:  96%|█████████▋| 808/839 [09:49<00:22,  1.39it/s]\u001b[A\n",
      "Iteration:  96%|█████████▋| 809/839 [09:50<00:21,  1.39it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 810/839 [09:50<00:20,  1.39it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 811/839 [09:51<00:20,  1.39it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 812/839 [09:52<00:19,  1.37it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 813/839 [09:53<00:19,  1.37it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 814/839 [09:53<00:18,  1.36it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 815/839 [09:54<00:17,  1.37it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 816/839 [09:55<00:16,  1.38it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 817/839 [09:55<00:15,  1.38it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 818/839 [09:56<00:15,  1.39it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 819/839 [09:57<00:14,  1.38it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 820/839 [09:58<00:13,  1.39it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 821/839 [09:58<00:12,  1.39it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 822/839 [09:59<00:12,  1.39it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 823/839 [10:00<00:11,  1.40it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 824/839 [10:01<00:10,  1.39it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 825/839 [10:01<00:10,  1.39it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 826/839 [10:02<00:09,  1.39it/s]\u001b[A\n",
      "Iteration:  99%|█████████▊| 827/839 [10:03<00:08,  1.38it/s]\u001b[A\n",
      "Iteration:  99%|█████████▊| 828/839 [10:03<00:07,  1.39it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 829/839 [10:04<00:07,  1.39it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 830/839 [10:05<00:06,  1.39it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 831/839 [10:06<00:05,  1.38it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 832/839 [10:06<00:05,  1.39it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 833/839 [10:07<00:04,  1.39it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 834/839 [10:08<00:03,  1.39it/s]\u001b[A\n",
      "Iteration: 100%|█████████▉| 835/839 [10:08<00:02,  1.40it/s]\u001b[A\n",
      "Iteration: 100%|█████████▉| 836/839 [10:09<00:02,  1.38it/s]\u001b[A\n",
      "Iteration: 100%|█████████▉| 837/839 [10:10<00:01,  1.38it/s]\u001b[A\n",
      "Iteration: 100%|█████████▉| 838/839 [10:11<00:00,  1.37it/s]\u001b[A\n",
      "Iteration: 100%|██████████| 839/839 [10:11<00:00,  1.37it/s]\u001b[A\n",
      "Epoch:  33%|███▎      | 1/3 [10:12<20:24, 612.05s/it]\n",
      "Iteration:   0%|          | 0/839 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 1/839 [00:00<09:58,  1.40it/s]\u001b[A\n",
      "Iteration:   0%|          | 2/839 [00:01<10:01,  1.39it/s]\u001b[A\n",
      "Iteration:   0%|          | 3/839 [00:02<10:05,  1.38it/s]\u001b[A\n",
      "Iteration:   0%|          | 4/839 [00:02<10:08,  1.37it/s]\u001b[A\n",
      "Iteration:   1%|          | 5/839 [00:03<10:09,  1.37it/s]\u001b[A\n",
      "Iteration:   1%|          | 6/839 [00:04<10:15,  1.35it/s]\u001b[A\n",
      "Iteration:   1%|          | 7/839 [00:05<10:15,  1.35it/s]\u001b[A\n",
      "Iteration:   1%|          | 8/839 [00:05<10:09,  1.36it/s]\u001b[A\n",
      "Iteration:   1%|          | 9/839 [00:06<10:04,  1.37it/s]\u001b[A\n",
      "Iteration:   1%|          | 10/839 [00:07<10:02,  1.38it/s]\u001b[A01/07/2020 14:29:26 - INFO - __main__ -   Average loss: 1.4543072497844696 at global step: 850\n",
      "\n",
      "Iteration:   1%|▏         | 11/839 [00:08<09:59,  1.38it/s]\u001b[A\n",
      "Iteration:   1%|▏         | 12/839 [00:08<09:56,  1.39it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:   2%|▏         | 13/839 [00:09<09:54,  1.39it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 14/839 [00:10<09:53,  1.39it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 15/839 [00:10<09:51,  1.39it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 16/839 [00:11<09:49,  1.40it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 17/839 [00:12<09:49,  1.39it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 18/839 [00:13<09:47,  1.40it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 19/839 [00:13<09:46,  1.40it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 20/839 [00:14<09:44,  1.40it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 21/839 [00:15<09:42,  1.40it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 22/839 [00:15<09:41,  1.40it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 23/839 [00:16<09:41,  1.40it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 24/839 [00:17<09:43,  1.40it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 25/839 [00:18<09:40,  1.40it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 26/839 [00:18<09:40,  1.40it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 27/839 [00:19<09:41,  1.40it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 28/839 [00:20<09:42,  1.39it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 29/839 [00:20<09:47,  1.38it/s]\u001b[A\n",
      "Iteration:   4%|▎         | 30/839 [00:21<09:49,  1.37it/s]\u001b[A\n",
      "Iteration:   4%|▎         | 31/839 [00:22<09:54,  1.36it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 32/839 [00:23<09:56,  1.35it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 33/839 [00:23<09:54,  1.35it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 34/839 [00:24<09:48,  1.37it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 35/839 [00:25<09:46,  1.37it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 36/839 [00:26<09:42,  1.38it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 37/839 [00:26<09:38,  1.39it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 38/839 [00:27<09:39,  1.38it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 39/839 [00:28<09:42,  1.37it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 40/839 [00:28<09:43,  1.37it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 41/839 [00:29<09:40,  1.37it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 42/839 [00:30<09:42,  1.37it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 43/839 [00:31<09:38,  1.38it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 44/839 [00:31<09:35,  1.38it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 45/839 [00:32<09:31,  1.39it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 46/839 [00:33<09:38,  1.37it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 47/839 [00:34<09:35,  1.38it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 48/839 [00:34<09:32,  1.38it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 49/839 [00:35<09:26,  1.39it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 50/839 [00:36<09:22,  1.40it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 51/839 [00:36<09:19,  1.41it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 52/839 [00:37<09:18,  1.41it/s]\u001b[A\n",
      "Iteration:   6%|▋         | 53/839 [00:38<09:35,  1.37it/s]\u001b[A\n",
      "Iteration:   6%|▋         | 54/839 [00:39<09:35,  1.36it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 55/839 [00:39<09:43,  1.34it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 56/839 [00:40<09:39,  1.35it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 57/839 [00:41<09:47,  1.33it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 58/839 [00:42<09:44,  1.34it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 59/839 [00:42<09:38,  1.35it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 60/839 [00:43<09:32,  1.36it/s]\u001b[A01/07/2020 14:30:02 - INFO - __main__ -   Average loss: 1.4506784355640412 at global step: 900\n",
      "\n",
      "Iteration:   7%|▋         | 61/839 [00:44<09:29,  1.37it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 62/839 [00:45<09:26,  1.37it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 63/839 [00:45<09:27,  1.37it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 64/839 [00:46<09:25,  1.37it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 65/839 [00:47<09:19,  1.38it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 66/839 [00:47<09:17,  1.39it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 67/839 [00:48<09:17,  1.39it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 68/839 [00:49<09:17,  1.38it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 69/839 [00:50<09:14,  1.39it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 70/839 [00:50<09:16,  1.38it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 71/839 [00:51<09:20,  1.37it/s]\u001b[A\n",
      "Iteration:   9%|▊         | 72/839 [00:52<09:18,  1.37it/s]\u001b[A\n",
      "Iteration:   9%|▊         | 73/839 [00:52<09:15,  1.38it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 74/839 [00:53<09:14,  1.38it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 75/839 [00:54<09:12,  1.38it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 76/839 [00:55<09:14,  1.38it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 77/839 [00:55<09:12,  1.38it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 78/839 [00:56<09:12,  1.38it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 79/839 [00:57<09:10,  1.38it/s]\u001b[A\n",
      "Iteration:  10%|▉         | 80/839 [00:58<09:08,  1.38it/s]\u001b[A\n",
      "Iteration:  10%|▉         | 81/839 [00:58<09:04,  1.39it/s]\u001b[A\n",
      "Iteration:  10%|▉         | 82/839 [00:59<09:02,  1.39it/s]\u001b[A\n",
      "Iteration:  10%|▉         | 83/839 [01:00<09:00,  1.40it/s]\u001b[A\n",
      "Iteration:  10%|█         | 84/839 [01:00<09:01,  1.39it/s]\u001b[A\n",
      "Iteration:  10%|█         | 85/839 [01:01<09:00,  1.39it/s]\u001b[A\n",
      "Iteration:  10%|█         | 86/839 [01:02<08:59,  1.40it/s]\u001b[A\n",
      "Iteration:  10%|█         | 87/839 [01:03<08:57,  1.40it/s]\u001b[A\n",
      "Iteration:  10%|█         | 88/839 [01:03<08:59,  1.39it/s]\u001b[A\n",
      "Iteration:  11%|█         | 89/839 [01:04<09:00,  1.39it/s]\u001b[A\n",
      "Iteration:  11%|█         | 90/839 [01:05<09:01,  1.38it/s]\u001b[A\n",
      "Iteration:  11%|█         | 91/839 [01:05<09:03,  1.38it/s]\u001b[A\n",
      "Iteration:  11%|█         | 92/839 [01:06<09:01,  1.38it/s]\u001b[A\n",
      "Iteration:  11%|█         | 93/839 [01:07<09:03,  1.37it/s]\u001b[A\n",
      "Iteration:  11%|█         | 94/839 [01:08<09:07,  1.36it/s]\u001b[A\n",
      "Iteration:  11%|█▏        | 95/839 [01:08<09:07,  1.36it/s]\u001b[A\n",
      "Iteration:  11%|█▏        | 96/839 [01:09<09:08,  1.36it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 97/839 [01:10<09:04,  1.36it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 98/839 [01:11<09:01,  1.37it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 99/839 [01:11<09:16,  1.33it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 100/839 [01:12<09:16,  1.33it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 101/839 [01:13<09:16,  1.32it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 102/839 [01:14<09:09,  1.34it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 103/839 [01:14<09:05,  1.35it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 104/839 [01:15<09:01,  1.36it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 105/839 [01:16<08:57,  1.37it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 106/839 [01:17<08:52,  1.38it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 107/839 [01:17<08:49,  1.38it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 108/839 [01:18<08:47,  1.38it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 109/839 [01:19<08:46,  1.39it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 110/839 [01:19<08:45,  1.39it/s]\u001b[A01/07/2020 14:30:39 - INFO - __main__ -   Average loss: 1.5447703385353089 at global step: 950\n",
      "\n",
      "Iteration:  13%|█▎        | 111/839 [01:20<08:48,  1.38it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 112/839 [01:21<08:51,  1.37it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 113/839 [01:22<08:49,  1.37it/s]\u001b[A\n",
      "Iteration:  14%|█▎        | 114/839 [01:22<08:48,  1.37it/s]\u001b[A\n",
      "Iteration:  14%|█▎        | 115/839 [01:23<08:49,  1.37it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 116/839 [01:24<08:49,  1.37it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 117/839 [01:25<08:45,  1.37it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 118/839 [01:25<08:42,  1.38it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 119/839 [01:26<08:40,  1.38it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 120/839 [01:27<08:36,  1.39it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 121/839 [01:27<08:35,  1.39it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 122/839 [01:28<08:34,  1.39it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 123/839 [01:29<08:45,  1.36it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 124/839 [01:30<08:44,  1.36it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 125/839 [01:30<08:51,  1.34it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 126/839 [01:31<08:44,  1.36it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 127/839 [01:32<08:43,  1.36it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 128/839 [01:33<08:41,  1.36it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 129/839 [01:33<08:37,  1.37it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 130/839 [01:34<08:34,  1.38it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 131/839 [01:35<08:31,  1.38it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 132/839 [01:35<08:31,  1.38it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 133/839 [01:36<08:29,  1.39it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 134/839 [01:37<08:26,  1.39it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 135/839 [01:38<08:25,  1.39it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 136/839 [01:38<08:29,  1.38it/s]\u001b[A\n",
      "Iteration:  16%|█▋        | 137/839 [01:39<08:26,  1.38it/s]\u001b[A\n",
      "Iteration:  16%|█▋        | 138/839 [01:40<08:26,  1.38it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  17%|█▋        | 139/839 [01:41<08:30,  1.37it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 140/839 [01:41<08:30,  1.37it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 141/839 [01:42<08:30,  1.37it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 142/839 [01:43<08:27,  1.37it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 143/839 [01:43<08:25,  1.38it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 144/839 [01:44<08:25,  1.38it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 145/839 [01:45<08:23,  1.38it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 146/839 [01:46<08:20,  1.38it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 147/839 [01:46<08:22,  1.38it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 148/839 [01:47<08:19,  1.38it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 149/839 [01:48<08:16,  1.39it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 150/839 [01:48<08:14,  1.39it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 151/839 [01:49<08:13,  1.39it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 152/839 [01:50<08:15,  1.39it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 153/839 [01:51<08:15,  1.38it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 154/839 [01:51<08:14,  1.38it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 155/839 [01:52<08:12,  1.39it/s]\u001b[A\n",
      "Iteration:  19%|█▊        | 156/839 [01:53<08:22,  1.36it/s]\u001b[A\n",
      "Iteration:  19%|█▊        | 157/839 [01:54<08:21,  1.36it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 158/839 [01:54<08:25,  1.35it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 159/839 [01:55<08:20,  1.36it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 160/839 [01:56<08:16,  1.37it/s]\u001b[A01/07/2020 14:31:15 - INFO - __main__ -   Average loss: 1.4623148894309999 at global step: 1000\n",
      "01/07/2020 14:31:15 - INFO - src.transformers.configuration_utils -   Configuration saved in save/checkpoint-1000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save/\n",
      "save/checkpoint-1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/07/2020 14:31:17 - INFO - src.transformers.modeling_utils -   Model weights saved in save/checkpoint-1000/pytorch_model.bin\n",
      "01/07/2020 14:31:17 - INFO - __main__ -   Saving model checkpoint to save/checkpoint-1000\n",
      "\n",
      "Iteration:  19%|█▉        | 161/839 [01:58<14:35,  1.29s/it]\u001b[A\n",
      "Iteration:  19%|█▉        | 162/839 [01:59<12:36,  1.12s/it]\u001b[A\n",
      "Iteration:  19%|█▉        | 163/839 [02:00<11:18,  1.00s/it]\u001b[A\n",
      "Iteration:  20%|█▉        | 164/839 [02:01<10:17,  1.09it/s]\u001b[A\n",
      "Iteration:  20%|█▉        | 165/839 [02:01<09:35,  1.17it/s]\u001b[A\n",
      "Iteration:  20%|█▉        | 166/839 [02:02<09:07,  1.23it/s]\u001b[A\n",
      "Iteration:  20%|█▉        | 167/839 [02:03<08:46,  1.28it/s]\u001b[A\n",
      "Iteration:  20%|██        | 168/839 [02:03<08:32,  1.31it/s]\u001b[A\n",
      "Iteration:  20%|██        | 169/839 [02:04<08:22,  1.33it/s]\u001b[A\n",
      "Iteration:  20%|██        | 170/839 [02:05<08:15,  1.35it/s]\u001b[A\n",
      "Iteration:  20%|██        | 171/839 [02:06<08:10,  1.36it/s]\u001b[A\n",
      "Iteration:  21%|██        | 172/839 [02:06<08:10,  1.36it/s]\u001b[A\n",
      "Iteration:  21%|██        | 173/839 [02:07<08:07,  1.37it/s]\u001b[A\n",
      "Iteration:  21%|██        | 174/839 [02:08<08:03,  1.38it/s]\u001b[A\n",
      "Iteration:  21%|██        | 175/839 [02:08<08:03,  1.37it/s]\u001b[A\n",
      "Iteration:  21%|██        | 176/839 [02:09<08:00,  1.38it/s]\u001b[A\n",
      "Iteration:  21%|██        | 177/839 [02:10<07:58,  1.38it/s]\u001b[A\n",
      "Iteration:  21%|██        | 178/839 [02:11<07:55,  1.39it/s]\u001b[A\n",
      "Iteration:  21%|██▏       | 179/839 [02:11<08:03,  1.37it/s]\u001b[A\n",
      "Iteration:  21%|██▏       | 180/839 [02:12<08:02,  1.37it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 181/839 [02:13<08:05,  1.36it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 182/839 [02:14<08:02,  1.36it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 183/839 [02:14<08:16,  1.32it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 184/839 [02:15<08:14,  1.32it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 185/839 [02:16<08:07,  1.34it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 186/839 [02:17<08:00,  1.36it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 187/839 [02:17<08:08,  1.34it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 188/839 [02:18<08:05,  1.34it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 189/839 [02:19<08:12,  1.32it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 190/839 [02:20<08:04,  1.34it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 191/839 [02:20<07:59,  1.35it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 192/839 [02:21<07:52,  1.37it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 193/839 [02:22<07:48,  1.38it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 194/839 [02:22<07:46,  1.38it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 195/839 [02:23<07:43,  1.39it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 196/839 [02:24<07:43,  1.39it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 197/839 [02:25<07:42,  1.39it/s]\u001b[A\n",
      "Iteration:  24%|██▎       | 198/839 [02:25<07:43,  1.38it/s]\u001b[A\n",
      "Iteration:  24%|██▎       | 199/839 [02:26<07:42,  1.38it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 200/839 [02:27<07:39,  1.39it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 201/839 [02:27<07:36,  1.40it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 202/839 [02:28<07:39,  1.39it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 203/839 [02:29<07:37,  1.39it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 204/839 [02:30<07:36,  1.39it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 205/839 [02:30<07:35,  1.39it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 206/839 [02:31<07:35,  1.39it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 207/839 [02:32<07:35,  1.39it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 208/839 [02:33<07:35,  1.38it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 209/839 [02:33<07:35,  1.38it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 210/839 [02:34<07:41,  1.36it/s]\u001b[A01/07/2020 14:31:53 - INFO - __main__ -   Average loss: 1.4416878354549407 at global step: 1050\n",
      "\n",
      "Iteration:  25%|██▌       | 211/839 [02:35<07:39,  1.37it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 212/839 [02:35<07:33,  1.38it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 213/839 [02:36<07:30,  1.39it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 214/839 [02:37<07:27,  1.40it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 215/839 [02:38<07:25,  1.40it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 216/839 [02:38<07:34,  1.37it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 217/839 [02:39<07:34,  1.37it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 218/839 [02:40<07:43,  1.34it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 219/839 [02:41<07:41,  1.34it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 220/839 [02:41<07:37,  1.35it/s]\u001b[A\n",
      "Iteration:  26%|██▋       | 221/839 [02:42<07:32,  1.36it/s]\u001b[A\n",
      "Iteration:  26%|██▋       | 222/839 [02:43<07:29,  1.37it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 223/839 [02:43<07:24,  1.38it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 224/839 [02:44<07:24,  1.38it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 225/839 [02:45<07:23,  1.38it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 226/839 [02:46<07:23,  1.38it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 227/839 [02:46<07:22,  1.38it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 228/839 [02:47<07:24,  1.37it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 229/839 [02:48<07:24,  1.37it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 230/839 [02:49<07:22,  1.38it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 231/839 [02:49<07:18,  1.39it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 232/839 [02:50<07:21,  1.37it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 233/839 [02:51<07:22,  1.37it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 234/839 [02:51<07:22,  1.37it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 235/839 [02:52<07:23,  1.36it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 236/839 [02:53<07:23,  1.36it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 237/839 [02:54<07:22,  1.36it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 238/839 [02:54<07:20,  1.36it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 239/839 [02:55<07:17,  1.37it/s]\u001b[A\n",
      "Iteration:  29%|██▊       | 240/839 [02:56<07:17,  1.37it/s]\u001b[A\n",
      "Iteration:  29%|██▊       | 241/839 [02:57<07:17,  1.37it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 242/839 [02:57<07:15,  1.37it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 243/839 [02:58<07:16,  1.37it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 244/839 [02:59<07:25,  1.34it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 245/839 [03:00<07:24,  1.34it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 246/839 [03:00<07:31,  1.31it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 247/839 [03:01<07:24,  1.33it/s]\u001b[A\n",
      "Iteration:  30%|██▉       | 248/839 [03:02<07:17,  1.35it/s]\u001b[A\n",
      "Iteration:  30%|██▉       | 249/839 [03:03<07:17,  1.35it/s]\u001b[A\n",
      "Iteration:  30%|██▉       | 250/839 [03:03<07:25,  1.32it/s]\u001b[A\n",
      "Iteration:  30%|██▉       | 251/839 [03:04<07:21,  1.33it/s]\u001b[A\n",
      "Iteration:  30%|███       | 252/839 [03:05<07:15,  1.35it/s]\u001b[A\n",
      "Iteration:  30%|███       | 253/839 [03:06<07:10,  1.36it/s]\u001b[A\n",
      "Iteration:  30%|███       | 254/839 [03:06<07:06,  1.37it/s]\u001b[A\n",
      "Iteration:  30%|███       | 255/839 [03:07<07:04,  1.38it/s]\u001b[A\n",
      "Iteration:  31%|███       | 256/839 [03:08<06:59,  1.39it/s]\u001b[A\n",
      "Iteration:  31%|███       | 257/839 [03:08<06:57,  1.40it/s]\u001b[A\n",
      "Iteration:  31%|███       | 258/839 [03:09<06:54,  1.40it/s]\u001b[A\n",
      "Iteration:  31%|███       | 259/839 [03:10<06:56,  1.39it/s]\u001b[A\n",
      "Iteration:  31%|███       | 260/839 [03:11<06:54,  1.40it/s]\u001b[A01/07/2020 14:32:30 - INFO - __main__ -   Average loss: 1.4358810687065124 at global step: 1100\n",
      "\n",
      "Iteration:  31%|███       | 261/839 [03:11<06:57,  1.39it/s]\u001b[A\n",
      "Iteration:  31%|███       | 262/839 [03:12<06:55,  1.39it/s]\u001b[A\n",
      "Iteration:  31%|███▏      | 263/839 [03:13<06:53,  1.39it/s]\u001b[A\n",
      "Iteration:  31%|███▏      | 264/839 [03:13<06:56,  1.38it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 265/839 [03:14<06:55,  1.38it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 266/839 [03:15<06:52,  1.39it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 267/839 [03:16<06:52,  1.39it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 268/839 [03:16<06:52,  1.38it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 269/839 [03:17<06:50,  1.39it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 270/839 [03:18<06:49,  1.39it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 271/839 [03:18<06:48,  1.39it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 272/839 [03:19<06:49,  1.39it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 273/839 [03:20<06:47,  1.39it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 274/839 [03:21<06:46,  1.39it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 275/839 [03:21<06:50,  1.38it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 276/839 [03:22<06:54,  1.36it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 277/839 [03:23<06:51,  1.36it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 278/839 [03:24<06:51,  1.36it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 279/839 [03:24<06:56,  1.34it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 280/839 [03:25<06:54,  1.35it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 281/839 [03:26<06:54,  1.35it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  34%|███▎      | 282/839 [03:27<06:48,  1.36it/s]\u001b[A\n",
      "Iteration:  34%|███▎      | 283/839 [03:27<06:45,  1.37it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 284/839 [03:28<06:42,  1.38it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 285/839 [03:29<06:41,  1.38it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 286/839 [03:29<06:38,  1.39it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 287/839 [03:30<06:35,  1.39it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 288/839 [03:31<06:34,  1.40it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 289/839 [03:32<06:33,  1.40it/s]\u001b[A\n",
      "Iteration:  35%|███▍      | 290/839 [03:32<06:42,  1.36it/s]\u001b[A\n",
      "Iteration:  35%|███▍      | 291/839 [03:33<06:40,  1.37it/s]\u001b[A\n",
      "Iteration:  35%|███▍      | 292/839 [03:34<06:41,  1.36it/s]\u001b[A\n",
      "Iteration:  35%|███▍      | 293/839 [03:35<06:41,  1.36it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 294/839 [03:35<06:37,  1.37it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 295/839 [03:36<06:38,  1.36it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 296/839 [03:37<06:34,  1.38it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 297/839 [03:37<06:37,  1.36it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 298/839 [03:38<06:33,  1.37it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 299/839 [03:39<06:34,  1.37it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 300/839 [03:40<06:34,  1.37it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 301/839 [03:40<06:30,  1.38it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 302/839 [03:41<06:28,  1.38it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 303/839 [03:42<06:29,  1.37it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 304/839 [03:43<06:28,  1.38it/s]\u001b[A\n",
      "Iteration:  36%|███▋      | 305/839 [03:43<06:25,  1.39it/s]\u001b[A\n",
      "Iteration:  36%|███▋      | 306/839 [03:44<06:21,  1.40it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 307/839 [03:45<06:19,  1.40it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 308/839 [03:45<06:19,  1.40it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 309/839 [03:46<06:18,  1.40it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 310/839 [03:47<06:25,  1.37it/s]\u001b[A01/07/2020 14:33:06 - INFO - __main__ -   Average loss: 1.451015762090683 at global step: 1150\n",
      "\n",
      "Iteration:  37%|███▋      | 311/839 [03:48<06:24,  1.37it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 312/839 [03:48<06:29,  1.35it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 313/839 [03:49<06:25,  1.36it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 314/839 [03:50<06:24,  1.37it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 315/839 [03:51<06:21,  1.38it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 316/839 [03:51<06:16,  1.39it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 317/839 [03:52<06:15,  1.39it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 318/839 [03:53<06:18,  1.37it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 319/839 [03:53<06:20,  1.37it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 320/839 [03:54<06:18,  1.37it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 321/839 [03:55<06:21,  1.36it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 322/839 [03:56<06:20,  1.36it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 323/839 [03:56<06:17,  1.37it/s]\u001b[A\n",
      "Iteration:  39%|███▊      | 324/839 [03:57<06:14,  1.38it/s]\u001b[A\n",
      "Iteration:  39%|███▊      | 325/839 [03:58<06:15,  1.37it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 326/839 [03:59<06:13,  1.37it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 327/839 [03:59<06:10,  1.38it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 328/839 [04:00<06:05,  1.40it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 329/839 [04:01<06:05,  1.40it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 330/839 [04:01<06:08,  1.38it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 331/839 [04:02<06:10,  1.37it/s]\u001b[A\n",
      "Iteration:  40%|███▉      | 332/839 [04:03<06:10,  1.37it/s]\u001b[A\n",
      "Iteration:  40%|███▉      | 333/839 [04:04<06:08,  1.37it/s]\u001b[A\n",
      "Iteration:  40%|███▉      | 334/839 [04:04<06:05,  1.38it/s]\u001b[A\n",
      "Iteration:  40%|███▉      | 335/839 [04:05<06:03,  1.39it/s]\u001b[A\n",
      "Iteration:  40%|████      | 336/839 [04:06<06:01,  1.39it/s]\u001b[A\n",
      "Iteration:  40%|████      | 337/839 [04:06<05:58,  1.40it/s]\u001b[A\n",
      "Iteration:  40%|████      | 338/839 [04:07<05:59,  1.39it/s]\u001b[A\n",
      "Iteration:  40%|████      | 339/839 [04:08<05:59,  1.39it/s]\u001b[A\n",
      "Iteration:  41%|████      | 340/839 [04:09<05:58,  1.39it/s]\u001b[A\n",
      "Iteration:  41%|████      | 341/839 [04:09<05:58,  1.39it/s]\u001b[A\n",
      "Iteration:  41%|████      | 342/839 [04:10<05:59,  1.38it/s]\u001b[A\n",
      "Iteration:  41%|████      | 343/839 [04:11<06:02,  1.37it/s]\u001b[A\n",
      "Iteration:  41%|████      | 344/839 [04:12<06:01,  1.37it/s]\u001b[A\n",
      "Iteration:  41%|████      | 345/839 [04:12<05:58,  1.38it/s]\u001b[A\n",
      "Iteration:  41%|████      | 346/839 [04:13<05:56,  1.38it/s]\u001b[A\n",
      "Iteration:  41%|████▏     | 347/839 [04:14<05:56,  1.38it/s]\u001b[A\n",
      "Iteration:  41%|████▏     | 348/839 [04:14<05:55,  1.38it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 349/839 [04:15<05:55,  1.38it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 350/839 [04:16<05:53,  1.38it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 351/839 [04:17<05:54,  1.37it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 352/839 [04:17<06:04,  1.33it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 353/839 [04:18<06:00,  1.35it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 354/839 [04:19<05:55,  1.36it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 355/839 [04:20<05:50,  1.38it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 356/839 [04:20<05:50,  1.38it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 357/839 [04:21<05:49,  1.38it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 358/839 [04:22<05:48,  1.38it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 359/839 [04:22<05:45,  1.39it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 360/839 [04:23<05:47,  1.38it/s]\u001b[A01/07/2020 14:33:43 - INFO - __main__ -   Average loss: 1.4116824865341187 at global step: 1200\n",
      "\n",
      "Iteration:  43%|████▎     | 361/839 [04:24<05:46,  1.38it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 362/839 [04:25<05:45,  1.38it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 363/839 [04:25<05:44,  1.38it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 364/839 [04:26<05:42,  1.39it/s]\u001b[A\n",
      "Iteration:  44%|████▎     | 365/839 [04:27<05:40,  1.39it/s]\u001b[A\n",
      "Iteration:  44%|████▎     | 366/839 [04:27<05:38,  1.40it/s]\u001b[A\n",
      "Iteration:  44%|████▎     | 367/839 [04:28<05:38,  1.39it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 368/839 [04:29<05:37,  1.39it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 369/839 [04:30<05:37,  1.39it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 370/839 [04:30<05:37,  1.39it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 371/839 [04:31<05:37,  1.39it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 372/839 [04:32<05:37,  1.38it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 373/839 [04:33<05:36,  1.38it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 374/839 [04:33<05:35,  1.38it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 375/839 [04:34<05:35,  1.38it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 376/839 [04:35<05:34,  1.38it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 377/839 [04:35<05:37,  1.37it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 378/839 [04:36<05:40,  1.35it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 379/839 [04:37<05:36,  1.37it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 380/839 [04:38<05:33,  1.38it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 381/839 [04:38<05:32,  1.38it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 382/839 [04:39<05:32,  1.38it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 383/839 [04:40<05:30,  1.38it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 384/839 [04:41<05:28,  1.39it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 385/839 [04:41<05:26,  1.39it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 386/839 [04:42<05:27,  1.38it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 387/839 [04:43<05:26,  1.38it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 388/839 [04:43<05:25,  1.39it/s]\u001b[A\n",
      "Iteration:  46%|████▋     | 389/839 [04:44<05:25,  1.38it/s]\u001b[A\n",
      "Iteration:  46%|████▋     | 390/839 [04:45<05:25,  1.38it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 391/839 [04:46<05:24,  1.38it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 392/839 [04:46<05:34,  1.34it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 393/839 [04:47<05:30,  1.35it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 394/839 [04:48<05:26,  1.36it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 395/839 [04:49<05:24,  1.37it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 396/839 [04:49<05:20,  1.38it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 397/839 [04:50<05:18,  1.39it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 398/839 [04:51<05:21,  1.37it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 399/839 [04:51<05:24,  1.36it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 400/839 [04:52<05:22,  1.36it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 401/839 [04:53<05:19,  1.37it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 402/839 [04:54<05:17,  1.38it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 403/839 [04:54<05:15,  1.38it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 404/839 [04:55<05:13,  1.39it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 405/839 [04:56<05:15,  1.38it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 406/839 [04:57<05:16,  1.37it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  49%|████▊     | 407/839 [04:57<05:18,  1.36it/s]\u001b[A\n",
      "Iteration:  49%|████▊     | 408/839 [04:58<05:17,  1.36it/s]\u001b[A\n",
      "Iteration:  49%|████▊     | 409/839 [04:59<05:13,  1.37it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 410/839 [04:59<05:10,  1.38it/s]\u001b[A01/07/2020 14:34:19 - INFO - __main__ -   Average loss: 1.4465142679214478 at global step: 1250\n",
      "\n",
      "Iteration:  49%|████▉     | 411/839 [05:00<05:08,  1.39it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 412/839 [05:01<05:06,  1.39it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 413/839 [05:02<05:06,  1.39it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 414/839 [05:02<05:06,  1.39it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 415/839 [05:03<05:04,  1.39it/s]\u001b[A\n",
      "Iteration:  50%|████▉     | 416/839 [05:04<05:02,  1.40it/s]\u001b[A\n",
      "Iteration:  50%|████▉     | 417/839 [05:04<05:03,  1.39it/s]\u001b[A\n",
      "Iteration:  50%|████▉     | 418/839 [05:05<05:02,  1.39it/s]\u001b[A\n",
      "Iteration:  50%|████▉     | 419/839 [05:06<04:59,  1.40it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 420/839 [05:07<04:57,  1.41it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 421/839 [05:07<05:03,  1.38it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 422/839 [05:08<05:02,  1.38it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 423/839 [05:09<05:03,  1.37it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 424/839 [05:10<05:03,  1.37it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 425/839 [05:10<05:06,  1.35it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 426/839 [05:11<05:04,  1.36it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 427/839 [05:12<05:00,  1.37it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 428/839 [05:12<04:57,  1.38it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 429/839 [05:13<04:53,  1.40it/s]\u001b[A\n",
      "Iteration:  51%|█████▏    | 430/839 [05:14<04:53,  1.39it/s]\u001b[A\n",
      "Iteration:  51%|█████▏    | 431/839 [05:15<04:53,  1.39it/s]\u001b[A\n",
      "Iteration:  51%|█████▏    | 432/839 [05:15<04:54,  1.38it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 433/839 [05:16<04:52,  1.39it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 434/839 [05:17<04:53,  1.38it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 435/839 [05:18<04:51,  1.39it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 436/839 [05:18<04:50,  1.39it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 437/839 [05:19<04:48,  1.39it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 438/839 [05:20<04:48,  1.39it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 439/839 [05:20<04:47,  1.39it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 440/839 [05:21<04:48,  1.38it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 441/839 [05:22<04:47,  1.38it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 442/839 [05:23<04:45,  1.39it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 443/839 [05:23<04:45,  1.39it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 444/839 [05:24<04:44,  1.39it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 445/839 [05:25<04:42,  1.39it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 446/839 [05:25<04:41,  1.40it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 447/839 [05:26<04:40,  1.40it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 448/839 [05:27<04:39,  1.40it/s]\u001b[A\n",
      "Iteration:  54%|█████▎    | 449/839 [05:28<04:39,  1.40it/s]\u001b[A\n",
      "Iteration:  54%|█████▎    | 450/839 [05:28<04:40,  1.39it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 451/839 [05:29<04:40,  1.38it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 452/839 [05:30<04:38,  1.39it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 453/839 [05:30<04:37,  1.39it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 454/839 [05:31<04:37,  1.39it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 455/839 [05:32<04:36,  1.39it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 456/839 [05:33<04:35,  1.39it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 457/839 [05:33<04:34,  1.39it/s]\u001b[A\n",
      "Iteration:  55%|█████▍    | 458/839 [05:34<04:33,  1.39it/s]\u001b[A\n",
      "Iteration:  55%|█████▍    | 459/839 [05:35<04:40,  1.35it/s]\u001b[A\n",
      "Iteration:  55%|█████▍    | 460/839 [05:36<04:39,  1.35it/s]\u001b[A01/07/2020 14:34:55 - INFO - __main__ -   Average loss: 1.3892311549186707 at global step: 1300\n",
      "\n",
      "Iteration:  55%|█████▍    | 461/839 [05:36<04:41,  1.34it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 462/839 [05:37<04:37,  1.36it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 463/839 [05:38<04:35,  1.37it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 464/839 [05:38<04:32,  1.38it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 465/839 [05:39<04:29,  1.39it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 466/839 [05:40<04:27,  1.39it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 467/839 [05:41<04:28,  1.38it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 468/839 [05:41<04:31,  1.37it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 469/839 [05:42<04:31,  1.36it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 470/839 [05:43<04:29,  1.37it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 471/839 [05:44<04:27,  1.37it/s]\u001b[A\n",
      "Iteration:  56%|█████▋    | 472/839 [05:44<04:30,  1.36it/s]\u001b[A\n",
      "Iteration:  56%|█████▋    | 473/839 [05:45<04:26,  1.37it/s]\u001b[A\n",
      "Iteration:  56%|█████▋    | 474/839 [05:46<04:27,  1.37it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 475/839 [05:47<04:26,  1.36it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 476/839 [05:47<04:23,  1.38it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 477/839 [05:48<04:22,  1.38it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 478/839 [05:49<04:21,  1.38it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 479/839 [05:49<04:20,  1.38it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 480/839 [05:50<04:17,  1.39it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 481/839 [05:51<04:17,  1.39it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 482/839 [05:52<04:17,  1.38it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 483/839 [05:52<04:17,  1.39it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 484/839 [05:53<04:15,  1.39it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 485/839 [05:54<04:16,  1.38it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 486/839 [05:54<04:14,  1.39it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 487/839 [05:55<04:14,  1.39it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 488/839 [05:56<04:16,  1.37it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 489/839 [05:57<04:13,  1.38it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 490/839 [05:57<04:14,  1.37it/s]\u001b[A\n",
      "Iteration:  59%|█████▊    | 491/839 [05:58<04:12,  1.38it/s]\u001b[A\n",
      "Iteration:  59%|█████▊    | 492/839 [05:59<04:14,  1.36it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 493/839 [06:00<04:13,  1.36it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 494/839 [06:00<04:16,  1.35it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 495/839 [06:01<04:16,  1.34it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 496/839 [06:02<04:20,  1.32it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 497/839 [06:03<04:16,  1.33it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 498/839 [06:03<04:13,  1.35it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 499/839 [06:04<04:09,  1.36it/s]\u001b[A\n",
      "Iteration:  60%|█████▉    | 500/839 [06:05<04:06,  1.37it/s]\u001b[A\n",
      "Iteration:  60%|█████▉    | 501/839 [06:06<04:06,  1.37it/s]\u001b[A\n",
      "Iteration:  60%|█████▉    | 502/839 [06:06<04:05,  1.37it/s]\u001b[A\n",
      "Iteration:  60%|█████▉    | 503/839 [06:07<04:02,  1.38it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 504/839 [06:08<04:03,  1.37it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 505/839 [06:08<04:02,  1.37it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 506/839 [06:09<04:01,  1.38it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 507/839 [06:10<04:04,  1.36it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 508/839 [06:11<04:04,  1.35it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 509/839 [06:11<04:02,  1.36it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 510/839 [06:12<03:59,  1.38it/s]\u001b[A01/07/2020 14:35:31 - INFO - __main__ -   Average loss: 1.4756448078155517 at global step: 1350\n",
      "\n",
      "Iteration:  61%|██████    | 511/839 [06:13<03:55,  1.39it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 512/839 [06:14<03:57,  1.38it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 513/839 [06:14<03:54,  1.39it/s]\u001b[A\n",
      "Iteration:  61%|██████▏   | 514/839 [06:15<03:53,  1.39it/s]\u001b[A\n",
      "Iteration:  61%|██████▏   | 515/839 [06:16<03:52,  1.39it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 516/839 [06:16<03:51,  1.39it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 517/839 [06:17<03:50,  1.39it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 518/839 [06:18<03:55,  1.36it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 519/839 [06:19<03:53,  1.37it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 520/839 [06:19<03:52,  1.37it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 521/839 [06:20<03:51,  1.37it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 522/839 [06:21<03:48,  1.39it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 523/839 [06:21<03:47,  1.39it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 524/839 [06:22<03:47,  1.38it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 525/839 [06:23<03:47,  1.38it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 526/839 [06:24<03:46,  1.38it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 527/839 [06:24<03:45,  1.38it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 528/839 [06:25<03:43,  1.39it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 529/839 [06:26<03:42,  1.39it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  63%|██████▎   | 530/839 [06:27<03:43,  1.39it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 531/839 [06:27<03:40,  1.40it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 532/839 [06:28<03:39,  1.40it/s]\u001b[A\n",
      "Iteration:  64%|██████▎   | 533/839 [06:29<03:39,  1.39it/s]\u001b[A\n",
      "Iteration:  64%|██████▎   | 534/839 [06:29<03:39,  1.39it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 535/839 [06:30<03:37,  1.40it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 536/839 [06:31<03:37,  1.39it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 537/839 [06:32<03:37,  1.39it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 538/839 [06:32<03:37,  1.39it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 539/839 [06:33<03:36,  1.39it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 540/839 [06:34<03:35,  1.39it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 541/839 [06:34<03:34,  1.39it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 542/839 [06:35<03:35,  1.38it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 543/839 [06:36<03:36,  1.37it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 544/839 [06:37<03:37,  1.36it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 545/839 [06:37<03:35,  1.36it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 546/839 [06:38<03:33,  1.37it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 547/839 [06:39<03:34,  1.36it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 548/839 [06:40<03:34,  1.36it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 549/839 [06:40<03:33,  1.36it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 550/839 [06:41<03:31,  1.37it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 551/839 [06:42<03:30,  1.37it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 552/839 [06:42<03:28,  1.37it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 553/839 [06:43<03:27,  1.38it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 554/839 [06:44<03:25,  1.39it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 555/839 [06:45<03:24,  1.39it/s]\u001b[A\n",
      "Iteration:  66%|██████▋   | 556/839 [06:45<03:25,  1.38it/s]\u001b[A\n",
      "Iteration:  66%|██████▋   | 557/839 [06:46<03:23,  1.39it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 558/839 [06:47<03:24,  1.37it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 559/839 [06:48<03:40,  1.27it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 560/839 [06:48<03:33,  1.31it/s]\u001b[A01/07/2020 14:36:08 - INFO - __main__ -   Average loss: 1.5053509759902954 at global step: 1400\n",
      "\n",
      "Iteration:  67%|██████▋   | 561/839 [06:49<03:30,  1.32it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 562/839 [06:50<03:26,  1.34it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 563/839 [06:51<03:22,  1.36it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 564/839 [06:51<03:20,  1.37it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 565/839 [06:52<03:20,  1.37it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 566/839 [06:53<03:19,  1.37it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 567/839 [06:54<03:17,  1.38it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 568/839 [06:54<03:18,  1.36it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 569/839 [06:55<03:18,  1.36it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 570/839 [06:56<03:16,  1.37it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 571/839 [06:56<03:14,  1.37it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 572/839 [06:57<03:13,  1.38it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 573/839 [06:58<03:11,  1.39it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 574/839 [06:59<03:11,  1.38it/s]\u001b[A\n",
      "Iteration:  69%|██████▊   | 575/839 [06:59<03:12,  1.37it/s]\u001b[A\n",
      "Iteration:  69%|██████▊   | 576/839 [07:00<03:11,  1.37it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 577/839 [07:01<03:11,  1.37it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 578/839 [07:02<03:09,  1.38it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 579/839 [07:02<03:06,  1.39it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 580/839 [07:03<03:05,  1.39it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 581/839 [07:04<03:04,  1.40it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 582/839 [07:04<03:04,  1.40it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 583/839 [07:05<03:03,  1.40it/s]\u001b[A\n",
      "Iteration:  70%|██████▉   | 584/839 [07:06<03:04,  1.38it/s]\u001b[A\n",
      "Iteration:  70%|██████▉   | 585/839 [07:07<03:04,  1.38it/s]\u001b[A\n",
      "Iteration:  70%|██████▉   | 586/839 [07:07<03:05,  1.37it/s]\u001b[A\n",
      "Iteration:  70%|██████▉   | 587/839 [07:08<03:05,  1.36it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 588/839 [07:09<03:03,  1.37it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 589/839 [07:09<03:01,  1.38it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 590/839 [07:10<03:01,  1.37it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 591/839 [07:11<02:58,  1.39it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 592/839 [07:12<02:56,  1.40it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 593/839 [07:12<02:58,  1.38it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 594/839 [07:13<02:59,  1.37it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 595/839 [07:14<03:01,  1.34it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 596/839 [07:15<02:59,  1.36it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 597/839 [07:15<03:00,  1.34it/s]\u001b[A\n",
      "Iteration:  71%|███████▏  | 598/839 [07:16<02:57,  1.36it/s]\u001b[A\n",
      "Iteration:  71%|███████▏  | 599/839 [07:17<02:57,  1.35it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 600/839 [07:18<02:55,  1.36it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 601/839 [07:18<02:53,  1.37it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 602/839 [07:19<02:52,  1.37it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 603/839 [07:20<02:50,  1.39it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 604/839 [07:20<02:49,  1.39it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 605/839 [07:21<02:50,  1.37it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 606/839 [07:22<02:50,  1.37it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 607/839 [07:23<02:48,  1.38it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 608/839 [07:23<02:47,  1.38it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 609/839 [07:24<02:44,  1.40it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 610/839 [07:25<02:42,  1.41it/s]\u001b[A01/07/2020 14:36:44 - INFO - __main__ -   Average loss: 1.3969742631912232 at global step: 1450\n",
      "\n",
      "Iteration:  73%|███████▎  | 611/839 [07:25<02:42,  1.41it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 612/839 [07:26<02:43,  1.39it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 613/839 [07:27<02:43,  1.38it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 614/839 [07:28<02:43,  1.37it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 615/839 [07:28<02:42,  1.38it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 616/839 [07:29<02:41,  1.38it/s]\u001b[A\n",
      "Iteration:  74%|███████▎  | 617/839 [07:30<02:44,  1.35it/s]\u001b[A\n",
      "Iteration:  74%|███████▎  | 618/839 [07:31<02:42,  1.36it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 619/839 [07:31<02:43,  1.34it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 620/839 [07:32<02:42,  1.35it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 621/839 [07:33<02:43,  1.33it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 622/839 [07:34<02:42,  1.34it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 623/839 [07:34<02:43,  1.32it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 624/839 [07:35<02:42,  1.33it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 625/839 [07:36<02:40,  1.33it/s]\u001b[A\n",
      "Iteration:  75%|███████▍  | 626/839 [07:37<02:39,  1.34it/s]\u001b[A\n",
      "Iteration:  75%|███████▍  | 627/839 [07:37<02:37,  1.34it/s]\u001b[A\n",
      "Iteration:  75%|███████▍  | 628/839 [07:38<02:36,  1.35it/s]\u001b[A\n",
      "Iteration:  75%|███████▍  | 629/839 [07:39<02:37,  1.33it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 630/839 [07:40<02:35,  1.34it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 631/839 [07:40<02:36,  1.33it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 632/839 [07:41<02:35,  1.33it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 633/839 [07:42<02:33,  1.34it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 634/839 [07:43<02:31,  1.35it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 635/839 [07:43<02:32,  1.34it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 636/839 [07:44<02:30,  1.35it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 637/839 [07:45<02:29,  1.35it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 638/839 [07:46<02:27,  1.37it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 639/839 [07:46<02:25,  1.38it/s]\u001b[A\n",
      "Iteration:  76%|███████▋  | 640/839 [07:47<02:24,  1.38it/s]\u001b[A\n",
      "Iteration:  76%|███████▋  | 641/839 [07:48<02:23,  1.38it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 642/839 [07:48<02:22,  1.38it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 643/839 [07:49<02:21,  1.38it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 644/839 [07:50<02:20,  1.39it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 645/839 [07:51<02:19,  1.39it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 646/839 [07:51<02:18,  1.40it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 647/839 [07:52<02:16,  1.41it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 648/839 [07:53<02:15,  1.41it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 649/839 [07:53<02:15,  1.40it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 650/839 [07:54<02:16,  1.38it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 651/839 [07:55<02:15,  1.38it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 652/839 [07:56<02:14,  1.39it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 653/839 [07:56<02:13,  1.39it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 654/839 [07:57<02:13,  1.39it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  78%|███████▊  | 655/839 [07:58<02:13,  1.38it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 656/839 [07:58<02:13,  1.38it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 657/839 [07:59<02:12,  1.38it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 658/839 [08:00<02:11,  1.38it/s]\u001b[A\n",
      "Iteration:  79%|███████▊  | 659/839 [08:01<02:10,  1.38it/s]\u001b[A\n",
      "Iteration:  79%|███████▊  | 660/839 [08:01<02:11,  1.36it/s]\u001b[A01/07/2020 14:37:21 - INFO - __main__ -   Average loss: 1.3854327201843262 at global step: 1500\n",
      "\n",
      "Iteration:  79%|███████▉  | 661/839 [08:02<02:11,  1.35it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 662/839 [08:03<02:09,  1.36it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 663/839 [08:04<02:07,  1.38it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 664/839 [08:04<02:06,  1.38it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 665/839 [08:05<02:05,  1.38it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 666/839 [08:06<02:04,  1.38it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 667/839 [08:06<02:04,  1.38it/s]\u001b[A\n",
      "Iteration:  80%|███████▉  | 668/839 [08:07<02:05,  1.37it/s]\u001b[A\n",
      "Iteration:  80%|███████▉  | 669/839 [08:08<02:04,  1.36it/s]\u001b[A\n",
      "Iteration:  80%|███████▉  | 670/839 [08:09<02:03,  1.37it/s]\u001b[A\n",
      "Iteration:  80%|███████▉  | 671/839 [08:09<02:02,  1.37it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 672/839 [08:10<02:01,  1.38it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 673/839 [08:11<01:59,  1.38it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 674/839 [08:12<01:59,  1.38it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 675/839 [08:12<01:59,  1.38it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 676/839 [08:13<01:58,  1.38it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 677/839 [08:14<01:57,  1.37it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 678/839 [08:14<01:57,  1.37it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 679/839 [08:15<01:55,  1.38it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 680/839 [08:16<01:54,  1.39it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 681/839 [08:17<01:54,  1.38it/s]\u001b[A\n",
      "Iteration:  81%|████████▏ | 682/839 [08:17<01:53,  1.38it/s]\u001b[A\n",
      "Iteration:  81%|████████▏ | 683/839 [08:18<01:51,  1.40it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 684/839 [08:19<01:50,  1.40it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 685/839 [08:20<01:51,  1.38it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 686/839 [08:20<01:50,  1.39it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 687/839 [08:21<01:49,  1.39it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 688/839 [08:22<01:48,  1.39it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 689/839 [08:22<01:48,  1.38it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 690/839 [08:23<01:47,  1.38it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 691/839 [08:24<01:48,  1.36it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 692/839 [08:25<01:47,  1.36it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 693/839 [08:25<01:46,  1.37it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 694/839 [08:26<01:45,  1.37it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 695/839 [08:27<01:45,  1.37it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 696/839 [08:28<01:44,  1.37it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 697/839 [08:28<01:42,  1.38it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 698/839 [08:29<01:41,  1.39it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 699/839 [08:30<01:39,  1.40it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 700/839 [08:30<01:39,  1.40it/s]\u001b[A\n",
      "Iteration:  84%|████████▎ | 701/839 [08:31<01:38,  1.40it/s]\u001b[A\n",
      "Iteration:  84%|████████▎ | 702/839 [08:32<01:39,  1.38it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 703/839 [08:33<01:37,  1.39it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 704/839 [08:33<01:36,  1.40it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 705/839 [08:34<01:35,  1.40it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 706/839 [08:35<01:34,  1.40it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 707/839 [08:35<01:34,  1.40it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 708/839 [08:36<01:33,  1.39it/s]\u001b[A\n",
      "Iteration:  85%|████████▍ | 709/839 [08:37<01:34,  1.37it/s]\u001b[A\n",
      "Iteration:  85%|████████▍ | 710/839 [08:38<01:34,  1.37it/s]\u001b[A01/07/2020 14:37:57 - INFO - __main__ -   Average loss: 1.4320767259597778 at global step: 1550\n",
      "\n",
      "Iteration:  85%|████████▍ | 711/839 [08:38<01:35,  1.34it/s]\u001b[A\n",
      "Iteration:  85%|████████▍ | 712/839 [08:39<01:33,  1.35it/s]\u001b[A\n",
      "Iteration:  85%|████████▍ | 713/839 [08:40<01:33,  1.35it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 714/839 [08:41<01:32,  1.35it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 715/839 [08:41<01:31,  1.36it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 716/839 [08:42<01:31,  1.35it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 717/839 [08:43<01:29,  1.36it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 718/839 [08:44<01:28,  1.36it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 719/839 [08:44<01:27,  1.37it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 720/839 [08:45<01:26,  1.37it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 721/839 [08:46<01:26,  1.36it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 722/839 [08:46<01:25,  1.36it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 723/839 [08:47<01:25,  1.35it/s]\u001b[A\n",
      "Iteration:  86%|████████▋ | 724/839 [08:48<01:25,  1.34it/s]\u001b[A\n",
      "Iteration:  86%|████████▋ | 725/839 [08:49<01:23,  1.36it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 726/839 [08:49<01:23,  1.36it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 727/839 [08:50<01:21,  1.37it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 728/839 [08:51<01:21,  1.37it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 729/839 [08:52<01:20,  1.37it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 730/839 [08:52<01:19,  1.37it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 731/839 [08:53<01:19,  1.36it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 732/839 [08:54<01:20,  1.33it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 733/839 [08:55<01:18,  1.35it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 734/839 [08:55<01:16,  1.36it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 735/839 [08:56<01:15,  1.38it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 736/839 [08:57<01:14,  1.39it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 737/839 [08:57<01:12,  1.40it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 738/839 [08:58<01:12,  1.39it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 739/839 [08:59<01:11,  1.39it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 740/839 [09:00<01:11,  1.39it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 741/839 [09:00<01:10,  1.39it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 742/839 [09:01<01:09,  1.40it/s]\u001b[A\n",
      "Iteration:  89%|████████▊ | 743/839 [09:02<01:08,  1.40it/s]\u001b[A\n",
      "Iteration:  89%|████████▊ | 744/839 [09:02<01:08,  1.39it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 745/839 [09:03<01:07,  1.39it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 746/839 [09:04<01:06,  1.40it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 747/839 [09:05<01:06,  1.39it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 748/839 [09:05<01:05,  1.39it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 749/839 [09:06<01:05,  1.37it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 750/839 [09:07<01:05,  1.36it/s]\u001b[A\n",
      "Iteration:  90%|████████▉ | 751/839 [09:08<01:04,  1.37it/s]\u001b[A\n",
      "Iteration:  90%|████████▉ | 752/839 [09:08<01:03,  1.38it/s]\u001b[A\n",
      "Iteration:  90%|████████▉ | 753/839 [09:09<01:02,  1.37it/s]\u001b[A\n",
      "Iteration:  90%|████████▉ | 754/839 [09:10<01:02,  1.36it/s]\u001b[A\n",
      "Iteration:  90%|████████▉ | 755/839 [09:10<01:01,  1.37it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 756/839 [09:11<01:00,  1.38it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 757/839 [09:12<00:59,  1.37it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 758/839 [09:13<00:59,  1.37it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 759/839 [09:13<00:58,  1.36it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 760/839 [09:14<00:57,  1.37it/s]\u001b[A01/07/2020 14:38:34 - INFO - __main__ -   Average loss: 1.3985833287239076 at global step: 1600\n",
      "\n",
      "Iteration:  91%|█████████ | 761/839 [09:15<00:57,  1.35it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 762/839 [09:16<00:56,  1.36it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 763/839 [09:16<00:55,  1.36it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 764/839 [09:17<00:54,  1.37it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 765/839 [09:18<00:53,  1.38it/s]\u001b[A\n",
      "Iteration:  91%|█████████▏| 766/839 [09:18<00:52,  1.38it/s]\u001b[A\n",
      "Iteration:  91%|█████████▏| 767/839 [09:19<00:51,  1.39it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 768/839 [09:20<00:51,  1.37it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 769/839 [09:21<00:51,  1.37it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 770/839 [09:21<00:50,  1.37it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 771/839 [09:22<00:49,  1.38it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 772/839 [09:23<00:48,  1.38it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 773/839 [09:24<00:47,  1.38it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 774/839 [09:24<00:47,  1.38it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 775/839 [09:25<00:46,  1.37it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 776/839 [09:26<00:45,  1.38it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 777/839 [09:26<00:45,  1.37it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  93%|█████████▎| 778/839 [09:27<00:44,  1.37it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 779/839 [09:28<00:43,  1.37it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 780/839 [09:29<00:43,  1.37it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 781/839 [09:29<00:42,  1.38it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 782/839 [09:30<00:41,  1.38it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 783/839 [09:31<00:41,  1.36it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 784/839 [09:32<00:40,  1.37it/s]\u001b[A\n",
      "Iteration:  94%|█████████▎| 785/839 [09:32<00:39,  1.36it/s]\u001b[A\n",
      "Iteration:  94%|█████████▎| 786/839 [09:33<00:38,  1.37it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 787/839 [09:34<00:37,  1.38it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 788/839 [09:35<00:37,  1.38it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 789/839 [09:35<00:36,  1.38it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 790/839 [09:36<00:35,  1.39it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 791/839 [09:37<00:34,  1.39it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 792/839 [09:37<00:33,  1.39it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 793/839 [09:38<00:33,  1.39it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 794/839 [09:39<00:32,  1.38it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 795/839 [09:40<00:32,  1.37it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 796/839 [09:40<00:31,  1.36it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 797/839 [09:41<00:30,  1.38it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 798/839 [09:42<00:29,  1.39it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 799/839 [09:42<00:28,  1.38it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 800/839 [09:43<00:28,  1.37it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 801/839 [09:44<00:27,  1.37it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 802/839 [09:45<00:26,  1.38it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 803/839 [09:45<00:26,  1.38it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 804/839 [09:46<00:25,  1.39it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 805/839 [09:47<00:24,  1.39it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 806/839 [09:48<00:23,  1.38it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 807/839 [09:48<00:23,  1.39it/s]\u001b[A\n",
      "Iteration:  96%|█████████▋| 808/839 [09:49<00:22,  1.39it/s]\u001b[A\n",
      "Iteration:  96%|█████████▋| 809/839 [09:50<00:21,  1.39it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 810/839 [09:50<00:20,  1.39it/s]\u001b[A01/07/2020 14:39:10 - INFO - __main__ -   Average loss: 1.41852268576622 at global step: 1650\n",
      "\n",
      "Iteration:  97%|█████████▋| 811/839 [09:51<00:20,  1.38it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 812/839 [09:52<00:19,  1.39it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 813/839 [09:53<00:18,  1.39it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 814/839 [09:53<00:17,  1.39it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 815/839 [09:54<00:17,  1.40it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 816/839 [09:55<00:16,  1.40it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 817/839 [09:55<00:15,  1.40it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 818/839 [09:56<00:15,  1.39it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 819/839 [09:57<00:14,  1.38it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 820/839 [09:58<00:13,  1.39it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 821/839 [09:58<00:13,  1.38it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 822/839 [09:59<00:12,  1.38it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 823/839 [10:00<00:11,  1.38it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 824/839 [10:01<00:10,  1.37it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 825/839 [10:01<00:10,  1.37it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 826/839 [10:02<00:09,  1.37it/s]\u001b[A\n",
      "Iteration:  99%|█████████▊| 827/839 [10:03<00:08,  1.38it/s]\u001b[A\n",
      "Iteration:  99%|█████████▊| 828/839 [10:03<00:07,  1.39it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 829/839 [10:04<00:07,  1.39it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 830/839 [10:05<00:06,  1.38it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 831/839 [10:06<00:05,  1.37it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 832/839 [10:06<00:05,  1.35it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 833/839 [10:07<00:04,  1.34it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 834/839 [10:08<00:03,  1.34it/s]\u001b[A\n",
      "Iteration: 100%|█████████▉| 835/839 [10:09<00:02,  1.35it/s]\u001b[A\n",
      "Iteration: 100%|█████████▉| 836/839 [10:09<00:02,  1.36it/s]\u001b[A\n",
      "Iteration: 100%|█████████▉| 837/839 [10:10<00:01,  1.36it/s]\u001b[A\n",
      "Iteration: 100%|█████████▉| 838/839 [10:11<00:00,  1.38it/s]\u001b[A\n",
      "Iteration: 100%|██████████| 839/839 [10:11<00:00,  1.37it/s]\u001b[A\n",
      "Epoch:  67%|██████▋   | 2/3 [20:24<10:12, 612.03s/it]\n",
      "Iteration:   0%|          | 0/839 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:   0%|          | 1/839 [00:00<09:56,  1.41it/s]\u001b[A\n",
      "Iteration:   0%|          | 2/839 [00:01<09:54,  1.41it/s]\u001b[A\n",
      "Iteration:   0%|          | 3/839 [00:02<09:55,  1.40it/s]\u001b[A\n",
      "Iteration:   0%|          | 4/839 [00:02<10:00,  1.39it/s]\u001b[A\n",
      "Iteration:   1%|          | 5/839 [00:03<10:03,  1.38it/s]\u001b[A\n",
      "Iteration:   1%|          | 6/839 [00:04<10:05,  1.38it/s]\u001b[A\n",
      "Iteration:   1%|          | 7/839 [00:05<10:04,  1.38it/s]\u001b[A\n",
      "Iteration:   1%|          | 8/839 [00:05<10:08,  1.36it/s]\u001b[A\n",
      "Iteration:   1%|          | 9/839 [00:06<10:09,  1.36it/s]\u001b[A\n",
      "Iteration:   1%|          | 10/839 [00:07<10:04,  1.37it/s]\u001b[A\n",
      "Iteration:   1%|▏         | 11/839 [00:07<10:02,  1.37it/s]\u001b[A\n",
      "Iteration:   1%|▏         | 12/839 [00:08<09:57,  1.38it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 13/839 [00:09<09:56,  1.39it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 14/839 [00:10<09:55,  1.39it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 15/839 [00:10<10:06,  1.36it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 16/839 [00:11<10:04,  1.36it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 17/839 [00:12<09:59,  1.37it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 18/839 [00:13<09:54,  1.38it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 19/839 [00:13<09:51,  1.39it/s]\u001b[A\n",
      "Iteration:   2%|▏         | 20/839 [00:14<09:48,  1.39it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 21/839 [00:15<09:46,  1.39it/s]\u001b[A01/07/2020 14:39:46 - INFO - __main__ -   Average loss: 1.3710638332366942 at global step: 1700\n",
      "\n",
      "Iteration:   3%|▎         | 22/839 [00:15<09:51,  1.38it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 23/839 [00:16<09:54,  1.37it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 24/839 [00:17<09:52,  1.38it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 25/839 [00:18<09:51,  1.38it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 26/839 [00:18<09:59,  1.36it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 27/839 [00:19<09:59,  1.35it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 28/839 [00:20<10:09,  1.33it/s]\u001b[A\n",
      "Iteration:   3%|▎         | 29/839 [00:21<10:07,  1.33it/s]\u001b[A\n",
      "Iteration:   4%|▎         | 30/839 [00:21<09:59,  1.35it/s]\u001b[A\n",
      "Iteration:   4%|▎         | 31/839 [00:22<09:52,  1.36it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 32/839 [00:23<09:53,  1.36it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 33/839 [00:24<09:47,  1.37it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 34/839 [00:24<09:42,  1.38it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 35/839 [00:25<09:40,  1.39it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 36/839 [00:26<09:37,  1.39it/s]\u001b[A\n",
      "Iteration:   4%|▍         | 37/839 [00:26<09:39,  1.38it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 38/839 [00:27<09:36,  1.39it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 39/839 [00:28<09:35,  1.39it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 40/839 [00:29<09:35,  1.39it/s]\u001b[A\n",
      "Iteration:   5%|▍         | 41/839 [00:29<09:32,  1.39it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 42/839 [00:30<09:33,  1.39it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 43/839 [00:31<09:32,  1.39it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 44/839 [00:31<09:31,  1.39it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 45/839 [00:32<09:31,  1.39it/s]\u001b[A\n",
      "Iteration:   5%|▌         | 46/839 [00:33<09:30,  1.39it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 47/839 [00:34<09:29,  1.39it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 48/839 [00:34<09:36,  1.37it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 49/839 [00:35<09:34,  1.37it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 50/839 [00:36<09:29,  1.39it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 51/839 [00:37<09:26,  1.39it/s]\u001b[A\n",
      "Iteration:   6%|▌         | 52/839 [00:37<09:26,  1.39it/s]\u001b[A\n",
      "Iteration:   6%|▋         | 53/839 [00:38<09:25,  1.39it/s]\u001b[A\n",
      "Iteration:   6%|▋         | 54/839 [00:39<09:25,  1.39it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 55/839 [00:39<09:24,  1.39it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 56/839 [00:40<09:22,  1.39it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 57/839 [00:41<09:20,  1.39it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 58/839 [00:42<09:19,  1.39it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 59/839 [00:42<09:18,  1.40it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 60/839 [00:43<09:18,  1.39it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 61/839 [00:44<09:18,  1.39it/s]\u001b[A\n",
      "Iteration:   7%|▋         | 62/839 [00:44<09:20,  1.39it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:   8%|▊         | 63/839 [00:45<09:18,  1.39it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 64/839 [00:46<09:19,  1.38it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 65/839 [00:47<09:21,  1.38it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 66/839 [00:47<09:26,  1.36it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 67/839 [00:48<09:22,  1.37it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 68/839 [00:49<09:17,  1.38it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 69/839 [00:49<09:14,  1.39it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 70/839 [00:50<09:12,  1.39it/s]\u001b[A\n",
      "Iteration:   8%|▊         | 71/839 [00:51<09:11,  1.39it/s]\u001b[A01/07/2020 14:40:22 - INFO - __main__ -   Average loss: 1.4366578674316406 at global step: 1750\n",
      "\n",
      "Iteration:   9%|▊         | 72/839 [00:52<09:10,  1.39it/s]\u001b[A\n",
      "Iteration:   9%|▊         | 73/839 [00:52<09:11,  1.39it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 74/839 [00:53<09:08,  1.40it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 75/839 [00:54<09:07,  1.39it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 76/839 [00:55<09:07,  1.39it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 77/839 [00:55<09:16,  1.37it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 78/839 [00:56<09:18,  1.36it/s]\u001b[A\n",
      "Iteration:   9%|▉         | 79/839 [00:57<09:15,  1.37it/s]\u001b[A\n",
      "Iteration:  10%|▉         | 80/839 [00:57<09:12,  1.37it/s]\u001b[A\n",
      "Iteration:  10%|▉         | 81/839 [00:58<09:10,  1.38it/s]\u001b[A\n",
      "Iteration:  10%|▉         | 82/839 [00:59<09:08,  1.38it/s]\u001b[A\n",
      "Iteration:  10%|▉         | 83/839 [01:00<09:05,  1.39it/s]\u001b[A\n",
      "Iteration:  10%|█         | 84/839 [01:00<09:15,  1.36it/s]\u001b[A\n",
      "Iteration:  10%|█         | 85/839 [01:01<09:14,  1.36it/s]\u001b[A\n",
      "Iteration:  10%|█         | 86/839 [01:02<09:19,  1.35it/s]\u001b[A\n",
      "Iteration:  10%|█         | 87/839 [01:03<09:16,  1.35it/s]\u001b[A\n",
      "Iteration:  10%|█         | 88/839 [01:03<09:14,  1.35it/s]\u001b[A\n",
      "Iteration:  11%|█         | 89/839 [01:04<09:22,  1.33it/s]\u001b[A\n",
      "Iteration:  11%|█         | 90/839 [01:05<09:22,  1.33it/s]\u001b[A\n",
      "Iteration:  11%|█         | 91/839 [01:06<09:15,  1.35it/s]\u001b[A\n",
      "Iteration:  11%|█         | 92/839 [01:06<09:12,  1.35it/s]\u001b[A\n",
      "Iteration:  11%|█         | 93/839 [01:07<09:05,  1.37it/s]\u001b[A\n",
      "Iteration:  11%|█         | 94/839 [01:08<09:00,  1.38it/s]\u001b[A\n",
      "Iteration:  11%|█▏        | 95/839 [01:08<08:56,  1.39it/s]\u001b[A\n",
      "Iteration:  11%|█▏        | 96/839 [01:09<08:54,  1.39it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 97/839 [01:10<08:56,  1.38it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 98/839 [01:11<08:58,  1.38it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 99/839 [01:11<08:56,  1.38it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 100/839 [01:12<08:56,  1.38it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 101/839 [01:13<09:06,  1.35it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 102/839 [01:14<09:07,  1.35it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 103/839 [01:14<09:05,  1.35it/s]\u001b[A\n",
      "Iteration:  12%|█▏        | 104/839 [01:15<09:00,  1.36it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 105/839 [01:16<09:00,  1.36it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 106/839 [01:17<08:56,  1.37it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 107/839 [01:17<08:51,  1.38it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 108/839 [01:18<08:55,  1.37it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 109/839 [01:19<08:55,  1.36it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 110/839 [01:19<08:50,  1.37it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 111/839 [01:20<08:47,  1.38it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 112/839 [01:21<08:44,  1.39it/s]\u001b[A\n",
      "Iteration:  13%|█▎        | 113/839 [01:22<08:42,  1.39it/s]\u001b[A\n",
      "Iteration:  14%|█▎        | 114/839 [01:22<08:44,  1.38it/s]\u001b[A\n",
      "Iteration:  14%|█▎        | 115/839 [01:23<08:42,  1.39it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 116/839 [01:24<08:43,  1.38it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 117/839 [01:25<08:42,  1.38it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 118/839 [01:25<08:40,  1.39it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 119/839 [01:26<08:37,  1.39it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 120/839 [01:27<08:36,  1.39it/s]\u001b[A\n",
      "Iteration:  14%|█▍        | 121/839 [01:27<08:40,  1.38it/s]\u001b[A01/07/2020 14:40:59 - INFO - __main__ -   Average loss: 1.436280575990677 at global step: 1800\n",
      "\n",
      "Iteration:  15%|█▍        | 122/839 [01:28<08:41,  1.38it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 123/839 [01:29<08:48,  1.35it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 124/839 [01:30<08:46,  1.36it/s]\u001b[A\n",
      "Iteration:  15%|█▍        | 125/839 [01:30<08:44,  1.36it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 126/839 [01:31<08:41,  1.37it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 127/839 [01:32<08:38,  1.37it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 128/839 [01:33<08:34,  1.38it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 129/839 [01:33<08:31,  1.39it/s]\u001b[A\n",
      "Iteration:  15%|█▌        | 130/839 [01:34<08:28,  1.39it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 131/839 [01:35<08:27,  1.40it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 132/839 [01:35<08:36,  1.37it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 133/839 [01:36<08:34,  1.37it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 134/839 [01:37<08:43,  1.35it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 135/839 [01:38<08:42,  1.35it/s]\u001b[A\n",
      "Iteration:  16%|█▌        | 136/839 [01:38<08:38,  1.36it/s]\u001b[A\n",
      "Iteration:  16%|█▋        | 137/839 [01:39<08:36,  1.36it/s]\u001b[A\n",
      "Iteration:  16%|█▋        | 138/839 [01:40<08:49,  1.32it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 139/839 [01:41<08:43,  1.34it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 140/839 [01:41<08:42,  1.34it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 141/839 [01:42<08:35,  1.35it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 142/839 [01:43<08:33,  1.36it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 143/839 [01:44<08:27,  1.37it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 144/839 [01:44<08:22,  1.38it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 145/839 [01:45<08:19,  1.39it/s]\u001b[A\n",
      "Iteration:  17%|█▋        | 146/839 [01:46<08:18,  1.39it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 147/839 [01:46<08:17,  1.39it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 148/839 [01:47<08:17,  1.39it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 149/839 [01:48<08:22,  1.37it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 150/839 [01:49<08:22,  1.37it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 151/839 [01:49<08:32,  1.34it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 152/839 [01:50<08:32,  1.34it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 153/839 [01:51<08:36,  1.33it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 154/839 [01:52<08:32,  1.34it/s]\u001b[A\n",
      "Iteration:  18%|█▊        | 155/839 [01:52<08:26,  1.35it/s]\u001b[A\n",
      "Iteration:  19%|█▊        | 156/839 [01:53<08:20,  1.37it/s]\u001b[A\n",
      "Iteration:  19%|█▊        | 157/839 [01:54<08:14,  1.38it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 158/839 [01:55<08:11,  1.39it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 159/839 [01:55<08:09,  1.39it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 160/839 [01:56<08:09,  1.39it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 161/839 [01:57<08:06,  1.39it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 162/839 [01:57<08:14,  1.37it/s]\u001b[A\n",
      "Iteration:  19%|█▉        | 163/839 [01:58<08:13,  1.37it/s]\u001b[A\n",
      "Iteration:  20%|█▉        | 164/839 [01:59<08:18,  1.35it/s]\u001b[A\n",
      "Iteration:  20%|█▉        | 165/839 [02:00<08:23,  1.34it/s]\u001b[A\n",
      "Iteration:  20%|█▉        | 166/839 [02:00<08:17,  1.35it/s]\u001b[A\n",
      "Iteration:  20%|█▉        | 167/839 [02:01<08:15,  1.36it/s]\u001b[A\n",
      "Iteration:  20%|██        | 168/839 [02:02<08:18,  1.34it/s]\u001b[A\n",
      "Iteration:  20%|██        | 169/839 [02:03<08:12,  1.36it/s]\u001b[A\n",
      "Iteration:  20%|██        | 170/839 [02:03<08:09,  1.37it/s]\u001b[A\n",
      "Iteration:  20%|██        | 171/839 [02:04<08:04,  1.38it/s]\u001b[A01/07/2020 14:41:35 - INFO - __main__ -   Average loss: 1.4289355230331422 at global step: 1850\n",
      "\n",
      "Iteration:  21%|██        | 172/839 [02:05<08:02,  1.38it/s]\u001b[A\n",
      "Iteration:  21%|██        | 173/839 [02:05<08:00,  1.39it/s]\u001b[A\n",
      "Iteration:  21%|██        | 174/839 [02:06<07:57,  1.39it/s]\u001b[A\n",
      "Iteration:  21%|██        | 175/839 [02:07<07:54,  1.40it/s]\u001b[A\n",
      "Iteration:  21%|██        | 176/839 [02:08<07:53,  1.40it/s]\u001b[A\n",
      "Iteration:  21%|██        | 177/839 [02:08<08:04,  1.37it/s]\u001b[A\n",
      "Iteration:  21%|██        | 178/839 [02:09<08:07,  1.36it/s]\u001b[A\n",
      "Iteration:  21%|██▏       | 179/839 [02:10<08:09,  1.35it/s]\u001b[A\n",
      "Iteration:  21%|██▏       | 180/839 [02:11<08:06,  1.35it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 181/839 [02:11<08:01,  1.37it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 182/839 [02:12<07:58,  1.37it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 183/839 [02:13<07:55,  1.38it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 184/839 [02:13<07:52,  1.39it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 185/839 [02:14<07:53,  1.38it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 186/839 [02:15<07:54,  1.38it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  22%|██▏       | 187/839 [02:16<07:51,  1.38it/s]\u001b[A\n",
      "Iteration:  22%|██▏       | 188/839 [02:16<07:53,  1.37it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 189/839 [02:17<07:52,  1.37it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 190/839 [02:18<07:58,  1.36it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 191/839 [02:19<07:54,  1.36it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 192/839 [02:19<07:52,  1.37it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 193/839 [02:20<07:51,  1.37it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 194/839 [02:21<07:47,  1.38it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 195/839 [02:21<07:45,  1.38it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 196/839 [02:22<07:42,  1.39it/s]\u001b[A\n",
      "Iteration:  23%|██▎       | 197/839 [02:23<07:44,  1.38it/s]\u001b[A\n",
      "Iteration:  24%|██▎       | 198/839 [02:24<07:42,  1.38it/s]\u001b[A\n",
      "Iteration:  24%|██▎       | 199/839 [02:24<07:49,  1.36it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 200/839 [02:25<07:46,  1.37it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 201/839 [02:26<07:42,  1.38it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 202/839 [02:27<07:40,  1.38it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 203/839 [02:27<07:37,  1.39it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 204/839 [02:28<07:35,  1.39it/s]\u001b[A\n",
      "Iteration:  24%|██▍       | 205/839 [02:29<07:34,  1.40it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 206/839 [02:29<07:33,  1.40it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 207/839 [02:30<07:33,  1.39it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 208/839 [02:31<07:40,  1.37it/s]\u001b[A\n",
      "Iteration:  25%|██▍       | 209/839 [02:32<07:39,  1.37it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 210/839 [02:32<07:47,  1.35it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 211/839 [02:33<07:45,  1.35it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 212/839 [02:34<07:48,  1.34it/s]\u001b[A\n",
      "Iteration:  25%|██▌       | 213/839 [02:35<07:43,  1.35it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 214/839 [02:35<07:41,  1.35it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 215/839 [02:36<07:37,  1.37it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 216/839 [02:37<07:36,  1.37it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 217/839 [02:38<07:34,  1.37it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 218/839 [02:38<07:31,  1.38it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 219/839 [02:39<07:28,  1.38it/s]\u001b[A\n",
      "Iteration:  26%|██▌       | 220/839 [02:40<07:26,  1.39it/s]\u001b[A\n",
      "Iteration:  26%|██▋       | 221/839 [02:40<07:24,  1.39it/s]\u001b[A01/07/2020 14:42:12 - INFO - __main__ -   Average loss: 1.4287010931968689 at global step: 1900\n",
      "\n",
      "Iteration:  26%|██▋       | 222/839 [02:41<07:28,  1.38it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 223/839 [02:42<07:37,  1.35it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 224/839 [02:43<07:36,  1.35it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 225/839 [02:43<07:45,  1.32it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 226/839 [02:44<07:41,  1.33it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 227/839 [02:45<07:37,  1.34it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 228/839 [02:46<07:32,  1.35it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 229/839 [02:46<07:25,  1.37it/s]\u001b[A\n",
      "Iteration:  27%|██▋       | 230/839 [02:47<07:20,  1.38it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 231/839 [02:48<07:17,  1.39it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 232/839 [02:48<07:15,  1.40it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 233/839 [02:49<07:14,  1.39it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 234/839 [02:50<07:13,  1.40it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 235/839 [02:51<07:12,  1.40it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 236/839 [02:51<07:19,  1.37it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 237/839 [02:52<07:18,  1.37it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 238/839 [02:53<07:18,  1.37it/s]\u001b[A\n",
      "Iteration:  28%|██▊       | 239/839 [02:54<07:15,  1.38it/s]\u001b[A\n",
      "Iteration:  29%|██▊       | 240/839 [02:54<07:10,  1.39it/s]\u001b[A\n",
      "Iteration:  29%|██▊       | 241/839 [02:55<07:10,  1.39it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 242/839 [02:56<07:10,  1.39it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 243/839 [02:56<07:06,  1.40it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 244/839 [02:57<07:08,  1.39it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 245/839 [02:58<07:17,  1.36it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 246/839 [02:59<07:19,  1.35it/s]\u001b[A\n",
      "Iteration:  29%|██▉       | 247/839 [02:59<07:15,  1.36it/s]\u001b[A\n",
      "Iteration:  30%|██▉       | 248/839 [03:00<07:11,  1.37it/s]\u001b[A\n",
      "Iteration:  30%|██▉       | 249/839 [03:01<07:15,  1.36it/s]\u001b[A\n",
      "Iteration:  30%|██▉       | 250/839 [03:02<07:11,  1.36it/s]\u001b[A\n",
      "Iteration:  30%|██▉       | 251/839 [03:02<07:10,  1.37it/s]\u001b[A\n",
      "Iteration:  30%|███       | 252/839 [03:03<07:07,  1.37it/s]\u001b[A\n",
      "Iteration:  30%|███       | 253/839 [03:04<07:03,  1.38it/s]\u001b[A\n",
      "Iteration:  30%|███       | 254/839 [03:04<07:02,  1.38it/s]\u001b[A\n",
      "Iteration:  30%|███       | 255/839 [03:05<07:01,  1.39it/s]\u001b[A\n",
      "Iteration:  31%|███       | 256/839 [03:06<07:03,  1.38it/s]\u001b[A\n",
      "Iteration:  31%|███       | 257/839 [03:07<07:03,  1.37it/s]\u001b[A\n",
      "Iteration:  31%|███       | 258/839 [03:07<07:01,  1.38it/s]\u001b[A\n",
      "Iteration:  31%|███       | 259/839 [03:08<06:59,  1.38it/s]\u001b[A\n",
      "Iteration:  31%|███       | 260/839 [03:09<07:03,  1.37it/s]\u001b[A\n",
      "Iteration:  31%|███       | 261/839 [03:10<07:00,  1.37it/s]\u001b[A\n",
      "Iteration:  31%|███       | 262/839 [03:10<06:56,  1.38it/s]\u001b[A\n",
      "Iteration:  31%|███▏      | 263/839 [03:11<06:58,  1.38it/s]\u001b[A\n",
      "Iteration:  31%|███▏      | 264/839 [03:12<06:57,  1.38it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 265/839 [03:12<06:57,  1.37it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 266/839 [03:13<06:56,  1.38it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 267/839 [03:14<06:57,  1.37it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 268/839 [03:15<06:57,  1.37it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 269/839 [03:15<06:55,  1.37it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 270/839 [03:16<06:52,  1.38it/s]\u001b[A\n",
      "Iteration:  32%|███▏      | 271/839 [03:17<06:50,  1.38it/s]\u001b[A01/07/2020 14:42:48 - INFO - __main__ -   Average loss: 1.4376867461204528 at global step: 1950\n",
      "\n",
      "Iteration:  32%|███▏      | 272/839 [03:18<06:50,  1.38it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 273/839 [03:18<06:49,  1.38it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 274/839 [03:19<06:46,  1.39it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 275/839 [03:20<06:44,  1.39it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 276/839 [03:20<06:44,  1.39it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 277/839 [03:21<06:42,  1.40it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 278/839 [03:22<06:41,  1.40it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 279/839 [03:23<06:41,  1.40it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 280/839 [03:23<06:39,  1.40it/s]\u001b[A\n",
      "Iteration:  33%|███▎      | 281/839 [03:24<06:40,  1.39it/s]\u001b[A\n",
      "Iteration:  34%|███▎      | 282/839 [03:25<06:38,  1.40it/s]\u001b[A\n",
      "Iteration:  34%|███▎      | 283/839 [03:25<06:37,  1.40it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 284/839 [03:26<06:37,  1.40it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 285/839 [03:27<06:44,  1.37it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 286/839 [03:28<06:44,  1.37it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 287/839 [03:28<06:44,  1.37it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 288/839 [03:29<06:44,  1.36it/s]\u001b[A\n",
      "Iteration:  34%|███▍      | 289/839 [03:30<06:45,  1.36it/s]\u001b[A\n",
      "Iteration:  35%|███▍      | 290/839 [03:31<06:43,  1.36it/s]\u001b[A\n",
      "Iteration:  35%|███▍      | 291/839 [03:31<06:38,  1.38it/s]\u001b[A\n",
      "Iteration:  35%|███▍      | 292/839 [03:32<06:33,  1.39it/s]\u001b[A\n",
      "Iteration:  35%|███▍      | 293/839 [03:33<06:32,  1.39it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 294/839 [03:33<06:33,  1.39it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 295/839 [03:34<06:31,  1.39it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 296/839 [03:35<06:31,  1.39it/s]\u001b[A\n",
      "Iteration:  35%|███▌      | 297/839 [03:36<06:31,  1.38it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 298/839 [03:36<06:31,  1.38it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 299/839 [03:37<06:30,  1.38it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 300/839 [03:38<06:30,  1.38it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 301/839 [03:38<06:28,  1.39it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 302/839 [03:39<06:26,  1.39it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 303/839 [03:40<06:30,  1.37it/s]\u001b[A\n",
      "Iteration:  36%|███▌      | 304/839 [03:41<06:33,  1.36it/s]\u001b[A\n",
      "Iteration:  36%|███▋      | 305/839 [03:41<06:29,  1.37it/s]\u001b[A\n",
      "Iteration:  36%|███▋      | 306/839 [03:42<06:27,  1.38it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 307/839 [03:43<06:33,  1.35it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 308/839 [03:44<06:28,  1.37it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 309/839 [03:44<06:31,  1.35it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 310/839 [03:45<06:27,  1.36it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 311/839 [03:46<06:25,  1.37it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  37%|███▋      | 312/839 [03:47<06:21,  1.38it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 313/839 [03:47<06:21,  1.38it/s]\u001b[A\n",
      "Iteration:  37%|███▋      | 314/839 [03:48<06:21,  1.38it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 315/839 [03:49<06:20,  1.38it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 316/839 [03:49<06:17,  1.38it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 317/839 [03:50<06:18,  1.38it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 318/839 [03:51<06:17,  1.38it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 319/839 [03:52<06:18,  1.37it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 320/839 [03:52<06:20,  1.36it/s]\u001b[A\n",
      "Iteration:  38%|███▊      | 321/839 [03:53<06:18,  1.37it/s]\u001b[A01/07/2020 14:43:24 - INFO - __main__ -   Average loss: 1.392681860923767 at global step: 2000\n",
      "01/07/2020 14:43:24 - INFO - src.transformers.configuration_utils -   Configuration saved in save/checkpoint-2000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save/\n",
      "save/checkpoint-2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/07/2020 14:43:27 - INFO - src.transformers.modeling_utils -   Model weights saved in save/checkpoint-2000/pytorch_model.bin\n",
      "01/07/2020 14:43:27 - INFO - __main__ -   Saving model checkpoint to save/checkpoint-2000\n",
      "\n",
      "Iteration:  38%|███▊      | 322/839 [03:56<11:50,  1.37s/it]\u001b[A\n",
      "Iteration:  38%|███▊      | 323/839 [03:57<10:06,  1.18s/it]\u001b[A\n",
      "Iteration:  39%|███▊      | 324/839 [03:57<08:54,  1.04s/it]\u001b[A\n",
      "Iteration:  39%|███▊      | 325/839 [03:58<08:03,  1.06it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 326/839 [03:59<07:35,  1.13it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 327/839 [04:00<07:09,  1.19it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 328/839 [04:00<06:48,  1.25it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 329/839 [04:01<06:33,  1.29it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 330/839 [04:02<06:24,  1.32it/s]\u001b[A\n",
      "Iteration:  39%|███▉      | 331/839 [04:02<06:17,  1.35it/s]\u001b[A\n",
      "Iteration:  40%|███▉      | 332/839 [04:03<06:13,  1.36it/s]\u001b[A\n",
      "Iteration:  40%|███▉      | 333/839 [04:04<06:09,  1.37it/s]\u001b[A\n",
      "Iteration:  40%|███▉      | 334/839 [04:05<06:06,  1.38it/s]\u001b[A\n",
      "Iteration:  40%|███▉      | 335/839 [04:05<06:07,  1.37it/s]\u001b[A\n",
      "Iteration:  40%|████      | 336/839 [04:06<06:06,  1.37it/s]\u001b[A\n",
      "Iteration:  40%|████      | 337/839 [04:07<06:04,  1.38it/s]\u001b[A\n",
      "Iteration:  40%|████      | 338/839 [04:07<06:01,  1.39it/s]\u001b[A\n",
      "Iteration:  40%|████      | 339/839 [04:08<06:01,  1.38it/s]\u001b[A\n",
      "Iteration:  41%|████      | 340/839 [04:09<06:01,  1.38it/s]\u001b[A\n",
      "Iteration:  41%|████      | 341/839 [04:10<06:00,  1.38it/s]\u001b[A\n",
      "Iteration:  41%|████      | 342/839 [04:10<06:01,  1.38it/s]\u001b[A\n",
      "Iteration:  41%|████      | 343/839 [04:11<06:02,  1.37it/s]\u001b[A\n",
      "Iteration:  41%|████      | 344/839 [04:12<06:01,  1.37it/s]\u001b[A\n",
      "Iteration:  41%|████      | 345/839 [04:13<05:59,  1.38it/s]\u001b[A\n",
      "Iteration:  41%|████      | 346/839 [04:13<05:57,  1.38it/s]\u001b[A\n",
      "Iteration:  41%|████▏     | 347/839 [04:14<05:56,  1.38it/s]\u001b[A\n",
      "Iteration:  41%|████▏     | 348/839 [04:15<05:55,  1.38it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 349/839 [04:15<05:53,  1.39it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 350/839 [04:16<05:52,  1.39it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 351/839 [04:17<05:51,  1.39it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 352/839 [04:18<05:51,  1.39it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 353/839 [04:18<06:01,  1.34it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 354/839 [04:19<06:01,  1.34it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 355/839 [04:20<06:00,  1.34it/s]\u001b[A\n",
      "Iteration:  42%|████▏     | 356/839 [04:21<05:56,  1.36it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 357/839 [04:21<05:59,  1.34it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 358/839 [04:22<05:55,  1.35it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 359/839 [04:23<05:54,  1.35it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 360/839 [04:24<05:51,  1.36it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 361/839 [04:24<05:48,  1.37it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 362/839 [04:25<05:45,  1.38it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 363/839 [04:26<05:43,  1.39it/s]\u001b[A\n",
      "Iteration:  43%|████▎     | 364/839 [04:26<05:42,  1.39it/s]\u001b[A\n",
      "Iteration:  44%|████▎     | 365/839 [04:27<05:41,  1.39it/s]\u001b[A\n",
      "Iteration:  44%|████▎     | 366/839 [04:28<05:39,  1.39it/s]\u001b[A\n",
      "Iteration:  44%|████▎     | 367/839 [04:29<05:45,  1.37it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 368/839 [04:29<05:45,  1.36it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 369/839 [04:30<05:43,  1.37it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 370/839 [04:31<05:44,  1.36it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 371/839 [04:32<05:41,  1.37it/s]\u001b[A01/07/2020 14:44:03 - INFO - __main__ -   Average loss: 1.4193358933925628 at global step: 2050\n",
      "\n",
      "Iteration:  44%|████▍     | 372/839 [04:32<05:39,  1.38it/s]\u001b[A\n",
      "Iteration:  44%|████▍     | 373/839 [04:33<05:37,  1.38it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 374/839 [04:34<05:35,  1.39it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 375/839 [04:34<05:33,  1.39it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 376/839 [04:35<05:32,  1.39it/s]\u001b[A\n",
      "Iteration:  45%|████▍     | 377/839 [04:36<05:31,  1.39it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 378/839 [04:37<05:30,  1.40it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 379/839 [04:37<05:32,  1.38it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 380/839 [04:38<05:29,  1.39it/s]\u001b[A\n",
      "Iteration:  45%|████▌     | 381/839 [04:39<05:30,  1.38it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 382/839 [04:39<05:28,  1.39it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 383/839 [04:40<05:26,  1.39it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 384/839 [04:41<05:28,  1.39it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 385/839 [04:42<05:30,  1.37it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 386/839 [04:42<05:32,  1.36it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 387/839 [04:43<05:32,  1.36it/s]\u001b[A\n",
      "Iteration:  46%|████▌     | 388/839 [04:44<05:33,  1.35it/s]\u001b[A\n",
      "Iteration:  46%|████▋     | 389/839 [04:45<05:28,  1.37it/s]\u001b[A\n",
      "Iteration:  46%|████▋     | 390/839 [04:45<05:29,  1.36it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 391/839 [04:46<05:28,  1.36it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 392/839 [04:47<05:25,  1.37it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 393/839 [04:48<05:22,  1.38it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 394/839 [04:48<05:18,  1.40it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 395/839 [04:49<05:21,  1.38it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 396/839 [04:50<05:20,  1.38it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 397/839 [04:50<05:20,  1.38it/s]\u001b[A\n",
      "Iteration:  47%|████▋     | 398/839 [04:51<05:17,  1.39it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 399/839 [04:52<05:23,  1.36it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 400/839 [04:53<05:22,  1.36it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 401/839 [04:53<05:23,  1.36it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 402/839 [04:54<05:21,  1.36it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 403/839 [04:55<05:18,  1.37it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 404/839 [04:56<05:16,  1.37it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 405/839 [04:56<05:19,  1.36it/s]\u001b[A\n",
      "Iteration:  48%|████▊     | 406/839 [04:57<05:19,  1.35it/s]\u001b[A\n",
      "Iteration:  49%|████▊     | 407/839 [04:58<05:15,  1.37it/s]\u001b[A\n",
      "Iteration:  49%|████▊     | 408/839 [04:58<05:15,  1.37it/s]\u001b[A\n",
      "Iteration:  49%|████▊     | 409/839 [04:59<05:13,  1.37it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 410/839 [05:00<05:10,  1.38it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 411/839 [05:01<05:09,  1.38it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 412/839 [05:01<05:07,  1.39it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 413/839 [05:02<05:06,  1.39it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 414/839 [05:03<05:05,  1.39it/s]\u001b[A\n",
      "Iteration:  49%|████▉     | 415/839 [05:04<05:03,  1.40it/s]\u001b[A\n",
      "Iteration:  50%|████▉     | 416/839 [05:04<05:02,  1.40it/s]\u001b[A\n",
      "Iteration:  50%|████▉     | 417/839 [05:05<05:02,  1.39it/s]\u001b[A\n",
      "Iteration:  50%|████▉     | 418/839 [05:06<05:01,  1.39it/s]\u001b[A\n",
      "Iteration:  50%|████▉     | 419/839 [05:06<05:02,  1.39it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 420/839 [05:07<05:02,  1.39it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 421/839 [05:08<05:04,  1.37it/s]\u001b[A01/07/2020 14:44:39 - INFO - __main__ -   Average loss: 1.3685736060142517 at global step: 2100\n",
      "\n",
      "Iteration:  50%|█████     | 422/839 [05:09<05:05,  1.36it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 423/839 [05:09<05:05,  1.36it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 424/839 [05:10<05:08,  1.35it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 425/839 [05:11<05:08,  1.34it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 426/839 [05:12<05:05,  1.35it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 427/839 [05:12<05:02,  1.36it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 428/839 [05:13<04:59,  1.37it/s]\u001b[A\n",
      "Iteration:  51%|█████     | 429/839 [05:14<04:59,  1.37it/s]\u001b[A\n",
      "Iteration:  51%|█████▏    | 430/839 [05:14<04:59,  1.37it/s]\u001b[A\n",
      "Iteration:  51%|█████▏    | 431/839 [05:15<04:56,  1.37it/s]\u001b[A\n",
      "Iteration:  51%|█████▏    | 432/839 [05:16<04:55,  1.38it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 433/839 [05:17<04:53,  1.38it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 434/839 [05:17<04:56,  1.37it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 435/839 [05:18<04:55,  1.37it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 436/839 [05:19<04:54,  1.37it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 437/839 [05:20<04:53,  1.37it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 438/839 [05:20<04:51,  1.37it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 439/839 [05:21<04:51,  1.37it/s]\u001b[A\n",
      "Iteration:  52%|█████▏    | 440/839 [05:22<04:51,  1.37it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 441/839 [05:22<04:48,  1.38it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 442/839 [05:23<04:47,  1.38it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  53%|█████▎    | 443/839 [05:24<04:47,  1.38it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 444/839 [05:25<04:45,  1.38it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 445/839 [05:25<04:51,  1.35it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 446/839 [05:26<04:49,  1.36it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 447/839 [05:27<04:51,  1.34it/s]\u001b[A\n",
      "Iteration:  53%|█████▎    | 448/839 [05:28<04:48,  1.35it/s]\u001b[A\n",
      "Iteration:  54%|█████▎    | 449/839 [05:28<04:48,  1.35it/s]\u001b[A\n",
      "Iteration:  54%|█████▎    | 450/839 [05:29<04:44,  1.37it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 451/839 [05:30<04:42,  1.37it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 452/839 [05:31<04:41,  1.38it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 453/839 [05:31<04:39,  1.38it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 454/839 [05:32<04:37,  1.39it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 455/839 [05:33<04:35,  1.39it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 456/839 [05:33<04:36,  1.39it/s]\u001b[A\n",
      "Iteration:  54%|█████▍    | 457/839 [05:34<04:36,  1.38it/s]\u001b[A\n",
      "Iteration:  55%|█████▍    | 458/839 [05:35<04:37,  1.37it/s]\u001b[A\n",
      "Iteration:  55%|█████▍    | 459/839 [05:36<04:35,  1.38it/s]\u001b[A\n",
      "Iteration:  55%|█████▍    | 460/839 [05:36<04:34,  1.38it/s]\u001b[A\n",
      "Iteration:  55%|█████▍    | 461/839 [05:37<04:31,  1.39it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 462/839 [05:38<04:30,  1.40it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 463/839 [05:38<04:30,  1.39it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 464/839 [05:39<04:32,  1.38it/s]\u001b[A\n",
      "Iteration:  55%|█████▌    | 465/839 [05:40<04:29,  1.39it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 466/839 [05:41<04:28,  1.39it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 467/839 [05:41<04:29,  1.38it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 468/839 [05:42<04:28,  1.38it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 469/839 [05:43<04:30,  1.37it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 470/839 [05:44<04:30,  1.36it/s]\u001b[A\n",
      "Iteration:  56%|█████▌    | 471/839 [05:44<04:27,  1.37it/s]\u001b[A01/07/2020 14:45:16 - INFO - __main__ -   Average loss: 1.3918996739387512 at global step: 2150\n",
      "\n",
      "Iteration:  56%|█████▋    | 472/839 [05:45<04:24,  1.39it/s]\u001b[A\n",
      "Iteration:  56%|█████▋    | 473/839 [05:46<04:21,  1.40it/s]\u001b[A\n",
      "Iteration:  56%|█████▋    | 474/839 [05:46<04:20,  1.40it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 475/839 [05:47<04:20,  1.40it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 476/839 [05:48<04:20,  1.39it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 477/839 [05:49<04:21,  1.38it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 478/839 [05:49<04:21,  1.38it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 479/839 [05:50<04:20,  1.38it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 480/839 [05:51<04:18,  1.39it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 481/839 [05:51<04:19,  1.38it/s]\u001b[A\n",
      "Iteration:  57%|█████▋    | 482/839 [05:52<04:20,  1.37it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 483/839 [05:53<04:18,  1.38it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 484/839 [05:54<04:17,  1.38it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 485/839 [05:54<04:16,  1.38it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 486/839 [05:55<04:17,  1.37it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 487/839 [05:56<04:19,  1.35it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 488/839 [05:57<04:17,  1.36it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 489/839 [05:57<04:18,  1.35it/s]\u001b[A\n",
      "Iteration:  58%|█████▊    | 490/839 [05:58<04:18,  1.35it/s]\u001b[A\n",
      "Iteration:  59%|█████▊    | 491/839 [05:59<04:15,  1.36it/s]\u001b[A\n",
      "Iteration:  59%|█████▊    | 492/839 [06:00<04:13,  1.37it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 493/839 [06:00<04:11,  1.38it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 494/839 [06:01<04:09,  1.38it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 495/839 [06:02<04:09,  1.38it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 496/839 [06:02<04:08,  1.38it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 497/839 [06:03<04:06,  1.39it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 498/839 [06:04<04:09,  1.37it/s]\u001b[A\n",
      "Iteration:  59%|█████▉    | 499/839 [06:05<04:07,  1.37it/s]\u001b[A\n",
      "Iteration:  60%|█████▉    | 500/839 [06:05<04:11,  1.35it/s]\u001b[A\n",
      "Iteration:  60%|█████▉    | 501/839 [06:06<04:09,  1.35it/s]\u001b[A\n",
      "Iteration:  60%|█████▉    | 502/839 [06:07<04:09,  1.35it/s]\u001b[A\n",
      "Iteration:  60%|█████▉    | 503/839 [06:08<04:07,  1.36it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 504/839 [06:08<04:04,  1.37it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 505/839 [06:09<04:02,  1.38it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 506/839 [06:10<04:00,  1.38it/s]\u001b[A\n",
      "Iteration:  60%|██████    | 507/839 [06:10<04:01,  1.37it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 508/839 [06:11<04:03,  1.36it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 509/839 [06:12<04:01,  1.37it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 510/839 [06:13<03:58,  1.38it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 511/839 [06:13<03:57,  1.38it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 512/839 [06:14<03:56,  1.39it/s]\u001b[A\n",
      "Iteration:  61%|██████    | 513/839 [06:15<03:55,  1.39it/s]\u001b[A\n",
      "Iteration:  61%|██████▏   | 514/839 [06:16<03:55,  1.38it/s]\u001b[A\n",
      "Iteration:  61%|██████▏   | 515/839 [06:16<03:53,  1.39it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 516/839 [06:17<03:52,  1.39it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 517/839 [06:18<03:51,  1.39it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 518/839 [06:18<03:51,  1.39it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 519/839 [06:19<03:50,  1.39it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 520/839 [06:20<03:53,  1.37it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 521/839 [06:21<03:52,  1.37it/s]\u001b[A01/07/2020 14:45:52 - INFO - __main__ -   Average loss: 1.4313869047164918 at global step: 2200\n",
      "\n",
      "Iteration:  62%|██████▏   | 522/839 [06:21<03:53,  1.36it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 523/839 [06:22<03:50,  1.37it/s]\u001b[A\n",
      "Iteration:  62%|██████▏   | 524/839 [06:23<03:48,  1.38it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 525/839 [06:24<03:47,  1.38it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 526/839 [06:24<03:47,  1.38it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 527/839 [06:25<03:47,  1.37it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 528/839 [06:26<03:47,  1.37it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 529/839 [06:26<03:47,  1.36it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 530/839 [06:27<03:45,  1.37it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 531/839 [06:28<03:44,  1.37it/s]\u001b[A\n",
      "Iteration:  63%|██████▎   | 532/839 [06:29<03:45,  1.36it/s]\u001b[A\n",
      "Iteration:  64%|██████▎   | 533/839 [06:29<03:43,  1.37it/s]\u001b[A\n",
      "Iteration:  64%|██████▎   | 534/839 [06:30<03:41,  1.38it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 535/839 [06:31<03:44,  1.36it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 536/839 [06:32<03:44,  1.35it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 537/839 [06:32<03:47,  1.33it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 538/839 [06:33<03:44,  1.34it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 539/839 [06:34<03:44,  1.34it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 540/839 [06:35<03:41,  1.35it/s]\u001b[A\n",
      "Iteration:  64%|██████▍   | 541/839 [06:35<03:42,  1.34it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 542/839 [06:36<03:40,  1.35it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 543/839 [06:37<03:37,  1.36it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 544/839 [06:38<03:34,  1.37it/s]\u001b[A\n",
      "Iteration:  65%|██████▍   | 545/839 [06:38<03:32,  1.38it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 546/839 [06:39<03:33,  1.37it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 547/839 [06:40<03:32,  1.37it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 548/839 [06:40<03:30,  1.38it/s]\u001b[A\n",
      "Iteration:  65%|██████▌   | 549/839 [06:41<03:30,  1.38it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 550/839 [06:42<03:29,  1.38it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 551/839 [06:43<03:28,  1.38it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 552/839 [06:43<03:27,  1.38it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 553/839 [06:44<03:27,  1.38it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 554/839 [06:45<03:27,  1.38it/s]\u001b[A\n",
      "Iteration:  66%|██████▌   | 555/839 [06:46<03:25,  1.38it/s]\u001b[A\n",
      "Iteration:  66%|██████▋   | 556/839 [06:46<03:24,  1.38it/s]\u001b[A\n",
      "Iteration:  66%|██████▋   | 557/839 [06:47<03:23,  1.39it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 558/839 [06:48<03:22,  1.39it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 559/839 [06:48<03:21,  1.39it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 560/839 [06:49<03:21,  1.38it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 561/839 [06:50<03:20,  1.39it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 562/839 [06:51<03:19,  1.39it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 563/839 [06:51<03:18,  1.39it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 564/839 [06:52<03:20,  1.37it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 565/839 [06:53<03:19,  1.37it/s]\u001b[A\n",
      "Iteration:  67%|██████▋   | 566/839 [06:53<03:19,  1.37it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 567/839 [06:54<03:18,  1.37it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  68%|██████▊   | 568/839 [06:55<03:20,  1.35it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 569/839 [06:56<03:18,  1.36it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 570/839 [06:56<03:16,  1.37it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 571/839 [06:57<03:14,  1.38it/s]\u001b[A01/07/2020 14:46:29 - INFO - __main__ -   Average loss: 1.4209796690940857 at global step: 2250\n",
      "\n",
      "Iteration:  68%|██████▊   | 572/839 [06:58<03:15,  1.37it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 573/839 [06:59<03:13,  1.38it/s]\u001b[A\n",
      "Iteration:  68%|██████▊   | 574/839 [06:59<03:10,  1.39it/s]\u001b[A\n",
      "Iteration:  69%|██████▊   | 575/839 [07:00<03:09,  1.39it/s]\u001b[A\n",
      "Iteration:  69%|██████▊   | 576/839 [07:01<03:08,  1.40it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 577/839 [07:01<03:10,  1.38it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 578/839 [07:02<03:10,  1.37it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 579/839 [07:03<03:09,  1.37it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 580/839 [07:04<03:08,  1.37it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 581/839 [07:04<03:09,  1.36it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 582/839 [07:05<03:07,  1.37it/s]\u001b[A\n",
      "Iteration:  69%|██████▉   | 583/839 [07:06<03:07,  1.37it/s]\u001b[A\n",
      "Iteration:  70%|██████▉   | 584/839 [07:07<03:05,  1.37it/s]\u001b[A\n",
      "Iteration:  70%|██████▉   | 585/839 [07:07<03:03,  1.39it/s]\u001b[A\n",
      "Iteration:  70%|██████▉   | 586/839 [07:08<03:02,  1.39it/s]\u001b[A\n",
      "Iteration:  70%|██████▉   | 587/839 [07:09<03:00,  1.39it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 588/839 [07:09<03:00,  1.39it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 589/839 [07:10<02:59,  1.39it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 590/839 [07:11<03:02,  1.36it/s]\u001b[A\n",
      "Iteration:  70%|███████   | 591/839 [07:12<03:00,  1.37it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 592/839 [07:12<03:01,  1.36it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 593/839 [07:13<02:59,  1.37it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 594/839 [07:14<02:58,  1.37it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 595/839 [07:15<02:57,  1.37it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 596/839 [07:15<02:55,  1.39it/s]\u001b[A\n",
      "Iteration:  71%|███████   | 597/839 [07:16<02:56,  1.37it/s]\u001b[A\n",
      "Iteration:  71%|███████▏  | 598/839 [07:17<02:55,  1.37it/s]\u001b[A\n",
      "Iteration:  71%|███████▏  | 599/839 [07:17<02:55,  1.37it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 600/839 [07:18<02:53,  1.38it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 601/839 [07:19<02:52,  1.38it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 602/839 [07:20<02:51,  1.39it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 603/839 [07:20<02:50,  1.38it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 604/839 [07:21<02:49,  1.39it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 605/839 [07:22<02:47,  1.39it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 606/839 [07:22<02:46,  1.40it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 607/839 [07:23<02:46,  1.40it/s]\u001b[A\n",
      "Iteration:  72%|███████▏  | 608/839 [07:24<02:45,  1.39it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 609/839 [07:25<02:45,  1.39it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 610/839 [07:25<02:46,  1.37it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 611/839 [07:26<02:45,  1.37it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 612/839 [07:27<02:48,  1.34it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 613/839 [07:28<02:47,  1.35it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 614/839 [07:28<02:48,  1.33it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 615/839 [07:29<02:45,  1.35it/s]\u001b[A\n",
      "Iteration:  73%|███████▎  | 616/839 [07:30<02:44,  1.36it/s]\u001b[A\n",
      "Iteration:  74%|███████▎  | 617/839 [07:31<02:43,  1.36it/s]\u001b[A\n",
      "Iteration:  74%|███████▎  | 618/839 [07:31<02:41,  1.37it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 619/839 [07:32<02:39,  1.38it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 620/839 [07:33<02:38,  1.38it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 621/839 [07:33<02:36,  1.39it/s]\u001b[A01/07/2020 14:47:05 - INFO - __main__ -   Average loss: 1.3734148907661439 at global step: 2300\n",
      "\n",
      "Iteration:  74%|███████▍  | 622/839 [07:34<02:37,  1.37it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 623/839 [07:35<02:37,  1.37it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 624/839 [07:36<02:36,  1.37it/s]\u001b[A\n",
      "Iteration:  74%|███████▍  | 625/839 [07:36<02:35,  1.38it/s]\u001b[A\n",
      "Iteration:  75%|███████▍  | 626/839 [07:37<02:34,  1.38it/s]\u001b[A\n",
      "Iteration:  75%|███████▍  | 627/839 [07:38<02:33,  1.38it/s]\u001b[A\n",
      "Iteration:  75%|███████▍  | 628/839 [07:39<02:33,  1.37it/s]\u001b[A\n",
      "Iteration:  75%|███████▍  | 629/839 [07:39<02:31,  1.38it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 630/839 [07:40<02:29,  1.40it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 631/839 [07:41<02:29,  1.39it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 632/839 [07:41<02:28,  1.39it/s]\u001b[A\n",
      "Iteration:  75%|███████▌  | 633/839 [07:42<02:27,  1.39it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 634/839 [07:43<02:31,  1.35it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 635/839 [07:44<02:30,  1.35it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 636/839 [07:44<02:28,  1.36it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 637/839 [07:45<02:27,  1.37it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 638/839 [07:46<02:26,  1.38it/s]\u001b[A\n",
      "Iteration:  76%|███████▌  | 639/839 [07:47<02:25,  1.38it/s]\u001b[A\n",
      "Iteration:  76%|███████▋  | 640/839 [07:47<02:24,  1.38it/s]\u001b[A\n",
      "Iteration:  76%|███████▋  | 641/839 [07:48<02:22,  1.39it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 642/839 [07:49<02:21,  1.39it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 643/839 [07:49<02:20,  1.39it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 644/839 [07:50<02:19,  1.40it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 645/839 [07:51<02:20,  1.38it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 646/839 [07:52<02:19,  1.38it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 647/839 [07:52<02:18,  1.38it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 648/839 [07:53<02:17,  1.39it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 649/839 [07:54<02:18,  1.37it/s]\u001b[A\n",
      "Iteration:  77%|███████▋  | 650/839 [07:54<02:17,  1.38it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 651/839 [07:55<02:16,  1.38it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 652/839 [07:56<02:16,  1.37it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 653/839 [07:57<02:15,  1.37it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 654/839 [07:57<02:14,  1.37it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 655/839 [07:58<02:14,  1.37it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 656/839 [07:59<02:15,  1.35it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 657/839 [08:00<02:13,  1.36it/s]\u001b[A\n",
      "Iteration:  78%|███████▊  | 658/839 [08:00<02:13,  1.36it/s]\u001b[A\n",
      "Iteration:  79%|███████▊  | 659/839 [08:01<02:11,  1.37it/s]\u001b[A\n",
      "Iteration:  79%|███████▊  | 660/839 [08:02<02:11,  1.36it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 661/839 [08:03<02:09,  1.38it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 662/839 [08:03<02:08,  1.37it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 663/839 [08:04<02:08,  1.37it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 664/839 [08:05<02:07,  1.37it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 665/839 [08:05<02:06,  1.38it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 666/839 [08:06<02:05,  1.38it/s]\u001b[A\n",
      "Iteration:  79%|███████▉  | 667/839 [08:07<02:03,  1.39it/s]\u001b[A\n",
      "Iteration:  80%|███████▉  | 668/839 [08:08<02:02,  1.39it/s]\u001b[A\n",
      "Iteration:  80%|███████▉  | 669/839 [08:08<02:01,  1.40it/s]\u001b[A\n",
      "Iteration:  80%|███████▉  | 670/839 [08:09<02:01,  1.39it/s]\u001b[A\n",
      "Iteration:  80%|███████▉  | 671/839 [08:10<02:00,  1.39it/s]\u001b[A01/07/2020 14:47:41 - INFO - __main__ -   Average loss: 1.4272548580169677 at global step: 2350\n",
      "\n",
      "Iteration:  80%|████████  | 672/839 [08:10<01:59,  1.39it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 673/839 [08:11<01:59,  1.39it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 674/839 [08:12<01:59,  1.38it/s]\u001b[A\n",
      "Iteration:  80%|████████  | 675/839 [08:13<01:59,  1.37it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 676/839 [08:13<01:58,  1.37it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 677/839 [08:14<01:56,  1.39it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 678/839 [08:15<01:55,  1.39it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 679/839 [08:16<01:54,  1.40it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 680/839 [08:16<01:53,  1.40it/s]\u001b[A\n",
      "Iteration:  81%|████████  | 681/839 [08:17<01:52,  1.40it/s]\u001b[A\n",
      "Iteration:  81%|████████▏ | 682/839 [08:18<01:52,  1.39it/s]\u001b[A\n",
      "Iteration:  81%|████████▏ | 683/839 [08:18<01:52,  1.38it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 684/839 [08:19<01:51,  1.39it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 685/839 [08:20<01:51,  1.38it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 686/839 [08:21<01:51,  1.38it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 687/839 [08:21<01:50,  1.38it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 688/839 [08:22<01:48,  1.39it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 689/839 [08:23<01:47,  1.39it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 690/839 [08:23<01:47,  1.39it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  82%|████████▏ | 691/839 [08:24<01:46,  1.39it/s]\u001b[A\n",
      "Iteration:  82%|████████▏ | 692/839 [08:25<01:46,  1.39it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 693/839 [08:26<01:46,  1.37it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 694/839 [08:26<01:45,  1.37it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 695/839 [08:27<01:44,  1.38it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 696/839 [08:28<01:43,  1.39it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 697/839 [08:29<01:42,  1.38it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 698/839 [08:29<01:42,  1.38it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 699/839 [08:30<01:41,  1.37it/s]\u001b[A\n",
      "Iteration:  83%|████████▎ | 700/839 [08:31<01:41,  1.37it/s]\u001b[A\n",
      "Iteration:  84%|████████▎ | 701/839 [08:31<01:41,  1.36it/s]\u001b[A\n",
      "Iteration:  84%|████████▎ | 702/839 [08:32<01:42,  1.34it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 703/839 [08:33<01:41,  1.34it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 704/839 [08:34<01:40,  1.34it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 705/839 [08:34<01:39,  1.35it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 706/839 [08:35<01:38,  1.35it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 707/839 [08:36<01:37,  1.36it/s]\u001b[A\n",
      "Iteration:  84%|████████▍ | 708/839 [08:37<01:35,  1.37it/s]\u001b[A\n",
      "Iteration:  85%|████████▍ | 709/839 [08:37<01:33,  1.38it/s]\u001b[A\n",
      "Iteration:  85%|████████▍ | 710/839 [08:38<01:32,  1.39it/s]\u001b[A\n",
      "Iteration:  85%|████████▍ | 711/839 [08:39<01:32,  1.38it/s]\u001b[A\n",
      "Iteration:  85%|████████▍ | 712/839 [08:40<01:32,  1.37it/s]\u001b[A\n",
      "Iteration:  85%|████████▍ | 713/839 [08:40<01:31,  1.38it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 714/839 [08:41<01:30,  1.38it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 715/839 [08:42<01:29,  1.38it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 716/839 [08:42<01:28,  1.39it/s]\u001b[A\n",
      "Iteration:  85%|████████▌ | 717/839 [08:43<01:27,  1.39it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 718/839 [08:44<01:28,  1.37it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 719/839 [08:45<01:27,  1.38it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 720/839 [08:45<01:26,  1.38it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 721/839 [08:46<01:25,  1.38it/s]\u001b[A01/07/2020 14:48:17 - INFO - __main__ -   Average loss: 1.3906275737285614 at global step: 2400\n",
      "\n",
      "Iteration:  86%|████████▌ | 722/839 [08:47<01:23,  1.40it/s]\u001b[A\n",
      "Iteration:  86%|████████▌ | 723/839 [08:47<01:23,  1.39it/s]\u001b[A\n",
      "Iteration:  86%|████████▋ | 724/839 [08:48<01:22,  1.40it/s]\u001b[A\n",
      "Iteration:  86%|████████▋ | 725/839 [08:49<01:21,  1.40it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 726/839 [08:50<01:21,  1.39it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 727/839 [08:50<01:21,  1.38it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 728/839 [08:51<01:20,  1.39it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 729/839 [08:52<01:19,  1.38it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 730/839 [08:53<01:19,  1.37it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 731/839 [08:53<01:18,  1.37it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 732/839 [08:54<01:17,  1.38it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 733/839 [08:55<01:16,  1.38it/s]\u001b[A\n",
      "Iteration:  87%|████████▋ | 734/839 [08:55<01:15,  1.38it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 735/839 [08:56<01:15,  1.38it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 736/839 [08:57<01:14,  1.39it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 737/839 [08:58<01:13,  1.39it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 738/839 [08:58<01:12,  1.38it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 739/839 [08:59<01:12,  1.39it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 740/839 [09:00<01:11,  1.39it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 741/839 [09:00<01:10,  1.38it/s]\u001b[A\n",
      "Iteration:  88%|████████▊ | 742/839 [09:01<01:10,  1.38it/s]\u001b[A\n",
      "Iteration:  89%|████████▊ | 743/839 [09:02<01:09,  1.38it/s]\u001b[A\n",
      "Iteration:  89%|████████▊ | 744/839 [09:03<01:08,  1.38it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 745/839 [09:03<01:07,  1.38it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 746/839 [09:04<01:06,  1.39it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 747/839 [09:05<01:06,  1.39it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 748/839 [09:06<01:05,  1.39it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 749/839 [09:06<01:04,  1.39it/s]\u001b[A\n",
      "Iteration:  89%|████████▉ | 750/839 [09:07<01:03,  1.39it/s]\u001b[A\n",
      "Iteration:  90%|████████▉ | 751/839 [09:08<01:03,  1.39it/s]\u001b[A\n",
      "Iteration:  90%|████████▉ | 752/839 [09:08<01:02,  1.39it/s]\u001b[A\n",
      "Iteration:  90%|████████▉ | 753/839 [09:09<01:01,  1.40it/s]\u001b[A\n",
      "Iteration:  90%|████████▉ | 754/839 [09:10<01:01,  1.39it/s]\u001b[A\n",
      "Iteration:  90%|████████▉ | 755/839 [09:11<01:00,  1.39it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 756/839 [09:11<00:59,  1.40it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 757/839 [09:12<00:59,  1.39it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 758/839 [09:13<00:58,  1.38it/s]\u001b[A\n",
      "Iteration:  90%|█████████ | 759/839 [09:13<00:58,  1.37it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 760/839 [09:14<00:57,  1.36it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 761/839 [09:15<00:57,  1.36it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 762/839 [09:16<00:56,  1.37it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 763/839 [09:16<00:55,  1.36it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 764/839 [09:17<00:54,  1.37it/s]\u001b[A\n",
      "Iteration:  91%|█████████ | 765/839 [09:18<00:54,  1.35it/s]\u001b[A\n",
      "Iteration:  91%|█████████▏| 766/839 [09:19<00:54,  1.35it/s]\u001b[A\n",
      "Iteration:  91%|█████████▏| 767/839 [09:19<00:53,  1.34it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 768/839 [09:20<00:52,  1.35it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 769/839 [09:21<00:51,  1.35it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 770/839 [09:22<00:50,  1.36it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 771/839 [09:22<00:49,  1.37it/s]\u001b[A01/07/2020 14:48:54 - INFO - __main__ -   Average loss: 1.4145712208747865 at global step: 2450\n",
      "\n",
      "Iteration:  92%|█████████▏| 772/839 [09:23<00:48,  1.39it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 773/839 [09:24<00:47,  1.40it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 774/839 [09:24<00:46,  1.40it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 775/839 [09:25<00:45,  1.41it/s]\u001b[A\n",
      "Iteration:  92%|█████████▏| 776/839 [09:26<00:44,  1.41it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 777/839 [09:27<00:44,  1.40it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 778/839 [09:27<00:43,  1.40it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 779/839 [09:28<00:42,  1.40it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 780/839 [09:29<00:42,  1.40it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 781/839 [09:29<00:41,  1.40it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 782/839 [09:30<00:41,  1.39it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 783/839 [09:31<00:40,  1.37it/s]\u001b[A\n",
      "Iteration:  93%|█████████▎| 784/839 [09:32<00:40,  1.37it/s]\u001b[A\n",
      "Iteration:  94%|█████████▎| 785/839 [09:32<00:39,  1.36it/s]\u001b[A\n",
      "Iteration:  94%|█████████▎| 786/839 [09:33<00:38,  1.37it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 787/839 [09:34<00:37,  1.38it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 788/839 [09:35<00:37,  1.38it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 789/839 [09:35<00:36,  1.38it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 790/839 [09:36<00:35,  1.38it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 791/839 [09:37<00:35,  1.36it/s]\u001b[A\n",
      "Iteration:  94%|█████████▍| 792/839 [09:37<00:34,  1.36it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 793/839 [09:38<00:33,  1.36it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 794/839 [09:39<00:33,  1.36it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 795/839 [09:40<00:32,  1.37it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 796/839 [09:40<00:31,  1.37it/s]\u001b[A\n",
      "Iteration:  95%|█████████▍| 797/839 [09:41<00:30,  1.38it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 798/839 [09:42<00:29,  1.38it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 799/839 [09:43<00:28,  1.38it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 800/839 [09:43<00:28,  1.38it/s]\u001b[A\n",
      "Iteration:  95%|█████████▌| 801/839 [09:44<00:27,  1.38it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 802/839 [09:45<00:26,  1.38it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 803/839 [09:45<00:26,  1.38it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 804/839 [09:46<00:25,  1.38it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 805/839 [09:47<00:24,  1.39it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 806/839 [09:48<00:23,  1.39it/s]\u001b[A\n",
      "Iteration:  96%|█████████▌| 807/839 [09:48<00:23,  1.39it/s]\u001b[A\n",
      "Iteration:  96%|█████████▋| 808/839 [09:49<00:22,  1.38it/s]\u001b[A\n",
      "Iteration:  96%|█████████▋| 809/839 [09:50<00:21,  1.38it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 810/839 [09:51<00:20,  1.38it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 811/839 [09:51<00:20,  1.38it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 812/839 [09:52<00:20,  1.29it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 813/839 [09:53<00:20,  1.29it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 814/839 [09:54<00:19,  1.31it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 815/839 [09:54<00:18,  1.31it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:  97%|█████████▋| 816/839 [09:55<00:17,  1.33it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 817/839 [09:56<00:16,  1.34it/s]\u001b[A\n",
      "Iteration:  97%|█████████▋| 818/839 [09:57<00:15,  1.34it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 819/839 [09:57<00:15,  1.33it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 820/839 [09:58<00:14,  1.35it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 821/839 [09:59<00:13,  1.37it/s]\u001b[A01/07/2020 14:49:30 - INFO - __main__ -   Average loss: 1.4241965866088868 at global step: 2500\n",
      "\n",
      "Iteration:  98%|█████████▊| 822/839 [10:00<00:12,  1.38it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 823/839 [10:00<00:11,  1.39it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 824/839 [10:01<00:10,  1.39it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 825/839 [10:02<00:10,  1.39it/s]\u001b[A\n",
      "Iteration:  98%|█████████▊| 826/839 [10:02<00:09,  1.39it/s]\u001b[A\n",
      "Iteration:  99%|█████████▊| 827/839 [10:03<00:08,  1.39it/s]\u001b[A\n",
      "Iteration:  99%|█████████▊| 828/839 [10:04<00:07,  1.39it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 829/839 [10:05<00:07,  1.40it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 830/839 [10:05<00:06,  1.40it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 831/839 [10:06<00:05,  1.40it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 832/839 [10:07<00:05,  1.40it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 833/839 [10:07<00:04,  1.39it/s]\u001b[A\n",
      "Iteration:  99%|█████████▉| 834/839 [10:08<00:03,  1.38it/s]\u001b[A\n",
      "Iteration: 100%|█████████▉| 835/839 [10:09<00:02,  1.36it/s]\u001b[A\n",
      "Iteration: 100%|█████████▉| 836/839 [10:10<00:02,  1.36it/s]\u001b[A\n",
      "Iteration: 100%|█████████▉| 837/839 [10:10<00:01,  1.36it/s]\u001b[A\n",
      "Iteration: 100%|█████████▉| 838/839 [10:11<00:00,  1.37it/s]\u001b[A\n",
      "Iteration: 100%|██████████| 839/839 [10:12<00:00,  1.37it/s]\u001b[A\n",
      "Epoch: 100%|██████████| 3/3 [30:36<00:00, 612.12s/it]\n",
      "01/07/2020 14:49:43 - INFO - __main__ -    global_step = 2517, average loss = 1.435550414644445\n"
     ]
    }
   ],
   "source": [
    "if do_train:\n",
    "    train_dataset = load_and_cache_examples(task_name,tokenizer, evaluate =False)\n",
    "    global_step, tr_loss, best_steps = train(train_dataset, model, tokenizer)\n",
    "    logger.info(\" global_step = %s, average loss = %s\", global_step, tr_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/07/2020 14:50:53 - INFO - __main__ -   Evaluate the following checkpoints: ['save/checkpoint-1000', 'save/checkpoint-2000']\n",
      "01/07/2020 14:50:53 - INFO - src.transformers.configuration_utils -   loading configuration file save/checkpoint-1000/config.json\n",
      "01/07/2020 14:50:53 - INFO - src.transformers.configuration_utils -   Model config {\n",
      "  \"attn_type\": \"bi\",\n",
      "  \"bi_data\": false,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"clamp_len\": -1,\n",
      "  \"d_head\": 64,\n",
      "  \"d_inner\": 3072,\n",
      "  \"d_model\": 768,\n",
      "  \"do_sample\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"end_n_top\": 5,\n",
      "  \"eos_token_ids\": 0,\n",
      "  \"ff_activation\": \"gelu\",\n",
      "  \"finetuning_task\": \"arc\",\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"mem_len\": null,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_labels\": 4,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"reuse_len\": null,\n",
      "  \"same_length\": false,\n",
      "  \"start_n_top\": 5,\n",
      "  \"summary_activation\": \"tanh\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"last\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"untie_r\": true,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "01/07/2020 14:50:53 - INFO - src.transformers.modeling_utils -   loading weights file save/checkpoint-1000/pytorch_model.bin\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'kg_embeddings'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-f39bb42dc24b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"checkpoint\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/transformers-master/src/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0;31m# Instantiate model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfrom_tf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/transformers-master/src/transformers/modeling_with_arc_xlnet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, kg)\u001b[0m\n\u001b[1;32m   1367\u001b[0m         \u001b[0;31m# d_model: Size of the encoder layers and the pooler layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1369\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_relations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkg_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rel_matrices'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1370\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_entities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkg_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ent_embeddings'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'kg_embeddings'"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "if do_eval and local_rank in [-1, 0]:\n",
    "    if not do_train:\n",
    "        output_dir = model_name_or_path\n",
    "    checkpoints = [output_dir]\n",
    "    if eval_all_checkpoints:\n",
    "        checkpoints = list(\n",
    "            os.path.dirname(c) for c in sorted(glob.glob(output_dir + \"/**/\" + WEIGHTS_NAME, recursive=True))\n",
    "        )\n",
    "        logging.getLogger(\"transformers.modeling_utils\").setLevel(logging.WARN)  # Reduce logging\n",
    "    logger.info(\"Evaluate the following checkpoints: %s\", checkpoints)\n",
    "    for checkpoint in checkpoints:\n",
    "        global_step = checkpoint.split(\"-\")[-1] if len(checkpoints) > 1 else \"\"\n",
    "        prefix = checkpoint.split(\"/\")[-1] if checkpoint.find(\"checkpoint\") != -1 else \"\"\n",
    "\n",
    "        model = model_class.from_pretrained(checkpoint)\n",
    "        model.to(device)\n",
    "        result = evaluate(args, model, tokenizer, prefix=prefix)\n",
    "        result = dict((k + \"_{}\".format(global_step), v) for k, v in result.items())\n",
    "        results.update(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints = [output_dir]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints = list(\n",
    "            os.path.dirname(c) for c in sorted(glob.glob(output_dir + \"/**/\" + WEIGHTS_NAME, recursive=True))\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['save/checkpoint-1000', 'save/checkpoint-2000']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = checkpoints[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = checkpoint.split(\"-\")[-1] if len(checkpoints) > 1 else \"\"\n",
    "prefix = checkpoint.split(\"/\")[-1] if checkpoint.find(\"checkpoint\") != -1 else \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/07/2020 15:26:34 - INFO - src.transformers.configuration_utils -   loading configuration file save/checkpoint-1000/config.json\n",
      "01/07/2020 15:26:34 - INFO - src.transformers.configuration_utils -   Model config {\n",
      "  \"attn_type\": \"bi\",\n",
      "  \"bi_data\": false,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"clamp_len\": -1,\n",
      "  \"d_head\": 64,\n",
      "  \"d_inner\": 3072,\n",
      "  \"d_model\": 768,\n",
      "  \"do_sample\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"end_n_top\": 5,\n",
      "  \"eos_token_ids\": 0,\n",
      "  \"ff_activation\": \"gelu\",\n",
      "  \"finetuning_task\": \"arc\",\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"mem_len\": null,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_labels\": 4,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"reuse_len\": null,\n",
      "  \"same_length\": false,\n",
      "  \"start_n_top\": 5,\n",
      "  \"summary_activation\": \"tanh\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"last\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"untie_r\": true,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "01/07/2020 15:26:34 - INFO - src.transformers.modeling_utils -   loading weights file save/checkpoint-1000/pytorch_model.bin\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'kg_embeddings'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-24d7d367ea47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/transformers-master/src/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0;31m# Instantiate model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfrom_tf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/transformers-master/src/transformers/modeling_with_arc_xlnet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, kg)\u001b[0m\n\u001b[1;32m   1367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXLNetModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1369\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence_summary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequenceSummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1370\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits_proj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m         \u001b[0;31m# d_model: Size of the encoder layers and the pooler layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'kg_embeddings'"
     ]
    }
   ],
   "source": [
    "model = model_class.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "src.transformers.modeling_with_arc_xlnet.XLNetForMultipleChoice"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
